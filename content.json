[{"title":"2021年-新的起点","date":"2021-01-23T01:54:15.000Z","path":"2021/01/23/2021年-新的起点/","text":"2021，重拾博客，开启新的旅途。","tags":[{"name":"Life","slug":"Life","permalink":"http://www.ylovex.cn/tags/Life/"}]},{"title":"LeetCode-钥匙和房间","date":"2019-08-13T11:24:33.000Z","path":"2019/08/13/LeetCode-钥匙和房间/","text":"题目来源：https://leetcode-cn.com/problems/keys-and-rooms/ 题目描述：有 N 个房间，开始时你位于 0 号房间。每个房间有不同的号码：0，1，2，…，N-1，并且房间里可能有一些钥匙能使你进入下一个房间。 在形式上，对于每个房间 i 都有一个钥匙列表 rooms[i]，每个钥匙 rooms[i][j] 由 [0,1，…，N-1] 中的一个整数表示，其中 N = rooms.length。 钥匙 rooms[i][j] = v 可以打开编号为 v 的房间。 最初，除 0 号房间外的其余所有房间都被锁住。 你可以自由地在房间之间来回走动。 如果能进入每个房间返回 true，否则返回 false。 参考代码：123456789101112131415161718192021class Solution &#123; public boolean canVisitAllRooms(List&lt;List&lt;Integer&gt;&gt; rooms) &#123; Set&lt;Integer&gt; visited = new HashSet&lt;&gt;(); if(rooms.size() == 0) return false; visited.add(0); dfs(rooms, visited, 0); return visited.size() == rooms.size(); &#125; private void dfs(List&lt;List&lt;Integer&gt;&gt; rooms, Set&lt;Integer&gt; visited, int room) &#123; for(int i = 0;i &lt; rooms.get(room).size(); i++) &#123; int key = rooms.get(room).get(i); if(!visited.contains(key)) &#123; visited.add(key); dfs(rooms, visited, key); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425public boolean canVisitAllRooms(List&lt;List&lt;Integer&gt;&gt; rooms) &#123; int totalRooms = rooms.size(); Set&lt;Integer&gt; visited = new HashSet&lt;&gt;(); Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); visited.add(0); queue.add(0); while(!queue.isEmpty()) &#123; int curRoom = queue.remove(); List&lt;Integer&gt; keys = rooms.get(curRoom); for (int key: keys) &#123; if (!visited.contains(key)) &#123; visited.add(key); queue.add(key); &#125; &#125; &#125; return visited.size() == totalRooms; &#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"}]},{"title":"nowcoder-进制转换","date":"2019-08-05T11:24:00.000Z","path":"2019/08/05/nowcoder-进制转换/","text":"写一个函数，求两个整数之和，要求在函数体内不得使用+、-、*、/四则运算符号。两个数异或：相当于每一位相加，而不考虑进位；两个数相与，并左移一位：相当于求得进位；将上述两步的结果相加 123456789public int Add(int num1,int num2) &#123; while( num2!=0 )&#123; int sum = num1 ^ num2; int carray = (num1 &amp; num2) &lt;&lt; 1; num1 = sum; num2 = carray; &#125; return num1;&#125; 求1+2+3+…+n，要求不能使用乘除法、for、while、if、else、switch、case等关键字及条件判断语句（A?B:C）解题思路： 1.需利用逻辑与的短路特性实现递归终止。 2.当n==0时，(n&gt;0)&amp;&amp;((sum+=Sum_Solution(n-1))&gt;0)只执行前面的判断，为false，然后直接返回0； 3.当n&gt;0时，执行sum+=Sum_Solution(n-1)，实现递归计算Sum_Solution(n). 12345public int Sum_Solution(int n) &#123; int sum = n; boolean ans = (n&gt;0)&amp;&amp;((sum+=Sum_Solution(n-1))&gt;0); return sum; &#125; 最大公约数（最大公因数）：指某几个整数共有约数中最大的一个。求两个整数最大公约数主要的方法： 列举法：各自列出约数，再找出最大的公约数。 素因数分解法：两数各作素因数分解，然后取出共有的项乘起来。 短除法 辗转相除法（扩展版）：常使用于直观上不容易判别公约数的场合。 1234private int GCD(int a, int b) &#123; if(b==0) return a; return a % b == 0 ? b : GCD(b, a % b);&#125; 最小公倍数123456private int GCD(int a, int b) &#123; return a % b == 0 ? b : GCD(b, a % b);&#125;private int LCM(int a, int b) &#123; return a * b / GCD(a, b);&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"}]},{"title":"Redis设计与实现笔记八","date":"2019-07-30T13:06:26.000Z","path":"2019/07/30/Redis设计与实现笔记八/","text":"数据库Redis服务器将所有的数据库都保存在服务器状态redisServer结构的db数组中，db数组的每项都是一个redisDb结构，每个redisDb结构都代表一个数据库 1234567891011121314151617181920212223242526typedef struct redisDb &#123; // 数据库键空间，保存着数据库中的所有键值对 dict *dict; /* The keyspace for this DB */ // 键的过期时间，字典的键为键，字典的值为过期事件 UNIX 时间戳 dict *expires; /* Timeout of keys with a timeout set */ // 正处于阻塞状态的键 dict *blocking_keys; /* Keys with clients waiting for data (BLPOP) */ // 可以解除阻塞的键 dict *ready_keys; /* Blocked keys that received a PUSH */ // 正在被 WATCH 命令监视的键 dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS */ struct evictionPoolEntry *eviction_pool; /* Eviction pool of keys */ // 数据库号码 int id; /* Database ID */ // 数据库的键的平均 TTL ，统计信息 long long avg_ttl; /* Average TTL, just for stats */&#125; redisDb; 初始化服务器时候，根据redisServer中的dbnum属性决定创建数据库个数，默认为16，默认情况使用0号数据库，通过SELECT命令可以切换目标数据库 客户端状态redisClient结构的db属性记录了客户端当前目标数据库。 数据库键空间redisDb结构的dict属性保存了数据库中的所有键值对， 键空间的键也就是数据库的键，每个键都是一个字符串对象 键空间的值也就是数据库的值，每个值可以是字符串对象、列表对象、哈希表对象、集合对象和有序集合对象中的任意一种 读写键空间时的维护操作当使用Redis命令对数据库进行读写时，服务器不仅会对键空间执行指定的读写操作，还会执行一些额外的维护操作，比如 在读取一个键后（读操作和写操作都要对键进行读取），服务器会根据键是否存在来更新服务器的键空间命中（hit）次数或键空间不命中（miss）次数，这两个值可以在INFO stats命令的keyspace_hits keyspace_misses属性查看 在读取一个键之后，服务器会更新键的LRU（最后一次使用）时间，这个值可以用于计算键的闲置时间，使用OBJECT idletime 命令可以查看键的闲置时间 如果服务器在读取一个键时发现键已经过期，那么服务器会先删除这个过期键，然后才执行余下的其他操作 如果有客户端使用WATCH命令监视了某个键，那么服务器在对被监视键进行修改后，会将这个键标记为脏（dirty）从而让事务程序注意到这个键已经被修改过 服务器每次修改一个键后，都会对脏键计数器值增一，这个计数器会触发服务器的持久化以及复制操作 如果服务器开启了数据库通知功能，那么在对键进行修改后，服务器将按配置发送相应的数据库通知 设置键生存时间或过期时间有四个不同的命令可以用于设置键的生存时间或过期时间 EXPIRE 用于将键key的生存时间设置为ttl秒 PEXPIRE 用于将生存时间设置为ttl毫秒 EXPIREAT 用于将过期时间设置为timestamp所指定的秒数时间戳 PEXPIREAT 用于将过期时间设置为timestamp所指定的毫秒数时间戳 实际上，EXPIRE、PEXPIRE、EXPIREAT都是通过PEXPIREAT实现 redisDb结构的expires字典保存了数据库中所有键的过期时间 移除过期时间PERSIST命令可以移除一个键的过期时间 计算并返回过期时间TTL命令和PTTL命令 过期键判断检查给定键是否存在于过期字典，如果存在那么取得键的过期时间 检查当前UNIX时间戳是否大于键的过期时候：如果是的话，那么键已经过期 过期键删除策略定时删除在设置键的过期时间的同时，创建一个定时器，让定时器在键过期时机来临时，立即执行对键的删除操作 惰性删除放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话就删除该键，如果没有过期就返回改建 定期删除每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。 Redis服务器实际使用的是惰性删除和定期删除两种策略：通过配合使用这两种删除策略，服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡 惰性删除策略由db.c中的expireIfNeeded函数实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/* * 检查 key 是否已经过期，如果是的话，将它从数据库中删除。 * * 返回 0 表示键没有过期时间，或者键未过期。 * * 返回 1 表示键已经因为过期而被删除了。 */int expireIfNeeded(redisDb *db, robj *key) &#123; // 取出键的过期时间 mstime_t when = getExpire(db,key); mstime_t now; // 没有过期时间 if (when &lt; 0) return 0; /* No expire for this key */ /* Don&apos;t expire anything while loading. It will be done later. */ // 如果服务器正在进行载入，那么不进行任何过期检查 if (server.loading) return 0; /* If we are in the context of a Lua script, we claim that time is * blocked to when the Lua script started. This way a key can expire * only the first time it is accessed and not in the middle of the * script execution, making propagation to slaves / AOF consistent. * See issue #1525 on Github for more information. */ now = server.lua_caller ? server.lua_time_start : mstime(); /* If we are running in the context of a slave, return ASAP: * the slave key expiration is controlled by the master that will * send us synthesized DEL operations for expired keys. * * Still we try to return the right information to the caller, * that is, 0 if we think the key should be still valid, 1 if * we think the key is expired at this time. */ // 当服务器运行在 replication 模式时 // 附属节点并不主动删除 key // 它只返回一个逻辑上正确的返回值 // 真正的删除操作要等待主节点发来删除命令时才执行 // 从而保证数据的同步 if (server.masterhost != NULL) return now &gt; when; // 运行到这里，表示键带有过期时间，并且服务器为主节点 /* Return when this key has not expired */ // 如果未过期，返回 0 if (now &lt;= when) return 0; /* Delete the key */ server.stat_expiredkeys++; // 向 AOF 文件和附属节点传播过期信息 propagateExpire(db,key); // 发送事件通知 notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED, &quot;expired&quot;,key,db-&gt;id); // 将过期键从数据库中删除 return dbDelete(db,key);&#125; 定期删除策略由redis.c中的activeExpireCycle实现，每当Redis服务器周期性操作redis.c/serverCron函数时，activeExpireCycle函数就会被调用，它在规定时间内，分多次遍历服务器中的各个数据库，从数据库的expire字典中随机检查一部分键的过期时间并删除其中过期键 AOF、RDB和复制功能对过期键处理生成RDB文件在执行SAVE命令或者BGSAVE命令创建一个新RDB文件，程序会对数据库中的键进行检查，已经过期键不会被保存到新创建的RDB文件中 载入RDB文件在启动Redis服务器时，如果服务器开启了RDB功能，那么服务器将对RDB文件进行载入 如果服务器以主服务器模式运行，那么在载入RDB文件时，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，过期键被忽略 如果服务器以从服务器运行，所有键都会载入。 AOF文件写入当服务器以AOF持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被惰性删除或者定期删除，那么AOF文件不会因为这个过期键产生任何影响 当过期键被惰性删除后，程序会向AOF文件追加一条DEL命令，来显示地记录该键已被删除 AOF重写在执行AOF重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的AOF文件中 复制主服务器在删除一个过期键之后，会显式地向所有从服务器发送一个DEL命令，告知从服务器删除这个过期键 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期的键删除，而是继续像处理未过期的键一样来处理过期键 从服务器只有在接到主服务器发来的DEL命令后，才会删除过期键 数据库通知可以让客户端通过订阅给定的频道或者模式，来获知数据库中键的变换，以及数据库中命令的执行情况\\ 发送数据库通知的功能是由notify.c/notifyKeyspaceEvent函数实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/* The API provided to the rest of the Redis core is a simple function: * * notifyKeyspaceEvent(char *event, robj *key, int dbid); * * &apos;event&apos; is a C string representing the event name. * * event 参数是一个字符串表示的事件名 * * &apos;key&apos; is a Redis object representing the key name. * * key 参数是一个 Redis 对象表示的键名 * * &apos;dbid&apos; is the database ID where the key lives. * * dbid 参数为键所在的数据库 */void notifyKeyspaceEvent(int type, char *event, robj *key, int dbid) &#123; sds chan; robj *chanobj, *eventobj; int len = -1; char buf[24]; /* If notifications for this class of events are off, return ASAP. */ // 如果服务器配置为不发送 type 类型的通知，那么直接返回 if (!(server.notify_keyspace_events &amp; type)) return; // 事件的名字 eventobj = createStringObject(event,strlen(event)); /* __keyspace@&lt;db&gt;__:&lt;key&gt; &lt;event&gt; notifications. */ // 发送键空间通知 if (server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYSPACE) &#123; // 构建频道对象 chan = sdsnewlen(&quot;__keyspace@&quot;,11); len = ll2string(buf,sizeof(buf),dbid); chan = sdscatlen(chan, buf, len); chan = sdscatlen(chan, &quot;__:&quot;, 3); chan = sdscatsds(chan, key-&gt;ptr); chanobj = createObject(REDIS_STRING, chan); // 通过 publish 命令发送通知 pubsubPublishMessage(chanobj, eventobj); // 释放频道对象 decrRefCount(chanobj); &#125; /* __keyevente@&lt;db&gt;__:&lt;event&gt; &lt;key&gt; notifications. */ // 发送键事件通知 if (server.notify_keyspace_events &amp; REDIS_NOTIFY_KEYEVENT) &#123; // 构建频道对象 chan = sdsnewlen(&quot;__keyevent@&quot;,11); // 如果在前面发送键空间通知的时候计算了 len ，那么它就不会是 -1 // 这可以避免计算两次 buf 的长度 if (len == -1) len = ll2string(buf,sizeof(buf),dbid); chan = sdscatlen(chan, buf, len); chan = sdscatlen(chan, &quot;__:&quot;, 3); chan = sdscatsds(chan, eventobj-&gt;ptr); chanobj = createObject(REDIS_STRING, chan); // 通过 publish 命令发送通知 pubsubPublishMessage(chanobj, key); // 释放频道对象 decrRefCount(chanobj); &#125; // 释放事件对象 decrRefCount(eventobj);&#125; redisServer结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494struct redisServer &#123; /* General */ // 配置文件的绝对路径 char *configfile; /* Absolute config file path, or NULL */ // serverCron() 每秒调用的次数 int hz; /* serverCron() calls frequency in hertz */ // 数据库 redisDb *db; // 命令表（受到 rename 配置选项的作用） dict *commands; /* Command table */ // 命令表（无 rename 配置选项的作用） dict *orig_commands; /* Command table before command renaming. */ // 事件状态 aeEventLoop *el; // 最近一次使用时钟 unsigned lruclock:REDIS_LRU_BITS; /* Clock for LRU eviction */ // 关闭服务器的标识 int shutdown_asap; /* SHUTDOWN needed ASAP */ // 在执行 serverCron() 时进行渐进式 rehash int activerehashing; /* Incremental rehash in serverCron() */ // 是否设置了密码 char *requirepass; /* Pass for AUTH command, or NULL */ // PID 文件 char *pidfile; /* PID file path */ // 架构类型 int arch_bits; /* 32 or 64 depending on sizeof(long) */ // serverCron() 函数的运行次数计数器 int cronloops; /* Number of times the cron function run */ // 本服务器的 RUN ID char runid[REDIS_RUN_ID_SIZE+1]; /* ID always different at every exec. */ // 服务器是否运行在 SENTINEL 模式 int sentinel_mode; /* True if this instance is a Sentinel. */ /* Networking */ // TCP 监听端口 int port; /* TCP listening port */ int tcp_backlog; /* TCP listen() backlog */ // 地址 char *bindaddr[REDIS_BINDADDR_MAX]; /* Addresses we should bind to */ // 地址数量 int bindaddr_count; /* Number of addresses in server.bindaddr[] */ // UNIX 套接字 char *unixsocket; /* UNIX socket path */ mode_t unixsocketperm; /* UNIX socket permission */ // 描述符 int ipfd[REDIS_BINDADDR_MAX]; /* TCP socket file descriptors */ // 描述符数量 int ipfd_count; /* Used slots in ipfd[] */ // UNIX 套接字文件描述符 int sofd; /* Unix socket file descriptor */ int cfd[REDIS_BINDADDR_MAX];/* Cluster bus listening socket */ int cfd_count; /* Used slots in cfd[] */ // 一个链表，保存了所有客户端状态结构 list *clients; /* List of active clients */ // 链表，保存了所有待关闭的客户端 list *clients_to_close; /* Clients to close asynchronously */ // 链表，保存了所有从服务器，以及所有监视器 list *slaves, *monitors; /* List of slaves and MONITORs */ // 服务器的当前客户端，仅用于崩溃报告 redisClient *current_client; /* Current client, only used on crash report */ int clients_paused; /* True if clients are currently paused */ mstime_t clients_pause_end_time; /* Time when we undo clients_paused */ // 网络错误 char neterr[ANET_ERR_LEN]; /* Error buffer for anet.c */ // MIGRATE 缓存 dict *migrate_cached_sockets;/* MIGRATE cached sockets */ /* RDB / AOF loading information */ // 这个值为真时，表示服务器正在进行载入 int loading; /* We are loading data from disk if true */ // 正在载入的数据的大小 off_t loading_total_bytes; // 已载入数据的大小 off_t loading_loaded_bytes; // 开始进行载入的时间 time_t loading_start_time; off_t loading_process_events_interval_bytes; /* Fast pointers to often looked up command */ // 常用命令的快捷连接 struct redisCommand *delCommand, *multiCommand, *lpushCommand, *lpopCommand, *rpopCommand; /* Fields used only for stats */ // 服务器启动时间 time_t stat_starttime; /* Server start time */ // 已处理命令的数量 long long stat_numcommands; /* Number of processed commands */ // 服务器接到的连接请求数量 long long stat_numconnections; /* Number of connections received */ // 已过期的键数量 long long stat_expiredkeys; /* Number of expired keys */ // 因为回收内存而被释放的过期键的数量 long long stat_evictedkeys; /* Number of evicted keys (maxmemory) */ // 成功查找键的次数 long long stat_keyspace_hits; /* Number of successful lookups of keys */ // 查找键失败的次数 long long stat_keyspace_misses; /* Number of failed lookups of keys */ // 已使用内存峰值 size_t stat_peak_memory; /* Max used memory record */ // 最后一次执行 fork() 时消耗的时间 long long stat_fork_time; /* Time needed to perform latest fork() */ // 服务器因为客户端数量过多而拒绝客户端连接的次数 long long stat_rejected_conn; /* Clients rejected because of maxclients */ // 执行 full sync 的次数 long long stat_sync_full; /* Number of full resyncs with slaves. */ // PSYNC 成功执行的次数 long long stat_sync_partial_ok; /* Number of accepted PSYNC requests. */ // PSYNC 执行失败的次数 long long stat_sync_partial_err;/* Number of unaccepted PSYNC requests. */ /* slowlog */ // 保存了所有慢查询日志的链表 list *slowlog; /* SLOWLOG list of commands */ // 下一条慢查询日志的 ID long long slowlog_entry_id; /* SLOWLOG current entry ID */ // 服务器配置 slowlog-log-slower-than 选项的值 long long slowlog_log_slower_than; /* SLOWLOG time limit (to get logged) */ // 服务器配置 slowlog-max-len 选项的值 unsigned long slowlog_max_len; /* SLOWLOG max number of items logged */ size_t resident_set_size; /* RSS sampled in serverCron(). */ /* The following two are used to track instantaneous &quot;load&quot; in terms * of operations per second. */ // 最后一次进行抽样的时间 long long ops_sec_last_sample_time; /* Timestamp of last sample (in ms) */ // 最后一次抽样时，服务器已执行命令的数量 long long ops_sec_last_sample_ops; /* numcommands in last sample */ // 抽样结果 long long ops_sec_samples[REDIS_OPS_SEC_SAMPLES]; // 数组索引，用于保存抽样结果，并在需要时回绕到 0 int ops_sec_idx; /* Configuration */ // 日志可见性 int verbosity; /* Loglevel in redis.conf */ // 客户端最大空转时间 int maxidletime; /* Client timeout in seconds */ // 是否开启 SO_KEEPALIVE 选项 int tcpkeepalive; /* Set SO_KEEPALIVE if non-zero. */ int active_expire_enabled; /* Can be disabled for testing purposes. */ size_t client_max_querybuf_len; /* Limit for client query buffer length */ int dbnum; /* Total number of configured DBs */ int daemonize; /* True if running as a daemon */ // 客户端输出缓冲区大小限制 // 数组的元素有 REDIS_CLIENT_LIMIT_NUM_CLASSES 个 // 每个代表一类客户端：普通、从服务器、pubsub，诸如此类 clientBufferLimitsConfig client_obuf_limits[REDIS_CLIENT_LIMIT_NUM_CLASSES]; /* AOF persistence */ // AOF 状态（开启/关闭/可写） int aof_state; /* REDIS_AOF_(ON|OFF|WAIT_REWRITE) */ // 所使用的 fsync 策略（每个写入/每秒/从不） int aof_fsync; /* Kind of fsync() policy */ char *aof_filename; /* Name of the AOF file */ int aof_no_fsync_on_rewrite; /* Don&apos;t fsync if a rewrite is in prog. */ int aof_rewrite_perc; /* Rewrite AOF if % growth is &gt; M and... */ off_t aof_rewrite_min_size; /* the AOF file is at least N bytes. */ // 最后一次执行 BGREWRITEAOF 时， AOF 文件的大小 off_t aof_rewrite_base_size; /* AOF size on latest startup or rewrite. */ // AOF 文件的当前字节大小 off_t aof_current_size; /* AOF current size. */ int aof_rewrite_scheduled; /* Rewrite once BGSAVE terminates. */ // 负责进行 AOF 重写的子进程 ID pid_t aof_child_pid; /* PID if rewriting process */ // AOF 重写缓存链表，链接着多个缓存块 list *aof_rewrite_buf_blocks; /* Hold changes during an AOF rewrite. */ // AOF 缓冲区 sds aof_buf; /* AOF buffer, written before entering the event loop */ // AOF 文件的描述符 int aof_fd; /* File descriptor of currently selected AOF file */ // AOF 的当前目标数据库 int aof_selected_db; /* Currently selected DB in AOF */ // 推迟 write 操作的时间 time_t aof_flush_postponed_start; /* UNIX time of postponed AOF flush */ // 最后一直执行 fsync 的时间 time_t aof_last_fsync; /* UNIX time of last fsync() */ time_t aof_rewrite_time_last; /* Time used by last AOF rewrite run. */ // AOF 重写的开始时间 time_t aof_rewrite_time_start; /* Current AOF rewrite start time. */ // 最后一次执行 BGREWRITEAOF 的结果 int aof_lastbgrewrite_status; /* REDIS_OK or REDIS_ERR */ // 记录 AOF 的 write 操作被推迟了多少次 unsigned long aof_delayed_fsync; /* delayed AOF fsync() counter */ // 指示是否需要每写入一定量的数据，就主动执行一次 fsync() int aof_rewrite_incremental_fsync;/* fsync incrementally while rewriting? */ int aof_last_write_status; /* REDIS_OK or REDIS_ERR */ int aof_last_write_errno; /* Valid if aof_last_write_status is ERR */ /* RDB persistence */ // 自从上次 SAVE 执行以来，数据库被修改的次数 long long dirty; /* Changes to DB from the last save */ // BGSAVE 执行前的数据库被修改次数 long long dirty_before_bgsave; /* Used to restore dirty on failed BGSAVE */ // 负责执行 BGSAVE 的子进程的 ID // 没在执行 BGSAVE 时，设为 -1 pid_t rdb_child_pid; /* PID of RDB saving child */ struct saveparam *saveparams; /* Save points array for RDB */ int saveparamslen; /* Number of saving points */ char *rdb_filename; /* Name of RDB file */ int rdb_compression; /* Use compression in RDB? */ int rdb_checksum; /* Use RDB checksum? */ // 最后一次完成 SAVE 的时间 time_t lastsave; /* Unix time of last successful save */ // 最后一次尝试执行 BGSAVE 的时间 time_t lastbgsave_try; /* Unix time of last attempted bgsave */ // 最近一次 BGSAVE 执行耗费的时间 time_t rdb_save_time_last; /* Time used by last RDB save run. */ // 数据库最近一次开始执行 BGSAVE 的时间 time_t rdb_save_time_start; /* Current RDB save start time. */ // 最后一次执行 SAVE 的状态 int lastbgsave_status; /* REDIS_OK or REDIS_ERR */ int stop_writes_on_bgsave_err; /* Don&apos;t allow writes if can&apos;t BGSAVE */ /* Propagation of commands in AOF / replication */ redisOpArray also_propagate; /* Additional command to propagate. */ /* Logging */ char *logfile; /* Path of log file */ int syslog_enabled; /* Is syslog enabled? */ char *syslog_ident; /* Syslog ident */ int syslog_facility; /* Syslog facility */ /* Replication (master) */ int slaveseldb; /* Last SELECTed DB in replication output */ // 全局复制偏移量（一个累计值） long long master_repl_offset; /* Global replication offset */ // 主服务器发送 PING 的频率 int repl_ping_slave_period; /* Master pings the slave every N seconds */ // backlog 本身 char *repl_backlog; /* Replication backlog for partial syncs */ // backlog 的长度 long long repl_backlog_size; /* Backlog circular buffer size */ // backlog 中数据的长度 long long repl_backlog_histlen; /* Backlog actual data length */ // backlog 的当前索引 long long repl_backlog_idx; /* Backlog circular buffer current offset */ // backlog 中可以被还原的第一个字节的偏移量 long long repl_backlog_off; /* Replication offset of first byte in the backlog buffer. */ // backlog 的过期时间 time_t repl_backlog_time_limit; /* Time without slaves after the backlog gets released. */ // 距离上一次有从服务器的时间 time_t repl_no_slaves_since; /* We have no slaves since that time. Only valid if server.slaves len is 0. */ // 是否开启最小数量从服务器写入功能 int repl_min_slaves_to_write; /* Min number of slaves to write. */ // 定义最小数量从服务器的最大延迟值 int repl_min_slaves_max_lag; /* Max lag of &lt;count&gt; slaves to write. */ // 延迟良好的从服务器的数量 int repl_good_slaves_count; /* Number of slaves with lag &lt;= max_lag. */ /* Replication (slave) */ // 主服务器的验证密码 char *masterauth; /* AUTH with this password with master */ // 主服务器的地址 char *masterhost; /* Hostname of master */ // 主服务器的端口 int masterport; /* Port of master */ // 超时时间 int repl_timeout; /* Timeout after N seconds of master idle */ // 主服务器所对应的客户端 redisClient *master; /* Client that is master for this slave */ // 被缓存的主服务器，PSYNC 时使用 redisClient *cached_master; /* Cached master to be reused for PSYNC. */ int repl_syncio_timeout; /* Timeout for synchronous I/O calls */ // 复制的状态（服务器是从服务器时使用） int repl_state; /* Replication status if the instance is a slave */ // RDB 文件的大小 off_t repl_transfer_size; /* Size of RDB to read from master during sync. */ // 已读 RDB 文件内容的字节数 off_t repl_transfer_read; /* Amount of RDB read from master during sync. */ // 最近一次执行 fsync 时的偏移量 // 用于 sync_file_range 函数 off_t repl_transfer_last_fsync_off; /* Offset when we fsync-ed last time. */ // 主服务器的套接字 int repl_transfer_s; /* Slave -&gt; Master SYNC socket */ // 保存 RDB 文件的临时文件的描述符 int repl_transfer_fd; /* Slave -&gt; Master SYNC temp file descriptor */ // 保存 RDB 文件的临时文件名字 char *repl_transfer_tmpfile; /* Slave-&gt; master SYNC temp file name */ // 最近一次读入 RDB 内容的时间 time_t repl_transfer_lastio; /* Unix time of the latest read, for timeout */ int repl_serve_stale_data; /* Serve stale data when link is down? */ // 是否只读从服务器？ int repl_slave_ro; /* Slave is read only? */ // 连接断开的时长 time_t repl_down_since; /* Unix time at which link with master went down */ // 是否要在 SYNC 之后关闭 NODELAY ？ int repl_disable_tcp_nodelay; /* Disable TCP_NODELAY after SYNC? */ // 从服务器优先级 int slave_priority; /* Reported in INFO and used by Sentinel. */ // 本服务器（从服务器）当前主服务器的 RUN ID char repl_master_runid[REDIS_RUN_ID_SIZE+1]; /* Master run id for PSYNC. */ // 初始化偏移量 long long repl_master_initial_offset; /* Master PSYNC offset. */ /* Replication script cache. */ // 复制脚本缓存 // 字典 dict *repl_scriptcache_dict; /* SHA1 all slaves are aware of. */ // FIFO 队列 list *repl_scriptcache_fifo; /* First in, first out LRU eviction. */ // 缓存的大小 int repl_scriptcache_size; /* Max number of elements. */ /* Synchronous replication. */ list *clients_waiting_acks; /* Clients waiting in WAIT command. */ int get_ack_from_slaves; /* If true we send REPLCONF GETACK. */ /* Limits */ int maxclients; /* Max number of simultaneous clients */ unsigned long long maxmemory; /* Max number of memory bytes to use */ int maxmemory_policy; /* Policy for key eviction */ int maxmemory_samples; /* Pricision of random sampling */ /* Blocked clients */ unsigned int bpop_blocked_clients; /* Number of clients blocked by lists */ list *unblocked_clients; /* list of clients to unblock before next loop */ list *ready_keys; /* List of readyList structures for BLPOP &amp; co */ /* Sort parameters - qsort_r() is only available under BSD so we * have to take this state global, in order to pass it to sortCompare() */ int sort_desc; int sort_alpha; int sort_bypattern; int sort_store; /* Zip structure config, see redis.conf for more information */ size_t hash_max_ziplist_entries; size_t hash_max_ziplist_value; size_t list_max_ziplist_entries; size_t list_max_ziplist_value; size_t set_max_intset_entries; size_t zset_max_ziplist_entries; size_t zset_max_ziplist_value; size_t hll_sparse_max_bytes; time_t unixtime; /* Unix time sampled every cron cycle. */ long long mstime; /* Like &apos;unixtime&apos; but with milliseconds resolution. */ /* Pubsub */ // 字典，键为频道，值为链表 // 链表中保存了所有订阅某个频道的客户端 // 新客户端总是被添加到链表的表尾 dict *pubsub_channels; /* Map channels to list of subscribed clients */ // 这个链表记录了客户端订阅的所有模式的名字 list *pubsub_patterns; /* A list of pubsub_patterns */ int notify_keyspace_events; /* Events to propagate via Pub/Sub. This is an xor of REDIS_NOTIFY... flags. */ /* Cluster */ int cluster_enabled; /* Is cluster enabled? */ mstime_t cluster_node_timeout; /* Cluster node timeout. */ char *cluster_configfile; /* Cluster auto-generated config file name. */ struct clusterState *cluster; /* State of the cluster */ int cluster_migration_barrier; /* Cluster replicas migration barrier. */ /* Scripting */ // Lua 环境 lua_State *lua; /* The Lua interpreter. We use just one for all clients */ // 复制执行 Lua 脚本中的 Redis 命令的伪客户端 redisClient *lua_client; /* The &quot;fake client&quot; to query Redis from Lua */ // 当前正在执行 EVAL 命令的客户端，如果没有就是 NULL redisClient *lua_caller; /* The client running EVAL right now, or NULL */ // 一个字典，值为 Lua 脚本，键为脚本的 SHA1 校验和 dict *lua_scripts; /* A dictionary of SHA1 -&gt; Lua scripts */ // Lua 脚本的执行时限 mstime_t lua_time_limit; /* Script timeout in milliseconds */ // 脚本开始执行的时间 mstime_t lua_time_start; /* Start time of script, milliseconds time */ // 脚本是否执行过写命令 int lua_write_dirty; /* True if a write command was called during the execution of the current script. */ // 脚本是否执行过带有随机性质的命令 int lua_random_dirty; /* True if a random command was called during the execution of the current script. */ // 脚本是否超时 int lua_timedout; /* True if we reached the time limit for script execution. */ // 是否要杀死脚本 int lua_kill; /* Kill the script if true. */ /* Assert &amp; bug reporting */ char *assert_failed; char *assert_file; int assert_line; int bug_report_start; /* True if bug report header was already logged. */ int watchdog_period; /* Software watchdog period in ms. 0 = off */&#125;;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"LeetCode-二叉树的序列化与反序列化","date":"2019-07-26T23:43:07.000Z","path":"2019/07/27/LeetCode-二叉树的序列化与反序列化/","text":"题目来源https://leetcode-cn.com/problems/serialize-and-deserialize-binary-tree/ 题目描述序列化是将一个数据结构或者对象转换为连续的比特位的操作，进而可以将转换后的数据存储在一个文件或者内存中，同时也可以通过网络传输到另一个计算机环境，采取相反方式重构得到原数据。 请设计一个算法来实现二叉树的序列化与反序列化。这里不限定你的序列 / 反序列化算法执行逻辑，你只需要保证一个二叉树可以被序列化为一个字符串并且将这个字符串反序列化为原始的树结构。 思路根据前序遍历的顺序来序列化二叉树，因为前序遍历是从根节点开始的，在遍历到null节点的时候，可以将null节点序列化为字符串”null“，反序列化也是按照前序遍历递归的重建二叉树。 参考代码123456789101112131415161718192021222324252627282930313233343536373839404142package le;import java.util.ArrayDeque;import java.util.Arrays;import java.util.Queue;public class le_297 &#123; class TreeNode&#123; int val; TreeNode left; TreeNode right; TreeNode(int x)&#123;val=x;&#125; &#125; public String serialize(TreeNode root)&#123; if(root==null)&#123; return &quot;null,&quot;; &#125; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(root.val + &quot;,&quot;); stringBuilder.append(serialize(root.left)); stringBuilder.append(serialize(root.right)); return stringBuilder.toString(); &#125; public TreeNode deserialize(String data)&#123; String[] strings = data.split(&quot;,&quot;); Queue&lt;String&gt; queue = new ArrayDeque&lt;&gt;(Arrays.asList(strings)); return func(queue); &#125; private TreeNode func(Queue&lt;String&gt; queue) &#123; String string = queue.remove(); if(&quot;null&quot;.equals(string))&#123; return null; &#125; TreeNode node = new TreeNode(Integer.parseInt(string)); node.left = func(queue); node.right = func(queue); return node; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"}]},{"title":"java基础面试题总结","date":"2019-07-25T13:06:02.000Z","path":"2019/07/25/java基础面试题总结/","text":"JavaSE部分1、Java基础为什么重写equals还要重写hashcodejava编程里有关约定：如果两个对象根据equals方法比较是相等的，那么调用这两个对象的任意一个hashcode方法都必须产生相同的结果。 为了正常的使用集合类，比如在HashSet中加对象的时候，会首先用到对象的hashCode值，如果不相等就认为肯定不是一个对象，从而可以省去equals的调用开销，如果两个对象 equals 相等，但是 hashCode 不相等，会导致在 HashSet 中认为是两个不相等的对象，两个对象都会被加入到 HashSet，可能会导致程序异常。 说一下map的分类和常见的情况HashMap：最常用的Map，根据键的hashcode值来存储数据，根据键可以直接获得他的值（因为相同的键hashcode值相同，在地址为hashcode值的地方存储的就是值，所以根据键可以直接获得值），具有很快的访问速度，遍历时，取得数据的顺序完全是随机的，HashMap最多只允许一条记录的键为null，允许多条记录的值为null，HashMap不支持线程同步，即任意时刻可以有多个线程同时写HashMap，这样对导致数据不一致，如果需要同步，可以使用synchronziedMap的方法使得HashMap具有同步的能力或者使用concurrentHashMap HashTable：与HashMap类似，不同的是，它不允许记录的键或值为空，支持线程同步，即任意时刻只能有一个线程写HashTable，因此也导致HashTable在写入时比较慢! LinkedHasMap：是HahsMap的一个子类，但它保持了记录的插入顺序，遍历时先得到的肯定是先插入的，也可以在构造时带参数，按照应用次数排序，在遍历时会比HahsMap慢，不过有个例外，当HashMap的容量很大，实际数据少时，遍历起来会比LinkedHashMap慢（因为它是链啊），因为HashMap的遍历速度和它容量有关，LinkedHashMap遍历速度只与数据多少有关 TreeMap：实现了sortMap接口，能够把保存的记录按照键排序（默认升序），也可以指定排序比较器，遍历时得到的数据是排过序的 Object若不重写hashCode()的话，hashCode()如何计算出来的？Object的hashcode方法是本地方法，也就是用c语言或者c++实现的，是通过该对象的内存地址进行hash计算得到的。 ==比较的是什么？“==”判断的是两个对象的内存地址是否一样，适用于原始数据类型和枚举类型（它们的变量存储的是值本身，而引用类型变量存储的是引用）；equals是Object类的方法，Object对它的实现是比较内存地址，我们可以重写这个方法来自定义“相等”这个概念。比如类库中的String、Date等类就对这个方法进行了重写。 综上，对于枚举类型和原始数据类型的相等性比较，应该使用”==”；对于引用类型的相等性比较，应该使用equals方法。 若对一个类不重写，它的equals()方法是如何比较的？如果没有对equals方法进行重写，则比较的是引用类型的变量所指向的对象的地址； 诸如String、Date等类对equals方法进行了重写的话，比较的是所指向的对象的内容。 java8新特性接口的默认方法实现与静态方法、Lambda表达式、函数式接口、方法与构造函数引用、新的日期与时间API、流式处理等重要特性。 说说Lamda表达式的优缺点。优点：1. 简洁。2. 非常容易并行计算。3. 可能代表未来的编程趋势。 缺点：1. 若不用并行计算，很多时候计算速度没有比传统的 for 循环快。（并行计算有时需要预热才显示出效率优势）2. 不容易调试。3. 若其他程序员没有学过 lambda 表达式，代码不容易让其他语言的程序员看懂。 一个十进制的数在内存中是怎么存的？以二进制补码形式存储，最高位是符号位，正数的补码是它的原码，负数的补码是它的反码加1，在求反码时符号位不变，符号位为1，其他位取反 为啥有时会出现4.0-3.6=0.40000001这种现象？2进制的小数无法精确的表达10进制小数，计算机在计算10进制小数的过程中要先转换为2进制进行计算，这个过程中出现了误差。 Java支持的数据类型有哪些？什么是自动拆装箱？基本数据类型：整数值型：byte,short,int,long,字符型：char浮点类型：float,double布尔型：boolean整数默认int型，小数默认是double型。Float和long类型的必须加后缀。 首先知道String是引用类型不是基本类型，引用类型声明的变量是指该变量在内存中实际存储的是一个引用地址，实体在堆中。引用类型包括类、接口、数组等。String类还是final修饰的。 而包装类就属于引用类型，自动装箱和拆箱就是基本类型和引用类型之间的转换，至于为什么要转换，因为基本类型转换为引用类型后，就可以new对象，从而调用包装类中封装好的方法进行基本类型之间的转换或者toString（当然用类名直接调用也可以，便于一眼看出该方法是静态的），还有就是如果集合中想存放基本类型，泛型的限定类型只能是对应的包装类型。 什么是值传递和引用传递？1、值传递 在方法的调用过程中，实参把它的实际值传递给形参，此传递过程就是将实参的值复制一份传递到函数中，这样如果在函数中对该值（形参的值）进行了操作将不会影响实参的值。因为是直接复制，所以这种方式在传递大量数据时，运行效率会特别低下。 2、引用传递 引用传递弥补了值传递的不足，如果传递的数据量很大，直接复过去的话，会占用大量的内存空间，而引用传递就是将对象的地址值传递过去，函数接收的是原始值的首地址值。在方法的执行过程中，形参和实参的内容相同，指向同一块内存地址，也就是说操作的其实都是源数据，所以方法的执行将会影响到实际对象。 数组(Array)和列表(ArrayList)有什么区别？什么时候应该使用Array而不是ArrayList？1、存储内容比较：Array 数组可以包含基本类型和对象类型，ArrayList 却只能包含对象类型。Array 数组在存放的时候一定是同种类型的元素。ArrayList 就不一定了 。 2、空间大小比较：Array 数组的空间大小是固定的,所以需要事前确定合适的空间大小。ArrayList 的空间是动态增长的,而且，每次添加新的元素的时候都会检查内部数组的空间是否足够。 3.方法上的比较：ArrayList 方法上比 Array 更多样化，比如添加全部 addAll()、删除全部 removeAll()、返回迭代器 iterator() 等。 适用场景： 如果想要保存一些在整个程序运行期间都会存在而且不变的数据，我们可以将它们放进一个全局数组里， 但是如果我们单纯只是想要以数组的形式保存数据，而不对数据进行增加等操作，只是方便我们进行查找的话，那么，我们就选择 ArrayList。 如果我们需要对元素进行频繁的移动或删除，或者是处理的是超大量的数据，那么，使用 ArrayList 就真的不是一个好的选择，因为它的效率很低，使用数组进行这样的动作就很麻烦，那么，我们可以考虑选择 LinkedList。 你了解大O符号(big-O notation)么？你能给出不同数据结构的例子么？大O符号表示一个程序运行时所需要的渐进时间复杂度上界。 其函数表示是：对于函数f(n),g(n),如果存在一个常数c，使得f(n)&lt;=c*g(n),则f(n)=O(g(n)); 大O描述当数据结构中的元素增加时，算法的规模和性能在最坏情景下有多好。 大O还可以描述其它行为，比如内存消耗。因为集合类实际上是数据结构，因此我们一般使用大O符号基于时间，内存，性能选择最好的实现。大O符号可以对大量数据性能给予一个很好的说明。 String是最基本的数据类型吗?不是，是一个final修饰的java类 int 和 Integer 有什么区别1、Integer是int的包装类，int则是java的一种基本数据类型2、Integer变量必须实例化后才能使用，而int变量不需要3、Integer实际是对象的引用，当new一个Integer时，实际上是生成一个指针指向此对象；而int则是直接存储数据值4、Integer的默认值是null，int的默认值是0 String 和StringBuffer的区别String: 不可变的字符序列，若要向其中添加新字符需要创建一个新的String对象StringBuilder: 可变字符序列，支持向其中添加新字符（无需创建新对象）StringBuffer: 可以看作线程安全版的StringBuilder 我们在web应用开发过程中经常遇到输出某种编码的字符，如iso8859-1等，如何输出一个某种编码的字符串？123456789101112public String translate (String str) &#123; String tempStr = &quot;&quot;; try &#123; tempStr = new String(str.getBytes(&quot;ISO-8859-1&quot;), &quot;GBK&quot;); tempStr = tempStr.trim(); &#125;catch (Exception e) &#123; System.err.println(e.getMessage()); &#125; return tempStr; &#125; Java中的四种引用及其应用场景是什么？强引用: 通常我们使用new操作符创建一个对象时所返回的引用即为强引用 软引用: 若一个对象只能通过软引用到达，那么这个对象在内存不足时会被回收，可用于图片缓存中，内存不足时系统会自动回收不再使用的Bitmap 弱引用: 若一个对象只能通过弱引用到达，那么它就会被回收（即使内存充足），同样可用于图片缓存中，这时候只要Bitmap不再使用就会被回收 虚引用: 虚引用是Java中最“弱”的引用，通过它甚至无法获取被引用的对象，它存在的唯一作用就是当它指向的对象回收时，它本身会被加入到引用队列中，这样我们可以知道它指向的对象何时被销毁。 &amp;和&amp;&amp;的区别？Java中&amp;&amp;和&amp;都是表示与的逻辑运算符，都表示逻辑运输符and，当两边的表达式都为true的时候，整个运算结果才为true，否则为false。 &amp;&amp;的短路功能，当第一个表达式的值为false的时候，则不再计算第二个表达式；&amp;则两个表达式都执行。 &amp;可以用作位运算符，当&amp;两边的表达式不是Boolean类型的时候，&amp;表示按位操作 在Java中，如何跳出当前的多重嵌套循环？在Java中，要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号的break 语句，即可跳出外层循环。 12345678910111213141516ok: for(int i=0;i&lt;10;i++) &#123; for(int j=0;j&lt;10;j++) &#123; System.out.println(“i=” + i + “,j=” + j); if(j == 5) break ok; &#125; &#125; for(int i=0;i&lt;4;i++)&#123; for(int j=0;j&lt;5;j++)&#123; System.out.println(&quot;i=&quot;+i+&quot;; j=&quot;+j); if(j==3)&#123; i=4; break; &#125; &#125; &#125; 或者让外层的循环条件表达式的结果可以受到里层循环体代码的控制，例如，要在二维数组中查找到某个数字。 1234567891011int arr[][] = &#123;&#123;1,2,3&#125;,&#123;4,5,6,7&#125;,&#123;9&#125;&#125;;boolean found = false;for(int i=0;i&lt;arr.length &amp;&amp; !found;i++) &#123; for(int j=0;j&lt;arr[i].length;j++)&#123; System.out.println(“i=” + i + “,j=” + j); if(arr[i][j] == 5) &#123; found = true; break; &#125; &#125; &#125; 你能比较一下Java和JavaSciprt吗？1）基于对象和面向对象：Java是一种真正的面向对象的语言，即使是开发简单的程序，必须设计对象；JavaScript是种脚本语言，它可以用来制作与网络无关的，与用户交互作用的复杂软件。它是一种基于对象（Object-Based）和事件驱动（Event-Driven）的编程语言。因而它本身提供了非常丰富的内部对象供设计人员使用；2）解释和编译：Java 的源代码在执行之前，必须经过编译；JavaScript 是一种解释性编程语言，其源代码不需经过编译，由浏览器解释执行；3）强类型变量和类型弱变量：Java采用强类型变量检查，即所有变量在编译之前必须作声明；JavaScript中变量声明，采用其弱类型。即变量在使用前不需作声明，而是解释器在运行时检查其数据类型； 4）代码格式不一样。 简述正则表达式及其用途。在编写处理字符串的程序时，经常会有查找符合某些复杂规则的字符串的需要。正则表达式就是用于描述这些规则的工具。换句话说，正则表达式就是记录文本规则的代码。计算机处理的信息更多的时候不是数值而是字符串，正则表达式就是在进行字符串匹配和处理的时候最为强大的工具，绝大多数语言都提供了对正则表达式的支持。 Java中是如何支持正则表达式操作的？ava中的String类提供了支持正则表达式操作的方法，包括：matches()、replaceAll()、replaceFirst()、split()。此外，Java中可以用Pattern类表示正则表达式对象，它提供了丰富的API进行各种正则表达式操作。 12345678910111213141516面试题： - 如果要从字符串中截取第一个英文左括号之前的字符串，例如：北京市(朝阳区)(西城区)(海淀区)，截取结果为：北京市，那么正则表达式怎么写？import java.util.regex.Matcher;import java.util.regex.Pattern; class RegExpTest &#123; public static void main(String[] args) &#123; String str = &quot;北京市(朝阳区)(西城区)(海淀区)&quot;; Pattern p = Pattern.compile(&quot;.*?(?=\\\\()&quot;); Matcher m = p.matcher(str); if(m.find()) &#123; System.out.println(m.group()); 、 &#125; &#125;&#125; 请你说说Java和PHP的区别？PHP暂时还不支持像Java那样JIT运行时编译热点代码,但是PHP具有opcache机制,能够把脚本对应的opcode缓存在内存,PHP7中还支持配置opcache.file_cache导出opcode到文件.第三方的Facebook HHVM也支持JIT.另外PHP官方基于LLVM围绕opcache机制构建的Zend JIT分支也正在开发测试中.在php-src/Zend/bench.php测试显示,PHP JIT分支速度是PHP 5.4的10倍.PHP的库函数用C实现,而Java核心运行时类库(jdk/jre/lib/rt.jar,大于60MB)用Java编写(jdk/src.zip), 所以Java应用运行的时候,用户编写的代码以及引用的类库和框架都要在JVM上解释执行. Java的HotSpot机制,直到有方法被执行10000次才会触发JIT编译, 在此之前运行在解释模式下,以避免出现JIT编译花费的时间比方法解释执行消耗的时间还要多的情况. PHP内置模板引擎,自身就是模板语言.而Java Web需要使用JSP容器如Tomcat或第三方模板引擎. PHP也可以运行在多线程模式下,比如Apache的event MPM和Facebook的HHVM都是多线程架构.不管是多进程还是多线程的PHP Web运行模式,都不需要PHP开发者关心和控制,也就是说PHP开发者不需要写代码参与进程和线程的管理,这些都由PHP-FPM/HHVM/Apache实现.PHP-FPM进程管理和并发实现并不需要PHP开发者关心,而Java多线程编程需要Java开发者编码参与.PHP一个worker进程崩溃,master进程会自动新建一个新的worker进程,并不会导致PHP服务崩溃.而Java多线程编程稍有不慎(比如没有捕获异常)就会导致JVM崩溃退出.对于PHP-FPM和Apache MOD_PHP来说,服务进程常驻内存,但一次请求释放一次资源,这种内存释放非常彻底. PHP基于引用计数的GC甚至都还没发挥作用程序就已经结束了。 2、关键字介绍一下Syncronized锁，如果用这个关键字修饰一个静态方法，锁住了什么？如果修饰成员方法，锁住了什么？ 在synchronized里面，包含有三种常见的锁状态：对于普通的同步方法：锁是当前的对象对于静态函数的同步方法：锁是指引用当前类的class对象对于同步方法块的内容：锁是指Synchonized括号里配置的对象 介绍一下volatile？volatile作为java中的关键词之一，用以声明变量的值可能随时会被别的线程修改，使用volatile修饰的变量会强制将修改的值立即写入主存，主存中值的更新会使缓存中的值失效(非volatile变量不具备这样的特性，非volatile变量的值会被缓存，线程A更新了这个值，线程B读取这个变量的值时可能读到的并不是是线程A更新后的值)。volatile会禁止指令重排 volatile具有可见性、有序性，不具备原子性。 注意，volatile不具备原子性，这是volatile与java中的synchronized、java.util.concurrent.locks.Lock最大的功能差异，这一点在面试中也是非常容易问到的点 锁有了解嘛，说一下Synchronized和lockLock是一个接口，而synchronized是关键字。 synchronized会自动释放锁，而Lock必须手动释放锁。 Lock可以让等待锁的线程响应中断，而synchronized不会，线程会一直等待下去。 通过Lock可以知道线程有没有拿到锁，而synchronized不能。 Lock能提高多个线程读操作的效率。 synchronized能锁住类、方法和代码块，而Lock是块范围内的 讲一讲Java里面的final关键字怎么用的？(1)修饰类：表示该类不能被继承； (2)修饰方法：表示方法不能被重写； (3)修饰变量：表示变量只能赋值一次且赋值以后值不能被修改（常量） 3、面向对象wait方法底层原理object中的方法，可以暂停线程，期间会释放对象锁，不像sleep方法，线程休眠期依然持有锁，wait方法的线程，必须调用notify或notifyAll方法唤醒线程！ Java有哪些特性，举个多态的例子。继承、封装、多态。多态的主要特征就是父类引用指向子类对象，生活中的例子：Animal animal = new Dog(); String为啥不可变？string是final修饰，不可变，同时string底层是字符串数组也是final修饰，这样做首先是安全，比如hashset中用string做为键，不会出现string变化，导致违反唯一键。另外节约内存。 类和对象的区别1，类是一个抽象的概念，它不存在于现实中的时间/空间里，类只是为所有的对象定义了抽象的属性与行为。就好像“Person（人）”这个类，它虽然可以包含很多个体，但它本身不存在于现实世界上。 2，对象是类的一个具体。它是一个实实在在存在的东西。 3，类是一个静态的概念，类本身不携带任何数据。当没有为类创建任何对象时，类本身不存在于内存空间中。 4，对象是一个动态的概念。每一个对象都存在着有别于其它对象的属于自己的独特的属性和行为。对象的属性可以随着它自己的行为而发生改变。 请列举你所知道的Object类的方法。getClass():用于返回当前运行时对象的Class对象，使用了final关键字修饰，故不允许子类重写； equals():用于比较两个对象的地址是否相同，即两个引用是否指向同一个对象； clone():用于创建并返回当前对象的一份拷贝； toString():返回类的名字@实例的哈希码的16进制字符串； notify():唤醒等待队列中的其中一个线程； notifyAll():唤醒线程等待队列中的所有线程； wait(long timeout):让一个线程等待一段时间。 重载和重写的区别？相同参数不同返回值能重载吗？重载：同名不同参，参数的类型和个数没有具体的限制，一般构造方法使用的比较多，他展现的是编译时的多态性 重写：是对父类的方法重新进行定义在继承父类的方法的时候可以通过重写保证和定义特定于自己的行为，它展现的是运行时的多态性 返回值类型作为函数运行之后的一个状态，他是保持方法的调用者与被调用者进行通信的关键，并不能作为某个方法的标识，所以通过返回类型并不能区分重载的方法，应该根据所要区分的方法的方法名是否相同并且方法中所带的参数去区分 ”static”关键字是什么意思？Java中是否可以覆盖(override)一个private或者是static的方法？ “static”关键字表明一个成员变量或者是成员方法可以在没有所属的类的实例变量的情况下被访问。 Java中static方法不能被覆盖，因为方法覆盖是基于运行时动态绑定的，而static方法是编译时静态绑定的。static方法跟类的任何实例都不相关，所以概念上不适用。 java中也不可以覆盖private的方法，因为private修饰的变量和方法只能在当前类中使用，如果是其他的类继承当前类是不能访问到private变量或方法的，当然也不能覆盖。 String能继承吗？不能被继承，因为String类有final修饰符，而final修饰的类是不能被继承的。 StringBuffer和StringBuilder有什么区别，底层实现上呢？StringBuffer 与 StringBuilder 中的方法和功能完全是等价的， 只是StringBuffer 中的方法大都采用了 synchronized 关键字进行修饰，因此是线程安全的， 而 StringBuilder 没有这个修饰，可以被认为是线程不安全的。 在单线程程序下，StringBuilder效率更快，因为它不需要加锁，不具备多线程安全 而StringBuffer则每次都需要判断锁，效率相对更低 类加载机制，双亲委派模型，好处是什么？类加载，JVM第一次使用到这个类时需要对，这个类的信息进行加载。一个类只会加载一次，之后这个类的信息放在堆空间，静态属性放在方法区。JVM类加载器从上到下一共分为三类 启动类加载器(Bootstrap ClassLoader)：负责加载 JAVA_HOME\\lib 目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。 扩展类加载器(Extension ClassLoader)：负责加载 JAVA_HOME\\lib\\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。 应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。 当一个加载器不管是应用程序类加载器还是我们自定义的类加载器在进行类加载的时候它首先不会自己去加载，它首先会把加载任务委派给自己的父类加载器，比如现在有个类需要我们的自定义类加载器来加载，其实它首先会把它交给应用程序类加载器，应用程序类加载器又会把任务交给扩展类加载器，一直往上提交，直到启动类加载器。启动类加载器如果在自己的扫描范围内能找到类，它就会去加载，如果它找不到，它就会交给它的下一级子加载器去加载，以此类推，这就是双亲委派模型。为什么jdk里要提出双亲委派模型？ 可以保证我们的类有一个合适的优先级，例如Object类，它是我们系统中所有类的根类，采用双亲委派模型以后，不管是哪个类加载器来加载Object类，哪怕这个加载器是自定义类加载器，通过双亲委派模型，最终都是由启动类加载器去加载的，这样就可以保证Object这个类在程序的各个类加载器环境中都是同一个类。在虚拟机里觉得一个类是不是唯一有两个因素，第一个就是这个类本身，第二个就是加载这个类的类加载器，如果同一个类由不同的类加载器去加载，在虚拟机看来，这两个类是不同的类。 静态变量存在哪?静态变量在方法区的静态存储区，但方法区既可以在堆上又可以位于栈（not java栈）上，static 变量保存在 Class 实例的尾部。Class 对象存在堆中。 讲讲什么是泛型？泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？ 顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参）， 然后在使用/调用时传入具体的类型（类型实参）。 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中， 操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。 解释extends 和super 泛型限定符-上界不存下界不取extends 指定上界限，只能传入本类和子类super 指定下界限，只能传入本类和父类 是否可以在static环境中访问非static变量？这个要从java的内存机制去分析，首先当你New 一个对象的时候，并不是先在堆中为对象开辟内存空间，而是先将类中的静态方法（带有static修饰的静态函数）的代码加载到一个叫做方法区的地方，然后再在堆内存中创建对象。所以说静态方法会随着类的加载而被加载。当你new一个对象时，该对象存在于对内存中，this关键字一般指该对象，但是如果没有new对象，而是通过类名调用该类的静态方法也可以。 程序最终都是在内存中执行，变量只有在内存中占有一席之地时才会被访问，类的静态成员（变态和方法）属于类本身，在类加载的时候就会分配内存，可以通过类名直接去访问，非静态成员（变量和方法）属于类的对象，所以只有在类的对象禅师（创建实例）的时候才会分配内存，然后通过类的对象去访问。 在一个类的静态成员中去访问非静态成员之所以会出错是因为在类的非静态成员不存在的时候静态成员就已经存在了，访问一个内存中不存在的东西当然会出错。 那类是什么时候被加载呢？在需要调用的时候被加载 谈谈如何通过反射创建对象？方法1：通过类对象调用newInstance()方法，例如：String.class.newInstance()方法2：通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器（Constructor）对象并调用其newInstance()方法创建对象，例如：String.class.getConstructor(String.class).newInstance(“Hello”); Java支持多继承么？java不支持多继承，只支持单继承（即一个类只能有一个父类）。但是java接口支持多继承，即一个子接口可以有多个父接口。（接口的作用是用来扩展对象的功能，一个子接口继承多个父接口，说明子接口扩展了多个功能，当类实现接口时，类就扩展了相应的功能） 接口和抽象类的区别是什么？一 接口和抽象类的相似性 接口和抽象类都不能被实例化，它们都位于继承树的顶端，用于被其他类实现和继承。 接口和抽象类都可以包含抽象方法，实现接口或继承抽象类的普通子类都必须实现这些抽象方法。 二 接口和抽象类的区别 （不能为普通方法提供方法体）接口里只能包含抽象方法，静态方法和默认方法（加default），不能为普通方法提供方法实现，抽象类则完全可以包含普通方法，接口中的普通方法默认为抽象方法。 (public static final 赋值)抽象类中的成员变量可以是各种类型的，而接口中的成员变量只能是 public static final 类型的，并且必须赋值，否则通不过编译。 （是否有构造器）接口不能包含构造器，抽象类可以包含构造器，抽象类里的构造器并不是用于创建对象，而是让其子类调用这些构造器来完成属于抽象类的初始化操作。 （不能包含初始化块）接口里不能包含初始化块，但抽象类里完全可以包含初始化块。 （继承一个抽象类、多个接口）一个类只能继承一个抽象类，而一个类却可以实现多个接口。 Comparable和Comparator接口是干什么的？列出它们的区别。Comparable接口位于 java.lang包下，Comparator接口位于java.util包下。 Comparable: 内部比较器，一个类如果想要使用 Collections.sort(list) 方法进行排序，则需要实现该接口 Comparator: 外部比较器用于对那些没有实现Comparable接口或者对已经实现的Comparable中的排序规则不满意进行排序.无需改变类的结构，更加灵活。（策略模式） 面向对象的特征有哪些方面（1）继承：就是保留父类的属性，开扩新的东西。通过子类可以实现继承，子类继承父类的所有状态和行为，同时添加自身的状态和行为。 （2）封装：就是类的私有化。将代码及处理数据绑定在一起的一种编程机制，该机制保证程序和数据不受外部干扰。 （3）多态：是允许将父对象设置成为和一个和多个它的子对象相等的技术。包括重载和重写。重载为编译时多态，重写是运行时多态。 final, finally, finalize的区别。final 可以用来修饰类、方法、变量，分别有不同的意义，final 修饰的 class 代表不可以继承扩展，final 的变量是不可以修改的，而 final 的方法也是不可以重写的（override）。 finally 则是 Java 保证重点代码一定要被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭 JDBC 连接、保证 unlock 锁等动作。 finalize 是基础类 java.lang.Object 的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize 机制现在已经不推荐使用，并且在 JDK 9 开始被标记为 deprecated Overload和Override的区别。Overloaded的方法是否可以改变返回值的类型?方法的重写Override和重载Overload是Java多态性的不同表现。重写Override是父类与子类之间多态性的一种表现。重载Overload是一个类中多态性的一种表现。如果在子类中定义某方法与其父类有相同的名称和参数，那么我们说该方法被重写了。子类的对象使用这个方法时，将调用子类中的定义。对子类而言，父类中的定义如同被“屏蔽”了一样。关于重载，如果在一个类中定义了多个同名的方法，它们或有不同的参数个数或有不同的参数类型，也就是参数签名不同，这种情况出现方法的重载。重载的方法是可以改变返回值的类型。 每个重载的方法都必须有一个独一无二的参数类型列表。甚至参数顺序不同也足以区分两个方法，在区分重载方法时候，以类名和方法的形参作为标准，不以方法的返回值来区分。 Static Nested Class 和 Inner Class的不同Nested Class 一般是C++的说法，Inner Class 一般是JAVA的说法。Nested class分为静态Static nested class 的和非静态的 inner class,静态的Static nested class是不可以直接调用它的外部类enclosing class的，但是可以通过外部类的引用来调用，就像你在一个类中写了main方法一样。非静态类inner class 可以自由的引用外部类的属性和方法，但是它与一个实例绑定在了一起，不可以定义静态的属性、方法 。Inner Class（内部类）定义在类中的类。Nested Class（嵌套类）是静态（static）内部类。1. 要创建嵌套类的对象，并不需要其外围类的对象。 2. 不能从嵌套类的对象中访问非静态的外围类对象。 当一个对象被当作参数传递到一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这里到底是值传递还是引用传递?传递的是值，只不过这个值是引用的地址值，地址值指向对象，所以改变的对象的内容，地址并没有改变 Java的接口和C++的虚类的相同和不同处。C++虚类相当于java中的抽象类，与接口的不同处是： 1.一个子类只能继承一个抽象类（虚类），但能实现多个接口 2.一个抽象类可以有构造方法，接口没有构造方法 3.一个抽象类中的方法不一定是抽象方法，即其中的方法可以有实现（有方法体），接口中的方法都是抽象方法，不能有方法体，只有方法声明 4.一个抽象类可以是public、private、protected、default，接口只有public 5.一个抽象类中的方法可以是public、private、protected、default，接口中的方法只能是public和default修饰，实际上都是public的abstract方法 相同之处是： 都不能实例化。 JAVA语言如何进行异常处理，关键字：throws,throw,try,catch,finally分别代表什么意义？在try块中可以抛出异常吗？throws是获取异常throw是抛出异常try是将会发生异常的语句括起来，从而进行异常的处理，catch是如果有异常就会执行他里面的语句，而finally不论是否有异常都会进行执行的语句。 内部类可以引用他包含类的成员吗？有没有什么限制？当内部类为静态内部类时他只能调用外部类的静态方法。如果内部类为非静态内部类时则调用无限制。主要是编译时就会加载静态类，而非静态类在运行时才会加载。所以如果静态类部类无法调用非静态外部类 两个对象值相同(x.equals(y) == true)，但却可有不同的hash code说法是否正确？如果此对象重写了equals方法，那么可能出现这两个对象的equals相同，而hashcode不同。因此可以说它是对的。 但是，如果此对象继承Object，没有重写equals方法，那么就使用Object的equals方法，Object对象的equals方法默认是用==实现的，那么如果equals相同，hashcode一定相同。 如何通过反射获取和设置对象私有字段的值？getDeclaredField方法 并且要设置访问权限为true ，setAccessible(true) 谈一下面向对象的”六原则一法则”。单一职责原则，里氏替换原则，依赖倒置原则，开闭原则，接口隔离原则，合成聚合复用原则和迪米特法则 单一职责原则：一个类只做它该做的事情。(单一职责原则想表达的就是”高内聚”，写代码最终极的原则只有六个字”高内聚、低耦合”) 开闭原则：软件实体应当对扩展开放，对修改关闭。(在理想的状态下，当我们需要为一个软件系统增加新功能时，只需要从原来的系统派生出一些新类就可以，不需要修改原来的任何一行代码。要做到开闭有两个要点：①抽象是关键，一个系统中如果没有抽象类或接口系统就没有扩展点;②封装可变性，将系统中的各种可变因素封装到一个继承结构中，如果多个可变因素混杂在一起，系统将变得复杂而换乱) 依赖倒转原则：面向接口编程。(该原则说得直白和具体一些就是声明方法的参数类型、方法的返回类型、变量的引用类型时，尽可能使用抽象类型而不用具体类型，因为抽象类型可以被它的任何一个子类型所替代) 里氏替换原则：任何时候都可以用子类型替换掉父类型。(子类一定是增加父类的能力而不是减少父类的能力，因为子类比父类的能力更多，把能力多的对象当成能力少的对象来用当然没有任何问题。) 接口隔离原则：接口要小而专，绝不能大而全。(臃肿的接口是对接口的污染，既然接口表示能力，那么一个接口只应该描述一种能力，接口也应该是高度内聚的。Java中的接口代表能力、代表约定、代表角色，能否正确的使用接口一定是编程水平高低的重要标识。) 合成聚合复用原则：优先使用聚合或合成关系复用代码。(通过继承来复用代码是面向对象程序设计中被滥用得最多的东西，记住：任何时候都不要继承工具类，工具是可以拥有并可以使用的，而不是拿来继承的。) 迪米特法则：迪米特法则又叫最少知识原则，一个对象应当对其他对象有尽可能少的了解。(迪米特法则简单的说就是如何做到”低耦合”，门面模式和调停者模式就是对迪米特法则的践行。Java Web开发中作为前端控制器的Servlet或Filter不就是一个门面吗，浏览器对服务器的运作方式一无所知，但是通过前端控制器就能够根据你的请求得到相应的服务。调停者模式也可以举一个简单的例子来说明，例如一台计算机，CPU、内存、硬盘、显卡、声卡各种设备需要相互配合才能很好的工作。迪米特法则用通俗的话来将就是不要和陌生人打交道，如果真的需要，找一个自己的朋友，让他替你和陌生人打交道。) 请问Query接口的list方法和iterate方法有什么区别？对于Query接口的list()方法与iterate()方法来说，都可以实现获取查询的对象，但是list()方法返回的每个对象都是完整的（对象中的每个属性都被表中的字段填充上了），而iterator()方法所返回的对象中仅包含了主键值（标识符），只有当你对iterator中的对象进行操作时，Hibernate才会向数据库再次发送SQL语句来获取该对象的属性值。 Java中，什么是构造函数？什么是构造函数重载？什么是复制构造函数？当新对象被创建的时候，构造方法会被调用。每一个类都有构造方法。在程序员没有给类提供构造方法的情况下，Java编译器会为这个类创建一个默认的构造方法。Java中构造方法重载和方法重载很相似。可以为一个类创建多个构造方法。每一个构造方法必须有它自己唯一的参数列表。 Java不支持像C++中那样的复制构造方法，这个不同点是因为如果你不自己写构造方法的情况下，Java不会创建默认的复制构造方法。 hashCode()和equals()方法有什么联系？前提： 谈到hashCode就不得不说equals方法，二者均是Object类里的方法。由于Object类是所有类的基类，所以一切类里都可以重写这两个方法。 原则 1 ： 如果 x.equals(y) 返回 “true”，那么 x 和 y 的 hashCode() 必须相等 ； 原则 2 ： 如果 x.equals(y) 返回 “false”，那么 x 和 y 的 hashCode() 有可能相等，也有可能不等 ； 原则 3 ： 如果 x 和 y 的 hashCode() 不相等，那么 x.equals(y) 一定返回 “false” ； 原则 4 ： 一般来讲，equals 这个方法是给用户调用的，而 hashcode 方法一般用户不会去调用 ； 原则 5 ： 当一个对象类型作为集合对象的元素时，那么这个对象应该拥有自己的equals()和hashCode()设计，而且要遵守前面所说的几个原则。 4、集合Map和ConcurrentHashMap的区别？首先Map是接口，一般而言concurrentHashMap是线程安全的，具体实现在1.7采取的segment分段锁，有点类似于16个线程安全的hashtable组合成了一个concurrenthashmap，不同分段操作不需要上锁，同一个分段才需要上锁，读不上锁，写上锁。锁的粒度更加精细。而1.8采取的AQS和CAS来实现【用了不少volatile】。 hashMap内部具体如何实现的？HashMap的底层是基于数组+链接的一个复合数据结构,非同步的 允许null键值 继承于map接口来实现,通过put和get方法来进行数据的操作.数组被分为一个个的bucket.哈希值决定了键值对在数组中的位置.具有相同哈希值的键值对会组成链表,当链表长度超过阀值(8)的时候回触发树化,链表转换成红黑树. 如果hashMap的key是一个自定义的类，怎么办？没问题，但是最好要重写hashcode方法，否则可能会出现对象是equals的，但放入hashset时却作为不同对象的问题。 ArrayList和LinkedList的区别，如果一直在list的尾部添加元素，用哪个效率高？ArrayList 底层数据结构是一中线性的数据结构 ArrayList 可以理解为动态数组，它的容量能动态增长，该容量是指用来存储列表的数组的大小，随着向ArrayList中不断添加元素，其容量也自动增长， ArrayList 容许包括null在内所有的元素 ArrayList 是List接口的非同步实现 ArrayList 是有序 LinkedList 基于链表的list接口的非同步实现 LinkedList 是容许包括null在内的所有元素 LinkedList 是有序的 ArrayList 访问任意位置，效率高 LinkedList 两端数据操作效率高 HashMap底层，负载因子，为啥是2^n？HashMap为了存取高效，要尽量较少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现就在把数据存到哪个链表中的算法； 这个算法实际就是取模，hash%length，计算机中直接求余效率不如位移运算，源码中做了优化hash&amp;(length-1)， hash%length==hash&amp;(length-1)的前提是length是2的n次方； 为什么这样能均匀分布减少碰撞呢？2的n次方实际就是1后面n个0，2的n次方-1 实际就是n个1； 例如长度为9时候，3&amp;(9-1)=0 2&amp;(9-1)=0 ，都在0上，碰撞了； 例如长度为8时候，3&amp;(8-1)=3 2&amp;(8-1)=2 ，不同位置上，不碰撞； 其实就是按位“与”的时候，每一位都能 &amp;1 ，也就是和1111……1111111进行与运算 ConcurrentHashMap锁加在了哪些地方？1.7中不同的Segment，ConcurrentHashMap将数据分段，在读写的时候只加到相应的数据段上，这样在多线程的时候，可以读写其他段的数据，提高效率 1.8 中取消了segments字段，直接采用transient volatile HashEntry&lt;k,v&gt;[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。 TreeMap底层，红黑树原理？TreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树，这样就可以保证当需要快速检索指定节点 ArrayList是否会越界？会的，底层是数组实现，是数组就一定会有越界的问题存在 什么是TreeMap?TreeMap继承AbstractMap，实现NavigableMap、Cloneable、Serializable三个接口,能按自然顺序或自定义顺序遍历 ConcurrentHashMap的原理是什么？底层采用分段的数组+链表实现，线程安全通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁扩容：段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容 https://www.cnblogs.com/heyonggang/p/9112731.html https://www.cnblogs.com/banjinbaijiu/p/9147434.html Java集合类框架的基本接口有哪些？总共有两大接口：Collection 和Map ，一个元素集合，一个是键值对集合； 其中List和Set接口继承了Collection接口，一个是有序元素集合，一个是无序元素集合； 而ArrayList和 LinkedList 实现了List接口，HashSet实现了Set接口，这几个都比较常用； HashMap 和HashTable实现了Map接口，并且HashTable是线程安全的，但是HashMap性能更好； 为什么集合类没有实现Cloneable和Serializable接口？Cloneable.接口是用于浅克隆，而Serializable接口是用于深克隆，标识性接口，之所以用到克隆，有时需要把对象信息保存到本地磁盘，防止在传输时出现乱序，而那些容器没有这个必要，只是用来存储数据 什么是迭代器？迭代器是一种设计模式，它是一个对象，它可以遍历并选择序列中的对象，而开发人员不需要了解该序列的底层结构。迭代器通常被称为“轻量级”对象，因为创建它的代价小。Java中的Iterator功能比较简单，并且只能单向移动： (1) 使用方法iterator()要求容器返回一个Iterator。第一次调用Iterator的next()方法时，它返回序列的第一个元素。注意：iterator()方法是java.lang.Iterable接口,被Collection继承。 (2) 使用next()获得序列中的下一个元素。 (3) 使用hasNext()检查序列中是否还有元素。 (4) 使用remove()将迭代器新返回的元素删除。 Iterator是Java迭代器最简单的实现，为List设计的ListIterator具有更多的功能，它可以从两个方向遍历List，也可以从List中插入和删除元素。 Iterator和ListIterator的区别是什么？ iterator()方法在set和list接口中都有定义，但是ListIterator（）仅存在于list接口中（或实现类中）； ListIterator有add()方法，可以向List中添加对象，而Iterator不能 ListIterator和Iterator都有hasNext()和next()方法，可以实现顺序向后遍历，但是ListIterator有hasPrevious()和previous()方法，可以实现逆向（顺序向前）遍历。Iterator就不可以。 ListIterator可以定位当前的索引位置，nextIndex()和previousIndex()可以实现。Iterator没有此功能。 都可实现删除对象，但是ListIterator可以实现对象的修改，set()方法可以实现。Iierator仅能遍历，不能修改。 因为ListIterator的这些功能，可以实现对LinkedList等List数据结构的操作。其实，数组对象也可以用迭代器来实现。 快速失败(fail-fast)和安全失败(fail-safe)的区别是什么？Iterator的安全失败是基于对底层集合做拷贝，因此，它不受源集合上修改的影响。java.util包下面的所有的集合类都是快速失败的，而java.util.concurrent包下面的所有的类都是安全失败的。快速失败的迭代器会抛出ConcurrentModificationException异常，而安全失败的迭代器永远不会抛出这样的异常 https://blog.csdn.net/qq_31780525/article/details/77431970 HashMap和Hashtable有什么区别？线程安全性不同 https://blog.csdn.net/wangxing233/article/details/79452946 ArrayList,Vector,LinkedList的存储性能和特性是什么？ArrayList 和Vector他们底层的实现都是一样的，都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢。 Vector中的方法由于添加了synchronized修饰，因此Vector是线程安全的容器，但性能上较ArrayList差，因此已经是Java中的遗留容器。 LinkedList使用双向链表实现存储（将内存中零散的内存单元通过附加的引用关联起来，形成一个可以按序号索引的线性结构，这种链式存储方式与数组的连续存储方式相比，内存的利用率更高），按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。 Vector属于遗留容器（Java早期的版本中提供的容器，除此之外，Hashtable、Dictionary、BitSet、Stack、Properties都是遗留容器），已经不推荐使用，但是由于ArrayList和LinkedListed都是非线程安全的，如果遇到多个线程操作同一个容器的场景，则可以通过工具类Collections中的synchronizedList方法将其转换成线程安全的容器后再使用（这是对装潢模式的应用，将已有对象传入另一个类的构造器中创建新的对象来增强实现）。 Collection 和 Collections的区别。java.util.Collection 是一个集合框架的父接口。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式。 java.util.Collections 是一个包装类。它包含有各种有关集合操作的静态多态方法。此类不能实例化，就像一个工具类，服务于Java的Collection框架。他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。 List、Set、Map是否继承自Collection接口？List，Set是，Map不是 List、Map、Set三个接口存取元素时，各有什么特点？Set里面不允许有重复的元素， 存元素：add方法有一个boolean的返回值，当集合中没有某个元素，此时add方法可成功加入该元素时，则返回true；当集合含有与某个元素equals相等的元素时，此时add方法无法加入该元素，返回结果为false。 取元素：没法说取第几个，只能以Iterator接口取得所有的元素，再逐一遍历各个元素。 List表示有先后顺序的集合， 存元素：多次调用add(Object)方法时，每次加入的对象按先来后到的顺序排序，也可以插队，即调用add(int index,Object)方法，就可以指定当前对象在集合中的存放位置。 取元素：方法1：Iterator接口取得所有，逐一遍历各个元素 ​ 方法2：调用get(index i)来明确说明取第几个。 Map是双列的集合，存放用put方法:put(obj key,obj value)，每次存储时，要存储一对key/value，不能存储重复的key，这个重复的规则也是按equals比较相等。 取元素：用get(Object key)方法根据key获得相应的value。 ​ 也可以获得所有的key的集合，还可以获得所有的value的集合， ​ 还可以获得key和value组合成的Map.Entry对象的集合。 5、线程多线程中的i++线程安全吗？为什么？i++和++i都是i=i+1的意思，但是过程有些许区别：i++：先赋值再自加。（例如：i=1；a=1+i++；结果为a=1+1=2，语句执行完后i再进行自加为2）++i：先自加再赋值。（例如：i=1；a=1+++i；结果为a=1+（1+1）=3，i先自加为2再进行运算）但是在单独使用时没有区别：如for(int i=0;i&lt;10;i++）{ }和for(int i=0;i&lt;10;++i) { }没有区别。 i++和++i的线程安全分为两种情况：1、如果i是局部变量（在方法里定义的），那么是线程安全的。因为局部变量是线程私有的，别的线程访问不到，其实也可以说没有线程安不安全之说，因为别的线程对他造不成影响。2、如果i是全局变量（类的成员变量），那么是线程不安全的。因为如果是全局变量的话，同一进程中的不同线程都有可能访问到。 如果有大量线程同时执行i++操作，i变量的副本拷贝到每个线程的线程栈，当同时有两个线程栈以上的线程读取线程变量，假如此时是1的话，那么同时执行i++操作，再写入到全局变量，最后两个线程执行完，i会等于3而不会是2，所以，出现不安全性。 如何线程安全的实现一个计数器？Java 提供了一组atomic class来帮助我们简化同步处理。基本工作原理是使用了同步synchronized的方法实现了对一个long, integer, 对象的增、减、赋值（更新）操作. 多线程同步的方法synchronized关键字、wait和notify、重入锁、阻塞队列等 https://blog.csdn.net/scgyus/article/details/79499650 介绍一下生产者消费者模式？生产者消费者模式：通过一个容器来解决生产者和消费者的强耦合关系，生产者生成数据无需等待消费者索取，消费者无需直接索要数据。两者并不进行任何通讯，而是通过容器来进行操作作用：解耦、支持并发、支持忙闲不均。 线程，进程，然后线程创建有很大开销，怎么优化？线程池。 线程池运行流程，参数，策略线程池的工作流程：当一个任务通过execute(Runnable)方法欲添加到线程池时： 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue未满，那么任务被放入缓冲队列。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maximumPoolSize，那么通过handler所指定的策略来处理此任务。也就是：处理任务的优先级为：核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。 当线程池中的线程数量大于corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。 举个例子来说明一下线程池中的工作流程：假设队列大小为 10，corePoolSize 为 3，maximumPoolSize 为 6，那么当加入 20 个任务时，执行的顺序就是这样的：首先执行任务 1、2、3，然后任务 413 被放入队列。这时候队列满了，任务 14、15、16 会被马上执行，而任务 1720 则会抛出异常。最终顺序是：1、2、3、14、15、16、4、5、6、7、8、9、10、11、12、13。 7个参数： corePoolSize： 线程池维护线程的最少数量（也叫核心线程池数量） maximumPoolSize：线程池维护线程的最大数量 keepAliveTime： 线程池维护线程所允许的空闲时间 unit： 线程池维护线程所允许的空闲时间的单位 workQueue： 线程池所使用的缓冲队列 threadFactory：线程创建的工厂 handler： 线程池对拒绝任务的处理策略 任务拒绝策略：当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略： ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。 ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务 自定义策略，如果在使用过程中，Java对我们提供给我们的四种策略都不符合我们的要求，那我们可以自定义策略。 讲一下AQS吧。AQS是一个并发包的基础组件，用来实现各种锁，各种同步组件。它包含了state变量，加锁线程，等待队列并发中的核心组件。 AQS的实现依赖内部的同步队列（FIFO双向队列），如果当前线程获取同步状态失败，AQS会将该线程以及等待状态等信息构造成一个Node，将其加入同步队列的尾部，同时阻塞当前线程，当同步状态释放时，唤醒队列的头节点。 https://www.cnblogs.com/waterystone/p/4920797.html 创建线程的方法，哪个更好，为什么？需要从Java.lang.Thread类派生一个新的线程类，重载它的run()方法； 实现Runnalbe接口，重载Runnalbe接口中的run()方法。 实现Runnalbe接口更好，使用实现Runnable接口的方式创建的线程可以处理同一资源，从而实现资源的共享. Java中有几种方式启动一个线程？1、继承Thread类，新建一个当前类对象，并且运行其start()方法 2、实现Runnable接口，然后新建当前类对象，接着新建Thread对象时把当前类对象传进去，最后运行Thread对象的start()方法 3、实现Callable接口，新建当前类对象，在新建FutureTask类对象时传入当前类对象，接着新建Thread类对象时传入FutureTask类对象，最后运行Thread对象的start()方法 Java中有几种线程池？Java通过Executors提供四种线程池，分别为：newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 自定义线程池：通过修改五大核心参数来控制 线程池有什么好处？1、线程池的重用线程的创建和销毁的开销是巨大的，而通过线程池的重用大大减少了这些不必要的开销，当然既然少了这么多消费内存的开销，其线程执行速度也是突飞猛进的提升。2、控制线程池的并发数3、线程池可以对线程进行管理 线程池可以提供定时、定期、单线程、并发数控制等功能。比如通过ScheduledThreadPool线程池来执行S秒后，每隔N秒执行一次的任务。 如何理解Java多线程回调方法？所谓回调，就是客户程序C调用服务程序S中的某个方法A，然后S又在某个时候反过来调用C中的某个方法B，对于C来说，这个B便叫做回调方法。下面看一个实际例子来理解： 本示例设置一个提问者，一个回答者，而回答者需要回答提问者一个很深奥的问题时，这时需要很多时间去查找，提问者又开始做其他的事情， 等回答者找到答案后，再把答案告诉提问者。 概括的解释下线程的几种可用状态。新建状态(New)：当用new操作符创建一个线程时， 例如new Thread®，线程还没有开始运行，此时线程处在新建状态。 当一个线程处于新生状态时，程序还没有开始运行线程中的代码 就绪状态(Runnable)一个新创建的线程并不自动开始运行，要执行线程，必须调用线程的start()方法。当线程对象调用start()方法即启动了线程，start()方法创建线程运行的系统资源，并调度线程运行run()方法。当start()方法返回后，线程就处于就绪状态。处于就绪状态的线程并不一定立即运行run()方法，线程还必须同其他线程竞争CPU时间，只有获得CPU时间才可以运行线程。因为在单CPU的计算机系统中，不可能同时运行多个线程，一个时刻仅有一个线程处于运行状态。因此此时可能有多个线程处于就绪状态。对多个处于就绪状态的线程是由Java运行时系统的线程调度程序(thread scheduler)来调度的。 运行状态(Running)当线程获得CPU时间后，它才进入运行状态，真正开始执行run()方法. 阻塞状态(Blocked)线程运行过程中，可能由于各种原因进入阻塞状态:1&gt;线程通过调用sleep方法进入睡眠状态；2&gt;线程调用一个在I/O上被阻塞的操作，即该操作在输入输出操作完成之前不会返回到它的调用者；3&gt;线程试图得到一个锁，而该锁正被其他线程持有；4&gt;线程在等待某个触发条件；… 所谓阻塞状态是正在运行的线程没有运行结束，暂时让出CPU，这时其他处于就绪状态的线程就可以获得CPU时间，进入运行状态。 5.死亡状态(Dead)有两个原因会导致线程死亡：1) run方法正常退出而自然死亡，2) 一个未捕获的异常终止了run方法而使线程猝死。为了确定线程在当前是否存活着（就是要么是可运行的，要么是被阻塞了），需要使用isAlive方法。如果是可运行或被阻塞，这个方法返回true； 如果线程仍旧是new状态且不是可运行的， 或者线程死亡了，则返回false 同步方法和同步代码块的区别是什么？语法不同。 同步块需要注明锁定对象，同步方法默认锁定this。 在静态方法中，都是默认锁定类对象。 在考虑性能方面，最好使用同步块来减少锁定范围提高并发效率。 在监视器(Monitor)内部，是如何做线程同步的？程序应该做哪种级别的同步？在 java 虚拟机中, 每个对象( Object 和 class )通过某种逻辑关联监视器,每个监视器和一个对象引用相关联, 为了实现监视器的互斥功能, 每个对象都关联着一把锁. 一旦方法或者代码块被 synchronized 修饰, 那么这个部分就放入了监视器的监视区域, 确保一次只能有一个线程执行该部分的代码, 线程在获取锁之前不允许执行该部分的代码 另外 java 还提供了显式监视器( Lock )和隐式监视器( synchronized )两种锁方案 sleep() 和 wait() 有什么区别？相同点:都可让线程处于冻结状态.不同点:1.wait()可以设置线程冻结的时间,也可以不设置冻结的时间,而sleep()必须设置冻结的时间.2.wait()释放cpu资源,同时也释放了锁,而sleep()释放cpu资源,但不释放锁. 同步和异步有何异同，在什么情况下分别使用他们？举例说明。同步异步：指的是需不需要等待返回结果； 同步：需要不断轮询数据是否准备好了，或者一直在等待数据准备好 异步：发送一个请求就立即返回，然后去干别的事情，当数据准备号了会通知进行相关处理。(同步的实时性比较号，异步的并发性能比较号)阻塞和非阻塞：是指需不需要阻塞线程 阻塞：当前线程不执行别的事情，一直再等待 非阻塞：当前线程可以干别事情，间隔一段时间检查一下上次的数据有没有准备好； 设计4个线程，其中两个线程每次对j增加1，另外两个线程对j每次减少1。使用内部类实现线程，对j增减的时候没有考虑顺序问题。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465链接：https://www.nowcoder.com/questionTerminal/8db05d0b47044b3f9605860451d63d25来源：牛客网class Resource&#123; private int j=0; //j增加1 public synchronized void add()&#123; j++; System.out.println(Thread.currentThread().getName()+&quot;...add...&quot;+&quot;目前j的值为：&quot;+j); &#125; //j减少1 public synchronized void des()&#123; j--; System.out.println(Thread.currentThread().getName()+&quot;-des-&quot;+&quot;目前j的值为：&quot;+j); &#125;&#125; class FourThreadTest&#123; //创建Resource对象 private Resource resource = new Resource(); public static void main(String[] args) &#123; FourThreadTest fourThread = new FourThreadTest(); fourThread.test(); &#125; public void test()&#123; for(int i=0;i&lt;2;i++)&#123; new Thread(new Runnable()&#123; public void run()&#123; while(true)&#123; try &#123; Thread.sleep((long)(Math.random()*1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; resource.add(); &#125; &#125; &#125;).start(); new Thread(new Runnable()&#123; public void run()&#123; while(true)&#123; try &#123; Thread.sleep((long)(Math.random()*1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; resource.des(); &#125; &#125; &#125;).start(); &#125; &#125;&#125; 启动一个线程是用run()还是start()?start（）； 请说出你所知道的线程同步的方法1 同步方法 2 同步块 3 wait 和 notify 4 volatile 5 Lock : ReentrantLock 6局部变量比如ThreadLocal 7 blockqueue stop()和suspend()方法为何不推荐使用？stop会导致不安全，为啥呢，如果在同步块执行一半时，stop来了，后面还没执行完呢，锁没了，线程退出了，别的线程又可以操作你的数据了，所以就是线程不安全了。 suspend会导致死锁，因为挂起后，是不释放锁的，别人也就阻塞着，如果没人唤醒，那就一直死锁。 线程的sleep()方法和yield()方法有什么区别？1.sleep()方法给其他线程机会不考虑线程的优先级别，而yield()方法只会给相同运行级别或更高运行级别的线程运行2.线程执行sleep()方法就会进入阻塞状态，执行yield()方法会转入就绪状态3.sleep()方法声明抛出InterruptException，而yield（）没有声明任何异常4.sleep（）方法比yield方法具有更好的移植性 当一个线程进入一个对象的synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B？不能。其它线程只能访问该对象的非同步方法，同步方法则不能进入。因为非静态方法上的synchronized修饰符要求执行方法时要获得对象的锁，如果已经进入A方法说明对象锁已经被取走，那么试图进入B方法的线程就只能在等锁池（注意不是等待池哦）中等待对象的锁。 请说出与线程同步以及线程调度相关的方法。-wait()：使一个线程处于等待（阻塞）状态，并且释放所持有的对象的锁； -sleep()：使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要处理InterruptedException异常； -notify()：唤醒一个处于等待状态的线程，当然在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且与优先级无关； -notityAll()：唤醒所有处于等待状态的线程，该方法并不是将对象的锁给所有线程，而是让它们竞争，只有获得锁的线程才能进入就绪状态； 什么是线程池（thread pool）？线程池就是用来存放已经创建过的线程的容器，有任务时直接从线程池里获取，可以节省时间。 如何保证线程安全？线程安全：线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。 线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据。如何保证呢：1、使用线程安全的类；2、使用synchronized同步代码块，或者用Lock锁；由于线程安全问题，使用synchronized同步代码块 原理：当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。 另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。3、多线程并发情况下，线程共享的变量改为方法局部级变量 如何处理项目的高并发、大数据1.HTML静态化2.文件服务器3.负载均衡4.反向代理5.动静分离6.数据库sql优化7.缓存8.数据库读写分离9.数据库活跃数据分离10.批量读取和延迟修改11.数据库集群和库表散列 6、锁讲一下非公平锁和公平锁在reetrantlock里的实现。非公平锁: 当线程争夺锁的过程中，会先进行一次CAS尝试获取锁，若失败，则进入acquire(1)函数，进行一次tryAcquire再次尝试获取锁，若再次失败，那么就通过addWaiter将当前线程封装成node结点加入到Sync队列，这时候该线程只能乖乖等前面的线程执行完再轮到自己了。 公平锁: 当线程在获取锁的时候，会先判断Sync队列中是否有在等待获取资源的线程。若没有，则尝试获取锁，若有，那么就那么就通过addWaiter将当前线程封装成node结点加入到Sync队列中 讲一下synchronized，可重入怎么实现。每个锁关联一个线程持有者和一个计数器。当计数器为0时表示该锁没有被任何线程持有，那么任何线程都都可能获得该锁而调用相应方法。当一个线程请求成功后，JVM会记下持有锁的线程，并将计数器计为1。此时其他线程请求该锁，则必须等待。而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增。当线程退出一个synchronized方法/块时，计数器会递减，如果计数器为0则释放该锁。 对象锁（synchronized method{}）和类锁（static sychronized method{}）的区别对象锁也叫实例锁，对应synchronized关键字，当多个线程访问多个实例时，它们互不干扰，每个对象都拥有自己的锁，如果是单例模式下，那么就是变成和类锁一样的功能。对象锁防止在同一个时刻多个线程访问同一个对象的synchronized块。如果不是同一个对象就没有这样子的限制。 类锁对应的关键字是static sychronized，是一个全局锁，无论多少个对象否共享同一个锁（也可以锁定在该类的class上或者是classloader对象上），同样是保障同一个时刻多个线程同时访问同一个synchronized块，当一个线程在访问时，其他的线程等待。 什么是死锁(deadlock)？死锁 :是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。原因：（1） 因为系统资源不足。（2） 资源分配不当等。（3） 进程运行推进顺序不合适。如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。（1） 互斥条件：一个资源每次只能被一个进程使用。（2） 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。（3） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。（4） 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。死锁的解除与预防：理解了死锁的原因，尤其是产生死锁的四个必要条件，就可以最大可能地避免、预防和解除死锁。所以，在系统设计、进程调度等方面注意如何不让这四个必要条件成立，如何确定资源的合理分配算法，避免进程永久占据系统资源。此外，也要防止进程在处于等待状态的情况下占用资源。因此，对资源的分配要给予合理的规划。 其中最简单的方法就是线程都是以同样的顺序加锁和释放锁，也就是破坏了第四个条件。 如何确保N个线程可以访问N个资源同时又不导致死锁？四个条件是死锁的必要条件，只要破坏其中任意一个条件，就可以避免死锁，其中最简单的就是破环循环等待条件。按同一顺序访问对象，加载锁，释放锁。 请你简述synchronized和java.util.concurrent.locks.Lock的异同？相同点：两者都是用来实现对某个资源的同步。两者区别如下：(1) 用法不一样。synchronized可以用于修饰方法，也可以用在代码块中。Lock需要指定起始和终点位置，一般放在try-finally结构中，try开始执行lock方法，finally中执行unlock方法。synchronized是托管给JVM执行的，Lock是通过代码执行的。(2) 性能不一样。在资源竞争不激烈情况下，synchronized的性能比Lock好，而在资源竞争激烈时，synchronized的性能下降很快，而Lock基本保持不变。 锁机制不一样。synchronized获得锁和释放锁都是在块结构中，获取多个锁时必须以相反顺序释放，并且自动释放锁。Lock需要开发人员手动释放锁，并且放在finally中。 7、JDKJava中的LongAdder和AtomicLong的区别JDK1.8引入了LongAdder类。CAS机制就是，在一个死循环内，不断尝试修改目标值，直到修改成功。如果竞争不激烈，那么修改成功的概率就很高，否则，修改失败的的概率就很高，在大量修改失败时，这些原子操作就会进行多次循环尝试，因此性能就会受到影响。 结合ConcurrentHashMap的实现思想，应该可以想到对一种传统AtomicInteger等原子类的改进思路。虽然CAS操作没有锁，但是像减少粒度这种分离热点的思想依然可以使用。将AtomicInteger的内部核心数据value分离成一个数组，每个线程访问时，通过哈希等算法映射到其中一个数字进行计数，而最终的计数结果，则为这个数组的求和累加。热点数据value被分离成多个单元cell，每个cell独自维护内部的值，当前对象的实际值由所有的cell累计合成，这样热点就进行了有效的分离，提高了并行度。 JDK和JRE的区别是什么？1.JDK JDK是Java Development Kit的缩写，是Java的开发工具包，主要包含了各种类库和工具，当然也包含了另外一个JRE.。那么为什么要包含另外一个JRE呢？而且&lt;JDK安装目录&gt;/JRE/bin目录下，包含有server一个文件夹~包含一个jvm.dll，这说明JDK提供了一个虚拟机。 另外，JDK的bin目录下有各种Java程序需要用到的命令，与JRE的bin目录最明显的区别就是JDK文件下才有javac，这一点很好理解，因为JRE只是一个运行环境而已，与开发无关。正因为如此，具备开发功能的JDK所包含的JRE下才会同时有server的JVM，而仅仅作为运行环境的JRE下，只需要server的jvm.dll就够了。 注意：JDK所提供的运行环境和工具度需要进行环境变量的配置以后，才能使用，最主要的配置就是把&lt;JDK安装目录&gt;/bin目录设置为Path环境变量值的一部分。 2.JRE JRE是Java Runtime Environment的缩写，是Java程序的运行环境。既然是运行，当然要包含JVM，也就是所谓的Java虚拟机，还有所以的Java类库的class文件，都在lib目录下，并且都打包成了jar。 至于在Windows上的虚拟机是哪个文件呢？就是&lt;JRE安装目录&gt;/bin/server中的jvm.dll。 另外，安装JRE的时候安装程序会自动把JRE的java.exe添加到了系统变量中。系统变量Path的最前面有%SystemRoot%system32;%SystemRoot%;这样的配置，那样到Windows/system32目录下main去看看，会发现一个java.exe文件。这样就无需配置环境变量，也可以运行Java程序了。 3.JDK与JRE的区别 JDK是Java的开发工具，它不仅提供了Java程序运行所需的JRE，还提供了一系列的编译，运行等工具，如javac，java，javaw等。JRE只是Java程序的运行环境，它最核心的内容就是JVM（Java虚拟机）及核心类库。 4.Tomcat和JDK是什么关系 tomcat是java的web项目运行容器之一；jdk是java运行环境。也就是说java没有jdk肯定是没法编译运行的。java运行必须依赖于jdk环境，但是不一定要用tomcat容器，如WebLogic、WebSphere等都是可以的。 8、反射反射的实现与作用它允许程序在运行时进行自我检查，同时也允许对其内部成员进行操作。反射机制提供的功能主要有：得到一个对象所属的类；获取一个类的所有成员变量和方法；在运行时创建对象；在运行时调用对象的方法 https://blog.csdn.net/SongYuxinIT/article/details/81872066 9、JVMJVM回收算法和回收器，CMS采用哪种回收算法，怎么解决内存碎片问题？标记清除算法、复制算法、标记整理 CMS采用标记清除 https://www.cnblogs.com/aspirant/p/8662690.html 类加载过程类加载过程分为：加载——验证——准备——解析——初始化加载：又分为三个阶段：（1）通过一个类的全限定名来获取定义此类的二进制字节流；（2）将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； （3）在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 JVM分区Java堆，虚拟机栈，本地方法栈，方法区，程序计数器 eden区，survial区?新生代有一个较大的Eden区和两个较小的Survivor区组成，绝大多数新创建的对象都是在Eden区分配的，其中大多数对象很快消亡。Eden是一块连续的内存，所以分配内存的速度很快。 首先，Eden满时，进行一次minor gc ，将存活 的对象复制到 To Survivor（以下简称To），清除Eden消亡的对象。当Eden再次满时，进行minor gc,To中能够晋升的移动到老年代，存活的对象复制到From。 清空Eden和To，如此切换（默认15），将存活的对象迁移到老年代 JAVA虚拟机的作用?解释运行字节码程序消除平台相关性。 jvm将java字节码解释为具体平台的具体指令。一般的高级语言如要在不同的平台上运行，至少需要编译成不同的目标代码。而引入JVM后，Java语言在不同平台上运行时不需要重新编译。Java语言使用模式Java虚拟机屏蔽了与具体平台相关的信息，使得Java语言编译程序只需生成在Java虚拟机上运行的目标代码（字节码），就可以在多种平台上不加修改地运行。Java虚拟机在执行字节码时，把字节码解释成具体平台上的机器指令执行。 GC中如何判断对象需要被回收？gc用到垃圾回收机制算法，判断是否是垃圾，从而进行回收。 引用可达法法，程序运行从开始，每次引用对象，都将对引用的对象进行连接起来，到最后形成一张网，没有在这张网上的对象则被认为是垃圾对象。 还有引用计数法，对于对象的引用，每引用一次计数器加一，引用失败，计数器减一，当计数器一段时间为0，则可以被认为是垃圾。 JAVA虚拟机中，哪些可作为ROOT对象？Java程序是怎么运行的？1）加载类定义进入方法区2）初始化类定义中的静态成员变量 &amp; 常量3）执行入口类的main方法 在后续程序的执行过程会创建一些对象，并调用一些方法。每调用一个方法，都会进行压栈，如果是Java方法，则压虚拟机栈；如果是native方法，则压本地方法栈。在方法中也会创建一些对象，每创建一个对象，就会在堆中占据一块内存。在方法中也会调用对象的方法。在方法中也会调用类的静态成员变量 or 常量。 所以在进行垃圾回收的时候，可以从几个地方开始下手，然后一路往前走，最终没有触及的对象，都将被回收调。这些root对象有哪些呢？1）虚拟机栈中引用的对象2）本地方法栈中引用的对象3）方法区静态变量引用的对象 4）方法去常量引用的对象 JVM内存模型是什么？https://blog.csdn.net/u011972171/article/details/80398771 jvm是如何实现线程？.使用内核线程实现内核线程(Kernel-Level Thread, KLT)就是直接由操作系统内核支持的线程。用户态和内核态切换消耗内核资源2 使用用户线程实现3 用户线程加轻量级进程混合实现 java虚拟机的多线程是通过线程轮流切换分配处理执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条程序中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。 简单点说，对于单核处理器，是通过快速切换线程执行指令来达到多线程的，因为单核处理器同时只能处理一条指令，只是这种切换速度很快，我们根本不会感知到。 jvm最大内存限制多少这个如果不使用-xx:Xmx -xx:Xms -xx:Permsize -xx:MaxPermsize参数进行设置的话，应该和不同版本的jdk的jvm最大内存限制相关吧。 1234567公司 JVM版本 最大内存(兆)client 最大内存(兆)serverSUN 1.5.x 1492 1520SUN 1.5.5(Linux) 2634 2660SUN 1.4.2 1564 1564SUN 1.4.2(Linux) 1900 1260IBM 1.4.2(Linux) 2047 N/ABEA JRockit 1.5 (U3) 1909 1902 什么是Java虚拟机？为什么Java被称作是“平台无关的编程语言”？一、什么是java虚拟机？java虚拟机是执行字节码文件（.class）的虚拟机进程。java源程序（.java）被编译器编译成字节码文件（.class）。然后字节码文件，将由java虚拟机，解释成机器码（不同平台的机器码不同）。利用机器码操作硬件和操作系统二、为什么java被称为平台无关的编程语言？ 因为不同的平台装有不同的JVM，它们能够将相同的.class文件，解释成不同平台所需要的机器码。正是因为有JVM的存在，java被称为平台无关的编程语言 描述一下JVM加载class文件的原理机制?委托机制，可见性机制，单一性机制 父类静态代码块，子类静态代码块，父类构造代码块和构造方法，子类构造代码块和构造方法。 启动类加载器，扩展类加载器，应用程序类加载器。双亲委派模型 10、GCjava中内存泄露是啥，什么时候出现内存泄露？java导致内存泄露的原因很明确：长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景。1.集合类，集合类仅仅有添加元素的方法，而没有相应的删除机制，导致内存被占用。这一点其实也不明确，这个集合类如果仅仅是局部变量，根本不会造成内存泄露，在方法栈退出后就没有引用了会被jvm正常回收。而如果这个集合类是全局性的变量（比如类中的静态属性，全局性的map等即有静态引用或final一直指向它），那么没有相应的删除机制，很可能导致集合所占用的内存只增不减，因此提供这样的删除机制或者定期清除策略非常必要。2.单例模式。不正确使用单例模式是引起内存泄露的一个常见问题，单例对象在被初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部对象的引用，那么这个外部对象将不能被jvm正常回收，导致内存泄露 minor gc如果运行的很频繁，可能是什么原因引起的，minor gc如果运行的很慢，可能是什么原因引起的?minor gc运行的很频繁可能是什么原因引起的？1、 产生了太多朝生夕灭的对象导致需要频繁minor gc 2、 新生代空间设置的比较小 minor gc运行的很慢有可能是什么原因引起的？1、 新生代空间设置过大。 2、 对象引用链较长，进行可达性分析时间较长。 3、 新生代survivor区设置的比较小，清理后剩余的对象不能装进去需要移动到老年代，造成移动开销。 4、 内存分配担保失败，由minor gc转化为full gc 5、 采用的垃圾收集器效率较低，比如新生代使用serial收集器 阐述GC算法标记清除算法：首先先标记，然后统一把标记的对象依次清除，缺点是CPU消耗大，极易出现内存碎片，所以一般用于老年代。复制算法：把内存区域分成俩块，每次只使用其中一块，然后把还存活的对象放在另一块中，清空原先的块，这样的话不会出现内存碎片。新生代常用的。复制整理：指针碰撞，将使用过的对象移动到内存的一段，不用的放在另一端。分代收集：根据不同代的区别，使用符合不同代的算法。 简单来说minorGC发生在新生代，频繁而且需要开销小，所以采取复制算法。老年代：对象相较于新生代gc不频繁且对象少，采取标记清除或者标记整理算法。 GC是什么? 为什么要有GC?Java GC（Garbage Collection，垃圾收集，垃圾回收）机制，是Java与C++/C的主要区别之一，在使用JAVA的时候，一般不需要专门编写内存回收和垃圾清理代 码。这是因为在Java虚拟机中，存在自动内存管理和垃圾清扫机制。 电脑的内存大小的不变的，当我们使用对象的时候，如使用New关键字的时候，就会在内存中生产一个对象，但是我们在使用JAVA开发的时候，当一个对象使用完毕之后我们并没有手动的释放那个对象所占用的内存，就这样在使用程序的过程中，对象越来越多，当内存存放不了这么多对象的时候，电脑就会崩溃了，JAVA为了解决这个问题就推出了这个自动清除无用对象的功能，或者叫机制，这就是GC 垃圾回收的优点和原理。并考虑2种回收机制由于有个垃圾回收机制，java中的对象不再有“作用域”的概念，只有对象的引用才有作用域。垃圾回收可以有效的防止内存泄漏，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低级别的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收，java语言没有提供释放已分配内存的显示操作方法。 回收机制有分代复制垃圾回收和标记垃圾回收、增量垃圾回收 java中会存在内存泄漏吗，请简单描述。java中的内存泄露的情况：长生命周期的对象持有短生命周期对象的引用就很可能发生内存泄露，尽管短生命周期对象已经不再需要，但是因为长生命周期对象持有它的引用而导致不能被回收，这就是java中内存泄露的发生场景，通俗地说，就是程序员可能创建了一个对象，以后一直不再使用这个对象，这个对象却一直被引用，即这个对象无用但是却无法被垃圾回收器回收的，这就是java中可能出现内存泄露的情况，例如，缓存系统，我们加载了一个对象放在缓存中(例如放在一个全局map对象中)，然后一直不再使用它，这个对象一直被缓存引用，但却不再被使用。检查java中的内存泄露，一定要让程序将各种分支情况都完整执行到程序结束，然后看某个对象是否被使用过，如果没有，则才能判定这个对象属于内存泄露。 如果一个外部类的实例对象的方法返回了一个内部类的实例对象，这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持久外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露 内存泄露的另外一种情况：当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露 https://blog.csdn.net/coodlong/article/details/50836613 垃圾回收器的基本原理是什么？垃圾回收器可以马上回收内存吗？有什么办法主动通知虚拟机进行垃圾回收？（垃圾回收）垃圾回收器是一个级别很低的线程,它通过不定时监测程序使用的内存中被占用的动态分配的内存内的对象是否还存在它的引用来判断是否该回收那个内存单元,如果不存在则回收,否则相反，并不是只要监测到就会回收的,因为垃圾回收器线程的低级别,所以当另一个级别比它高的线程跟他同时竞争运行时间时,前者优先运行,我们通过Thread或者继承Runnable的线程都级别都比它高,所以你无法知道垃圾回收器何时回收,System.gc()只是建议垃圾回收器进行回收处理,调用它并不能保证它回立即回收, 11、IO和NIO、AIOIO的基本常识1.同步用户进程触发IO操作并等待或者轮询的去查看IO操作是否完成2.异步用户触发IO操作以后,可以干别的事，IO操作完成以后再通知当前线程继续处理3.阻塞当一个线程调用 read() 或 write()时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务4.非阻塞当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞 IO 的空闲时间用于在其他通道上执行 IO 操作，所以单独的线程可以管理多个输入和输出通道。 BIO，NIO，AIO可以简述如下：BIO是同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。NIO是同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。AIO是异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理。 BIO、NIO、AIO适用场景分析：BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高NIO方式适用于连接数目多且连接比较短的架构，可充分利用服务器资源 AIO方式使用于连接数目多且连接比较长的架构，充分调用OS参与并发操作 怎么打印日志？使用log4j和slf4j实现日志打印 运行时异常与一般异常有何异同？异常表示程序运行过程中可能出现的非正常状态，运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误。java编译器要求方法必须声明抛出可能发生的非运行时异常，但是并不要求必须声明抛出未被捕获的运行时异常。 error和exception有什么区别?Exception： 1．可以是可被控制(checked) 或不可控制的(unchecked)。 2．表示一个由程序员导致的错误。 3．应该在应用程序级被处理。 Error： 1．总是不可控制的(unchecked)。 2．经常用来用于表示系统错误或低层资源的错误。 3．如何可能的话，应该在系统级被捕捉。 https://blog.csdn.net/min996358312/article/details/65729617 给我一个你最常见到的runtime exception1，当试图将对象强制转换为不是实例的子类时，抛出该异常（ClassCastException) 12Object x = new Integer(0);System.out.println((String)x); 2，一个整数“除以零”时，抛出ArithmeticException异常。 1int a=5/0; 3, 当应用程序试图在需要对象的地方使用 null 时，抛出NullPointerException异常 123String s=null;int size=s.size();4, 指示索引或者为负，或者超出字符串的大小，抛出StringIndexOutOfBoundsException异常 1&quot;hello&quot;.indexOf(-1); 5，如果应用程序试图创建大小为负的数组，则抛出NegativeArraySizeException异常。 1String[] ss=new String[-1]; Java中的异常处理机制的简单原理和应用。java异常处理机制可以从两个方面来描述，当一个java程序违反了java语义的时候，JVM虚拟机就会抛出一个异常，比如说当遇到的null的时候，会抛出一个nullpointExcepiton，当遇到下标越界的时候就会抛出indexoutofbroundsException，除此之外，程序员还可以自定义异常，去拓展这种语义的检查，并在合适的时机，通过throw关键字抛出异常。其中，try{}是监控的代码语句块，catch{}是处理异常，finally{}语句块无论是否发生异常都会执行 java中有几种类型的流？JDK为每种类型的流提供了一些抽象类以供继承，请说出他们分别是哪些类？Java中的流分为两种，一种是字节流，另一种是字符流，分别由四个抽象类来表示（每种流包括输入和输出两种所以一共四个）:InputStream，OutputStream，Reader，Writer。Java中其他多种多样变化的流均是由它们派生出来的. 什么是java序列化，如何实现java序列化？序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化（将对象转换成二进制）。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间，序列化是为了解决在对对象流进行读写操作时所引发的问题。把对象转换为字节序列的过程称为对象的序列化，把字节序列恢复为对象的过程称为对象的反序列化。 序列化的实现：将需要被序列化的类实现Serializable接口，该接口没有需要实现的方法，implements Serializable只是为了标注该对象是可被序列化的，然后使用一个输出流(如：FileOutputStream)来构造一个ObjectOutputStream(对象流)对象，接着，使用ObjectOutputStream对象的writeObject(Object obj)方法就可以将参数为obj的对象写出(即保存其状态)，要恢复的话则用输入流。 https://blog.csdn.net/qq_35868412/article/details/86978141 运行时异常与受检异常有什么区别？受检查异常表示程序可以处理的异常，如果抛出异常的方法本身不能处理它，那么方法调用者应该去处理它，从而使程序恢复运行，不至于终止程序。例如，喷墨打印机在打印文件时，如果纸用完或者墨水用完，就会暂停打印，等待用户添加打印纸或更换墨盒，如果用户添加了打印纸或更换了墨盒，就能继续打印。 运行时异常表示无法让程序恢复运行的异常，导致这种异常的原因通常是由于执行了错误操作。一旦出现了错误操作，建议终止程序，因此Java编译器不检查这种异常。 算法与数据结构1、哈希hashset存的数是有序的吗？hashset继承的是set接口，set是无序集合 Object作为HashMap的key的话，对Object有什么要求吗？Hashmap不允许有重复的key，所以要重写它的hashcode和equal方法，以便确认key是否重复 一致性哈希算法在日常工作中，经常有这样的情况，我们需要做hash，散列开数据到不同的区或节点。目标要的结果是要均匀散列，避免某个节点积累大量的数据，出现倾斜情况。比如目前有N台机器，过来的数据key，需要做散列key%N,分发到对应的节点上。 一致性哈希算法原理：为了解决hash倾斜难题，一致性算法是这样的，节点和节点形成一个环。比如A-&gt;B-&gt;C-&gt;A，这样一个环。数字hash后落在环上，而不是落到某个node。比如落在a~b node之间，通过顺时针转，这个数字归b节点管。但是如果节点很少，同样容易出现倾斜，负载不均衡问题。所以一致性哈希算法，引入了虚拟节点，在整个环上，均衡增加若干个节点。比如a1，a2，b1，b2，c1，c2，a1和a2都是属于A节点的。 通过让闭环上的节点增加，来平衡各个节点散列的值。 什么是hashmap?HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。 HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。 HashMap 的实现不是同步的，这意味着它不是线程安全的。它的key、value都可以为null。此外，HashMap中的映射不是有序的。 Java中的HashMap的工作原理是什么？hashmap是一个key-value键值对的数据结构，从结构上来讲在jdk1.8之前是用数组加链表的方式实现，jdk1.8加了红黑树，hashmap数组的默认初始长度是16，hashmap数组只允许一个key为null，允许多个value为nullhashmap的内部实现，hashmap是使用数组+链表+红黑树的形式实现的，其中数组是一个一个Node[]数组，我们叫他hash桶数组，它上面存放的是key-value键值对的节点。HashMap是用hash表来存储的，在hashmap里为解决hash冲突，使用链地址法，简单来说就是数组加链表的形式来解决，当数据被hash后，得到数组下标，把数据放在对应下表的链表中。然后再说一下hashmap的方法实现put方法，put方法的第一步，就是计算出要put元素在hash桶数组中的索引位置，得到索引位置需要三步，去put元素key的hashcode值，高位运算，取模运算，高位运算就是用第一步得到的值h，用h的高16位和低16位进行异或操作，第三步为了使hash桶数组元素分布更均匀，采用取模运算，取模运算就是用第二步得到的值和hash桶数组长度-1的值取与。这样得到的结果和传统取模运算结果一致，而且效率比取模运算高jdk1.8中put方法的具体步骤，先判断hashmap是否为空，为空的话扩容，不为空计算出key的hash值i，然后看table[i]是否为空，为空就直接插入，不为空判断当前位置的key和table[i]是否相同，相同就覆盖，不相同就查看table[i]是否是红黑树节点，如果是的话就用红黑树直接插入键值对，如果不是开始遍历链表插入，如果遇到重复值就覆盖，否则直接插入，如果链表长度大于8，转为红黑树结构，执行完成后看size是否大于阈值threshold，大于就扩容，否则直接结束get方法就是计算出要获取元素的hash值，去对应位置取即可。扩容机制，hashmap的扩容中主要进行两部，第一步把数组长度变为原来的两倍，第二部把旧数组的元素重新计算hash插入到新数组中，在jdk1.8时，不用重新计算hash，只用看看原来的hash值新增的一位是零还是1，如果是1这个元素在新数组中的位置，是原数组的位置加原数组长度，如果是零就插入到原数组中。扩容过程第二部一个非常重要的方法是transfer方法，采用头插法，把旧数组的元素插入到新数组中。3.hashmap大小为什么是2的幂次方在计算插入元素在hash桶数组的索引时第三步，为了使元素分布的更加均匀，用取模操作，但是传统取模操作效率低，然后优化成h&amp;(length-1)，设置成2幂次方，是因为2的幂次方-1后的值每一位上都是1，然后与第二步计算出的h值与的时候，最终的结果只和key的hashcode值本身有关，这样不会造成空间浪费并且分布均匀，如果不是2的幂次方如果length不为2的幂，比如15。那么length-1的2进制就会变成1110。在h为随机数的情况下，和1110做&amp;操作。尾数永远为0。那么0001、1001、1101等尾数为1的位置就永远不可能被entry占用。这样会造成浪费，不随机等问题。 hashCode()和equals()方法的重要性体现在什么地方？比如Java中HashMap使用hashcode()和equals()来确定键值对的索引，当根据键获取值的时候也会用到这两个方法。如果没有正确使用这两个方法，两个不同的键可能会有相同的hash值，因此，可能会被集合认定为是相等的。而且，这两个方法也会用来发现重复元素。所以，这两个的实现对HashMap的精确性和正确性是至关重要的。 2、树说一下B+树和B-树？m 阶的 B+ 树和 B- 树主要区别有三：（ 1 ）有 n 棵子树的结点中含有 n （ B- 树中 n-1 ）个关键字； （ 2 ） B+ 树叶子结点包含了全部关键字信息，及指向含关键字记录的指针，且叶子结点本身依关键字大小自小到大顺序链接； （ 3 ） B+ 树的非终端结点可以看成是索引部分，结点中只含其子树（根结点）中最大（或最小）关键字。 B+ 树的查找既可以顺序查找，也可以随机查找， B- 只能顺序查找。 怎么求一个二叉树的深度?手撕代码?1.后序遍历，最长栈长即为树的深度2.递归，最后比较即可3.遍历求层，层次即为深度 算法题：二叉树层序遍历，进一步提问：要求每层打印出一个换行符只需要在普通的BST基础上增加一个判断当前queue中数量的size即可，每个size就代表当前层的节点数量 https://www.jianshu.com/p/582d42dc8129 二叉树任意两个节点之间路径的最大长度https://blog.csdn.net/patkritLee/article/details/52162806 https://blog.csdn.net/liuyi1207164339/article/details/50917503 如何实现二叉树的深度？1234567891011121314151617181920212223242526static class TreeNode &#123; int val; TreeNode left; TreeNode right; public TreeNode(int val) &#123; this.val = val; &#125; &#125; /** * 递归求深度 * @param root * @return */ public static int treeDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; // 计算左子树的深度 int left = treeDepth(root.left); // 计算右子树的深度 int right = treeDepth(root.right); // 树root的深度=路径最长的子树深度 + 1 return left &gt;= right ? (left + 1) : (right + 1); &#125; 如何打印二叉树每层的节点？123456789101112131415161718192021222324/**思路是用arraylist模拟一个队列来存储相应的TreeNode*/public class Solution &#123; public ArrayList&lt;Integer&gt; PrintFromTopToBottom(TreeNode root) &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); ArrayList&lt;TreeNode&gt; queue = new ArrayList&lt;&gt;(); if (root == null) &#123; return list; &#125; queue.add(root); while (queue.size() != 0) &#123; TreeNode temp = queue.remove(0); if (temp.left != null)&#123; queue.add(temp.left); &#125; if (temp.right != null) &#123; queue.add(temp.right); &#125; list.add(temp.val); &#125; return list; &#125;&#125; TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？TreeSet要求存放的对象所属的类必须实现Comparable接口，该接口提供了比较元素的compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap要求存放的键值对映射的键必须实现Comparable接口从而根据键对元素进行排序。Collections工具类的sort方法有两种重载的形式，第一种要求传入的待排序容器中存放的对象必须实现Comparable接口以实现元素的比较；第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator接口的子类型（需要重写compare方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java中对函数式编程的支持） 3、遍历编程题：写一个函数，找到一个文件夹下所有文件，包括子文件夹https://blog.csdn.net/qq_38977097/article/details/88853568 1234567891011121314151617181920212223import java.io.File;public class Main &#123; public static void main(String[] args) &#123; File file = new File(&quot;D:\\\\360Downloads&quot;); walk(file); &#125; private static void walk(File file) &#123; if(file != null)&#123; if(file.isDirectory())&#123; // 列出全部的文件 File f[] = file.listFiles(); if(f != null) for(int i = 0; i &lt; f.length; i++) //递归调用自身 walk(f[i]); &#125;else&#123; // 输出路径 System.out.println(file); &#125; &#125; &#125; 二叉树 Z 字型遍历12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.util.ArrayList;import java.util.*;/*public class TreeNode &#123; int val = 0; TreeNode left = null; TreeNode right = null; public TreeNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ArrayList&lt;ArrayList&lt;Integer&gt; &gt; Print(TreeNode pRoot) &#123; int layer =1; Stack&lt;TreeNode&gt; s1 = new Stack&lt;TreeNode&gt;(); Stack&lt;TreeNode&gt; s2 = new Stack&lt;TreeNode&gt;(); ArrayList&lt;ArrayList&lt;Integer&gt;&gt; list = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if(pRoot == null ) return list; s1.push(pRoot); while(!s1.isEmpty() || !s2.isEmpty())&#123; if(layer%2!=0)&#123; ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;(); while(!s1.isEmpty())&#123; TreeNode node = s1.pop(); if(node != null)&#123; temp.add(node.val); System.out.print(node.val + &quot; &quot;); s2.push(node.left); s2.push(node.right); &#125; &#125; if(!temp.isEmpty())&#123; list.add(temp); layer++; System.out.println(); &#125; &#125; else&#123; ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;(); while(!s2.isEmpty())&#123; TreeNode node = s2.pop(); if(node != null)&#123; temp.add(node.val); System.out.print(node.val + &quot; &quot;); s1.push(node.right); s1.push(node.left); &#125; &#125; if(!temp.isEmpty())&#123; list.add(temp); layer++; System.out.println(); &#125; &#125; &#125; return list; &#125;&#125; 4、链表反转单链表1234567891011121314151617181920212223242526272829/*public class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125;&#125;*/public class Solution &#123; public ListNode ReverseList(ListNode head) &#123; if(head==null) return null; if(head.next==null) return head; ListNode p = head.next; head.next=null; while(p!=null)&#123; ListNode val=p.next; //head.next=null; p.next=head; head=p; p=val; &#125; return head; &#125;&#125; 随机链表的复制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/*public class RandomListNode &#123; int label; RandomListNode next = null; RandomListNode random = null; RandomListNode(int label) &#123; this.label = label; &#125;&#125;*/public class Solution &#123; public RandomListNode Clone(RandomListNode pHead) &#123; if(pHead == null) &#123; return null; &#125; RandomListNode currentNode = pHead; //1、复制每个结点，如复制结点A得到A1，将结点A1插到结点A后面； while(currentNode != null)&#123; RandomListNode cloneNode = new RandomListNode(currentNode.label); RandomListNode nextNode = currentNode.next; currentNode.next = cloneNode; cloneNode.next = nextNode; currentNode = nextNode; &#125; currentNode = pHead; //2、重新遍历链表，复制老结点的随机指针给新结点，如A1.random = A.random.next; while(currentNode != null) &#123; currentNode.next.random = currentNode.random==null?null:currentNode.random.next; currentNode = currentNode.next.next; &#125; //3、拆分链表，将链表拆分为原链表和复制后的链表 currentNode = pHead; RandomListNode pCloneHead = pHead.next; while(currentNode != null) &#123; RandomListNode cloneNode = currentNode.next; currentNode.next = cloneNode.next; cloneNode.next = cloneNode.next==null?null:cloneNode.next.next; currentNode = currentNode.next; &#125; return pCloneHead; &#125;&#125; 链表-奇数位升序偶数位降序-让链表变成升序https://www.cnblogs.com/DarrenChan/p/8764608.html bucket如果用链表存储，它的缺点是什么？不支持随机访问，查找的时间复杂度是O(n) 如何判断链表检测环https://blog.csdn.net/yangruxi/article/details/80333000 1234567891011121314151617public static boolean isLoop(Node head) &#123; boolean flag = false; Node slow = head; Node fast = head; while(fast != null &amp;&amp; fast.next !=null) &#123; fast = fast.next.next; slow = slow.next; if(fast == slow) &#123; flag = true; break; &#125; &#125; if(fast == null || fast.next ==null) &#123; flag = false; &#125; return flag; &#125; 5、数组寻找一数组中前K个最大的数https://blog.csdn.net/zhou15755387780/article/details/81318105 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111package com.Test; import java.util.ArrayList;import java.util.Arrays;import java.util.List; //给定一个长度为n的数组，寻找其中最大的k个数public class FindKthElements &#123; //算法一：排序，时间复杂度O(nlogn)，空间复杂度O(1) public ArrayList&lt;Integer&gt; findKthElements(int[] arr, int k) &#123; ArrayList&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if(arr.length &lt;= 0 || arr == null || arr.length &lt; k) &#123; return res; &#125; Arrays.sort(arr); for(int i = arr.length - 1;i &gt; arr.length - 1 - k;i --) &#123; res.add(arr[i]); &#125; return res; &#125; //算法二；前面k个数都比后面的数的最大值要大，则前面k个数就是最大的k个，时间复杂度O(k*(n-k))，空间复杂度O(1) public ArrayList&lt;Integer&gt; findKthElements2(int[] arr, int k) &#123; ArrayList&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if(arr.length &lt;= 0 || arr == null || arr.length &lt; k) &#123; return res; &#125; for(int i = 0;i &lt; k;i ++) &#123; int maxValueIndex = this.getMaxValueIndex(arr, k); if(arr[maxValueIndex] &gt; arr[i]) &#123; int temp = arr[maxValueIndex]; arr[maxValueIndex] = arr[i]; arr[i] = temp; &#125; &#125; for(int i = 0;i &lt; k;i ++) &#123; res.add(arr[i]); &#125; return res; &#125; //选择排序：选出最大值的下标 public int getMaxValueIndex(int[] arr, int k) &#123; int maxValueIndex = k; for(int i = k + 1;i &lt; arr.length;i ++) &#123; if(arr[i] &gt; arr[maxValueIndex]) &#123; maxValueIndex = i; &#125; &#125; return maxValueIndex; &#125; //算法三：构建大顶堆，然后调整k次，得到最大的k个数。时间复杂度(k+1)O(nlogn)，空间复杂度O(1) public ArrayList&lt;Integer&gt; findKthElements3(int[] arr, int k) &#123; ArrayList&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if(arr.length &lt;= 0 || arr == null || arr.length &lt; k) &#123; return res; &#125; //构建大顶堆 int len = arr.length; for(int i = len / 2;i &lt; len;i ++) &#123; heapSort(arr, i, len); &#125; //调整k次大顶堆 for(int i = arr.length - 1;i &gt; arr.length - 1 - k;i --) &#123; //交换最大的值到底部 int temp = arr[i]; arr[i] = arr[0]; arr[0] = temp; res.add(arr[i]); heapSort(arr, 0, i); &#125; return res; &#125; public void heapSort(int[] arr, int start, int len) &#123; int parent = start; int leftChild = parent * 2 + 1; int parentValue = arr[parent]; while(leftChild &lt; len) &#123; int rightChild = leftChild + 1; if(rightChild &lt; len &amp;&amp; arr[leftChild] &lt; arr[rightChild]) &#123; //在左右孩子里选一个较大的出来 leftChild = rightChild; &#125; if(parentValue &gt; arr[leftChild]) &#123; break; &#125; arr[parent] = arr[leftChild]; parent = leftChild; leftChild = parent * 2 + 1; &#125; arr[parent] = parentValue; &#125; public static void main(String[] args) &#123; int[] arr = &#123;9,4,5,8,2&#125;; FindKthElements fke = new FindKthElements(); List&lt;Integer&gt; res = fke.findKthElements3(arr, 3); System.out.println(res); &#125;&#125; 求一个数组中连续子向量的最大和123456789101112public class Solution &#123; public int FindGreatestSumOfSubArray(int[] array) &#123; int res=array[0]; int max=array[0]; for(int i=1;i&lt;array.length;i++)&#123; max=Math.max(max+array[i],array[i]); res=Math.max(res,max); &#125; return res; &#125;&#125; 找出数组中和为S的一对组合，找出一组就行123456789101112131415161718192021222324public class NumComberAll &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub int a[] = &#123;2,3,3,2,2,4,1,4,-2,5,1&#125;; String b = &quot;&quot;; fun(a, b, 11, 0, 5); &#125; //递归搜索 public static void fun(int a[],String b, int length, int i, int s) &#123; String temp = b; if(i&gt;=length) return; //输出 if(s==0) System.out.println(temp); //不取a[i] fun(a,temp, length, i+1, s); //取a[i] temp=temp+a[i]; fun(a,temp, length, i+1, s-a[i]); &#125;&#125; 一个数组，除一个元素外其它都是两两相等，求那个元素?1234567int singleNumber(int A[], int n) &#123; int num=0; for(int i=0;i&lt;n;i++)&#123; num=num^A[i]; &#125; return num;&#125; 算法题：将一个二维数组顺时针旋转90度，说一下思路。https://blog.csdn.net/peach90/article/details/40422097 6、排序排序算法知道哪些，时间复杂度是多少，解释一下快排？直接插入排序，选择排序，冒泡排序：O(n*n) ，快速排序，归并排序，堆排序：O(nlog2n)， 希尔排序：O(n√n) ，基数排序：O(d(r+n))， 快速排序：每次选择一个枢纽值，比它大的放在右边，比它小的放在左边，每一趟排序都会使一个数放到最终的位置。 如何得到一个数据流中的中位数？1234567891011121314151617181920212223242526272829303132333435private int count = 0;private PriorityQueue&lt;Integer&gt; minHeap = new PriorityQueue&lt;&gt;();private PriorityQueue&lt;Integer&gt; maxHeap = new PriorityQueue&lt;Integer&gt;(15, new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o2 - o1; &#125;&#125;); public void Insert(Integer num) &#123; if (count %2 == 0) &#123;//当数据总数为偶数时，新加入的元素，应当进入小根堆 //（注意不是直接进入小根堆，而是经大根堆筛选后取大根堆中最大元素进入小根堆） //1.新加入的元素先入到大根堆，由大根堆筛选出堆中最大的元素 maxHeap.offer(num); int filteredMaxNum = maxHeap.poll(); //2.筛选后的【大根堆中的最大元素】进入小根堆 minHeap.offer(filteredMaxNum); &#125; else &#123;//当数据总数为奇数时，新加入的元素，应当进入大根堆 //（注意不是直接进入大根堆，而是经小根堆筛选后取小根堆中最大元素进入大根堆） //1.新加入的元素先入到小根堆，由小根堆筛选出堆中最小的元素 minHeap.offer(num); int filteredMinNum = minHeap.poll(); //2.筛选后的【小根堆中的最小元素】进入大根堆 maxHeap.offer(filteredMinNum); &#125; count++;&#125; public Double GetMedian() &#123; if (count %2 == 0) &#123; return new Double((minHeap.peek() + maxHeap.peek())) / 2; &#125; else &#123; return new Double(minHeap.peek()); &#125;&#125; 堆排序的原理是什么？堆是一个完全二叉树，如果按照层序遍历结果存储为数组，下标为i且根节点i=0，则满足Key[i]&gt;=Key[2i+1]&amp;&amp;Key[i]&gt;=key[2i+2]的称为大根堆，即根结点大于子结点，堆顶为最大值。 堆排序第一步建堆，即将输入序列看作是层序遍历结果，然后按顺序写成完全二叉树的形式。第二步调整堆，即从最后一个非叶结点开始调整，它的数组下标为最后一个数的下标-1之后除以2，保证这个结点比子结点大。然后下标减一继续调整，交换结点之后的孩子结点有可能不满足堆的性质，继续调整直到下标为0，这里有递归和非递归两种方法。 堆排序就是根据前边建好的堆先取出根结点和最后一个结点交换，然后对前边len-1个结点进行堆调整，再取出根结点和倒数第二个结点交换，对前边len-2个结点堆调整，以此类推直到所有结点都取出。 heapAdjust函数可看做每次都从当前结点走到叶子节点，数高度为log(n+1)向上取整，所以复杂度可视为O(logn)，简单起见，不必考虑到底是从根节点到达叶结点还是从中间某节点到达叶结点。建堆时调用heapAdjust函数n/2次，排序时调用heapAdjust函数n-1次，得到三种情况下的复杂度都是O(logn)* (n/2)+O(logn)*(n-1)，化简为O(nlogn)。空间复杂度O(1)。是不稳定的排序 归并排序的原理是什么？归并排序是一种递归算法，不断将列表拆分为一半，如果列表为空或有一个项，则按定义进行排序。如果列表有多个项，我们分割列表，并递归调用两个半部分的合并排序。一旦对两半排序完成，获取两个较小的排序列表并将它们组合成单个排序的新列表的过程 如何用java写一个冒泡排序？https://www.jianshu.com/p/f31de0e89f7e 123456789101112public static void bubbleSort(int[] arr) &#123; int temp = 0; for (int i = arr.length - 1; i &gt; 0; --i) &#123; // 每次需要排序的长度 for (int j = 0; j &lt; i; ++j) &#123; // 从第一个元素到第i个元素 if (arr[j] &gt; arr[j + 1]) &#123; temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125;&#125; 7、堆与栈heap和stack有什么区别。要点：堆：顺序随意 栈：后进先出(Last-In/First-Out) 1.堆栈空间分配 ①栈（操作系统）：由操作系统自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。 ②堆（操作系统）： 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收，分配方式倒是类似于链表。 2.堆栈缓存方式 ①栈使用的是一级缓存， 他们通常都是被调用时处于存储空间中，调用完毕立即释放。 ②堆则是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定（并不是一旦成为孤儿对象就能被回收）。所以调用这些对象的速度要相对来得低一些。 3.堆栈数据结构区别 ①堆（数据结构）：堆可以被看成是一棵完全二叉树树，如：堆排序。 ②栈（数据结构）：一种先进后出的数据结构。 解释内存中的栈(stack)、堆(heap)和静态区(static area)的用法。堆区:专门用来保存对象的实例(new 创建的对象和数组)，实际上也只是保存对象实例的属性值，属性的类型和对象本身的类型标记等，并不保存对象的方法（方法是指令，保存在Stack中） 1.存储的全部是对象，每个对象都包含一个与之对应的class的信息。(class的目的是得到操作指令)2.jvm只有一个堆区(heap)被所有线程共享，堆中不存放基本类型和对象引用，只存放对象本身.3.一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。栈区:对象实例在Heap 中分配好以后，需要在Stack中保存一个4字节的Heap内存地址，用来定位该对象实例在Heap 中的位置，便于找到该对象实例。1.每个线程包含一个栈区，栈中只保存基础数据类型的对象和自定义对象的引用(不是对象)，对象都存放在堆区中2.每个栈中的数据(原始类型和对象引用)都是私有的，其他栈不能访问。3.栈分为3个部分：基本类型变量区、执行环境上下文、操作指令区(存放操作指令)。4.由编译器自动分配释放 ，存放函数的参数值，局部变量的值等．静态区/方法区:1.方法区又叫静态区，跟堆一样，被所有的线程共享。方法区包含所有的class和static变量。2.方法区中包含的都是在整个程序中永远唯一的元素，如class，static变量。3.全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 8、队列什么是Java优先级队列(Priority Queue)？PriorityQueue是一个基于优先级堆的无界队列。它的元素是按照自然顺序排序的。在创建元素的时候，我们给它一个一个负责排序的比较器。PriorityQueue不允许null值，因为 它们没有自然排序，或者说没有任何相关联的比较器。最后PriorityQueue不是线程安全的，出对和入队的时间复杂度都是O(log(n)) 9、高级算法题目：Design and implement a data structure for Least Frequently Used (LFU) cache. It should support the following operations: get and put.get(key) - Get the value (will always be positive) of the key if the key exists in the cache, otherwise return -1.put(key, value) - Set or insert the value if the key is not already present. When the cache reaches its capacity, it should invalidate the least frequently used item before inserting a new item. For the purpose of this problem, when there is a tie (i.e., two or more keys that have the same frequency), the least recently used key would be evicted.Could you do both operations in O(1) time complexity?123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103class LFUCache &#123; class Node &#123; int key, val, freq; Node prev, next; public Node(Node prev, int key, int val, Node next) &#123; this.prev = prev; this.key = key; this.val = val; this.next = next; freq = 1; &#125; &#125; Map&lt;Integer, Node&gt; nodes, heads; Node head, tail; int cap; public LFUCache(int capacity) &#123; nodes = new HashMap(); heads = new HashMap(); head = new Node(null, 0, 0, null); tail = new Node(head, 0, 0, null); head.next = tail; cap = capacity; &#125; private void pushNode(int key, int value) &#123; Node prev = heads.containsKey(1) ? heads.get(1) : tail; Node newNode = new Node(prev.prev, key, value, prev); newNode.next.prev = newNode; newNode.prev.next = newNode; heads.put(1, newNode); nodes.put(key, newNode); &#125; private void popNode() &#123; Node remove = tail.prev; tail.prev = tail.prev.prev; tail.prev.next = tail; nodes.remove(remove.key); if(heads.get(remove.freq) == remove) heads.remove(remove.freq); &#125; private void updateAndMoveNode(int key) &#123; Node node = nodes.get(key); node.prev.next = node.next; node.next.prev = node.prev; if(heads.containsKey(node.freq + 1)) &#123; if(heads.get(node.freq) == node) &#123; if(node.next == tail || node.next.freq != node.freq) heads.remove(node.freq); else heads.put(node.freq, node.next); &#125; node.freq++; node.next = heads.get(node.freq); node.prev = heads.get(node.freq).prev; heads.get(node.freq).prev.next = node; heads.get(node.freq).prev = node; heads.put(node.freq, node); &#125; else &#123; if(heads.get(node.freq) == node) &#123; if(node.next == tail || node.next.freq != node.freq) heads.remove(node.freq); else heads.put(node.freq, node.next); node.freq++; heads.put(node.freq, node); node.prev.next = node; node.next.prev = node; &#125; else &#123; node.next = heads.get(node.freq); node.prev = heads.get(node.freq).prev; heads.get(node.freq).prev.next = node; heads.get(node.freq).prev = node; node.freq++; heads.put(node.freq, node); &#125; &#125; &#125; public int get(int key) &#123; if(!nodes.containsKey(key)) return -1; updateAndMoveNode(key); return nodes.get(key).val; &#125; public void put(int key, int value) &#123; if(cap == 0) return; if(!nodes.containsKey(key)) &#123; if(nodes.size() == cap) popNode(); pushNode(key, value); &#125; else &#123; nodes.get(key).val = value; updateAndMoveNode(key); &#125; &#125;&#125; id全局唯一且自增，如何实现？id type primary key auto_increament 如何设计算法压缩一段URL？常用的url压缩算法是短地址映射法。具体步骤是： ① 将长网址用md5算法生成32位签名串，分为4段,，每段8个字符； ② 对这4段循环处理，取每段的8个字符, 将他看成16进制字符串与0x3fffffff(30位1)的位与操作，超过30位的忽略处理； ③ 将每段得到的这30位又分成6段，每5位的数字作为字母表的索引取得特定字符，依次进行获得6位字符串； ④ 这样一个md5字符串可以获得4个6位串，取里面的任意一个就可作为这个长url的短url地址。 为什么要设计后缀表达式，有什么好处？https://blog.csdn.net/xiazdong/article/details/7272693 后缀表达式的特点就是计算机运算非常方便，需要用到栈；计算机处理过程只需要顺序读入，如果遇到数字，则放入栈中，如果是运算符，则将两个栈中数字取出进行运算； LRU算法的实现原理？https://blog.csdn.net/elricboa/article/details/78847305 LRU算法的设计原则是：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小。也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰。 设计模式1、结构型模式java中有哪些代理模式？https://blog.csdn.net/gdutxiaoxu/article/details/81394050 如何实现动态代理https://blog.csdn.net/HEYUTAO007/article/details/49738887 jdk动态代理是由java内部的反射机制来实现的，cglib动态代理底层则是借助asm来实现的。 IO流熟悉吗，用的什么设计模式？https://blog.csdn.net/yjw123456/article/details/80094801 即装饰模式和适配器模式。 2、创建型模式介绍一下单例模式？懒汉式的单例模式如何实现单例？https://blog.csdn.net/mbh12333/article/details/82258455 3、行为型模式介绍一下策略模式？https://blog.csdn.net/qq_22314145/article/details/82664481 策略模式定义了算法族，分别封装起来，让他们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。 一般情况下我们是将一种行为写成一个类方法，比如计算器类中有加、减、乘、除四种方法，而策略模式则是将每一种算法都写成一个类，然后动态的选择使用哪一个算法 设计模式了解哪些，手写一下观察者模式？https://blog.csdn.net/liuguangxu1988/article/details/82055853 4、模式汇总说说你所熟悉或听说过的j2ee中的几种常用模式?及对设计模式的一些看法j2ee常用的设计模式？说明工厂模式。 Java中的23种设计模式： Factory（工厂模式）， Builder（建造模式）， Factory Method（工厂方法模式）， Prototype（原始模型模式），Singleton（单例模式）， Facade（门面模式）， Adapter（适配器模式）， Bridge（桥梁模式）， Composite（合成模式）， Decorator（装饰模式）， Flyweight（享元模式）， Proxy（代理模式）， Command（命令模式）， Interpreter（解释器模式）， Visitor（访问者模式）， Iterator（迭代子模式）， Mediator（调停者模式）， Memento（备忘录模式）， Observer（观察者模式）， State（状态模式）， Strategy（策略模式）， Template Method（模板方法模式）， Chain Of Responsibleity（责任链模式） 工厂模式：工厂模式是一种经常被使用到的模式，根据工厂模式实现的类可以根据提供的数据生成一组类中某一个类的实例，通常这一组类有一个公共的抽象父类并且实现了相同的方法，但是这些方法针对不同的数据进行了不同的操作。首先需要定义一个基类，该类的子类通过不同的方法实现了基类中的方法。然后需要定义一个工厂类，工厂类可以根据条件生成不同的子类实例。当得到子类的实例后，开发人员可以调用基类中的方法而不必考虑到底返回的是哪一个子类的实例。 开发中都用到了那些设计模式?用在什么场合?每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心。通过这种方式，你可以无数次地使用那些已有的解决方案，无需在重复相同的工作。主要用到了MVC的设计模式。用来开发JSP/Servlet或者J2EE的相关应用。简单工厂模式等。 singleton:单例,用来减少垃圾对象和缓存用factory:工厂模式,用来解耦（呵呵，其实模式都是用来解耦的）facade和decorator:封装接口command:命令模式，传递Iterator:用来遍历对象Observer:用来监听状态变化（现在习惯用listener机制替代）templete:模板模式，用来处理相同的操作步骤strategy:策略模式，策略选择proxy:用来附加功能，属性或隐蔽。 bridge也很实用，用来解耦工厂与产品搭配之类的选择 场景题如果一个外卖配送单子要发布，现在有200个骑手都想要接这一单，如何保证只有一个骑手接到单子？美团首页每天会从10000个商家里面推荐50个商家置顶，每个商家有一个权值，你如何来推荐？第二天怎么更新推荐的商家？可以借鉴下stackoverflow，视频网站等等的推荐算法。微信抢红包问题 悲观锁，乐观锁，存储过程放在mysql数据库中。1000个任务，分给10个人做，你怎么分配，先在纸上写个最简单的版本，然后优化。全局队列，把1000任务放在一个队列里面，然后每个人都是取，完成任务。分为10个队列，每个人分别到自己对应的队列中去取务。 保证发送消息的有序性，消息处理的有序性。https://blog.csdn.net/fengqiangdu/article/details/96139151 如何把一个文件快速下发到100w个服务器http://m.nowcoder.com/discuss/76829?type=0&amp;pos=18 给每个组分配不同的IP段，怎么设计一种结构使的快速得知IP是哪个组的?10亿个数，找出最大的10个。建议一个大小为10的小根堆。 有几台机器存储着几亿淘宝搜索日志，你只有一台2g的电脑，怎么选出搜索热度最高的十个搜索关键词？分布式集群中如何保证线程安全？https://www.jianshu.com/p/8c9e98a6e936 给个淘宝场景，怎么设计一消息队列？https://www.sohu.com/a/204619554_730031 10万个数，输出从小到大？先划分成多个小文件，送进内存排序，然后再采用多路归并排序。 有十万个单词，找出重复次数最高十个？12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import java.util.*;import java.util.Map.Entry;import java.io.*;import junit.framework.TestCase; public class search &#123; public static void main(String[] args) throws FileNotFoundException&#123;System.out.println(&quot;Press any letter to start word count:&quot;); Scanner s = new Scanner(System.in); if (s.nextLine() == null) &#123; s.close(); System.exit(0); &#125; else &#123; s.close(); &#125; Map&lt;String,Integer&gt; map=new TreeMap&lt;String,Integer&gt;();File file=new File(&quot;test.txt&quot;);//将文本文件与代码放入同一目录下，所以只写了相对路径Reader reader=null;StringBuilder exist=new StringBuilder();try&#123;reader=new InputStreamReader(new FileInputStream(file));int tmpchar;while((tmpchar=reader.read())!=-1)&#123;if(isCharacter(tmpchar))&#123;exist.append((char)tmpchar);&#125;else&#123;Addword(exist.toString(),map);exist=new StringBuilder();&#125;&#125;&#125;catch(IOException e)&#123;e.printStackTrace();&#125;List&lt;Map.Entry&lt;String,Integer&gt;&gt; list = new ArrayList&lt;Map.Entry&lt;String,Integer&gt;&gt;(map.entrySet()); Collections.sort(list,new Comparator&lt;Map.Entry&lt;String,Integer&gt;&gt;() &#123; public int compare(Entry&lt;String,Integer&gt; o1,Entry&lt;String,Integer&gt; o2) &#123; return (o2.getValue().compareTo(o1.getValue()));//降序排序 &#125; &#125;); int i=10; Set&lt;String&gt; keySet = map.keySet(); Iterator&lt;String&gt; iter = keySet.iterator(); while (iter.hasNext()&amp;&amp;i&gt;0) &#123; String key=iter.next(); System.out.println((String)key+&quot;:&quot;+map.get(key)); i--; &#125;&#125;public static void Addword(String str,Map&lt;String,Integer&gt; map)//是字母就append组成单词&#123;str=str.toLowerCase();Integer count=map.get(str);if(count==null)&#123;map.put(str,1);&#125;else&#123;map.put(str,count+1);&#125;&#125;public static boolean isCharacter(int tmpchar)//判断是否是字母&#123;if(tmpchar&gt;=65&amp;&amp;tmpchar&lt;=90)&#123;return true;&#125;else if(tmpchar&gt;=97&amp;&amp;tmpchar&lt;=122)&#123;return true;&#125;return false;&#125;&#125;运行结果（所选文本是一篇以a开头的词汇，所以结果都是a开头的）：a:37abbr:10abbreviation:5ability:4able:4abroad:3absence:3absent:2absenteeism:2 abolish:1 25匹马，5个跑道，最少赛马多少次可以找出跑的最快的前三匹马https://blog.csdn.net/wtwzd002/article/details/70154526 待补充。。。 参考链接https://blog.csdn.net/u014543872/article/details/90312139 https://cloud.tencent.com/developer/article/1362755 https://blog.csdn.net/qq_39382769/article/details/88792554 https://blog.csdn.net/qq_41701956/article/details/84378302 https://www.cnblogs.com/yewsky/articles/1864934.html https://blog.csdn.net/qq_38977097/article/details/88826939 https://blog.csdn.net/Norte_L/article/details/80250057 https://www.cnblogs.com/zhaideyou/p/5929977.html https://www.cnblogs.com/zk753159/p/4966571.html https://blog.csdn.net/qq_42322624/article/details/80470170 https://yq.aliyun.com/articles/635007 https://blog.csdn.net/natian306/article/details/18504111 https://blog.csdn.net/longfulong/article/details/78700239 https://blog.csdn.net/s10461/article/details/53941091 https://blog.csdn.net/snail_xinl/article/details/53427572 https://yq.aliyun.com/articles/635005 https://blog.csdn.net/qq_34602647/article/details/80560741 https://blog.csdn.net/lsqingfeng/article/details/80342620 https://www.cnblogs.com/heartstage/p/3365688.html https://blog.csdn.net/Onty_dr/article/details/84889097 https://blog.csdn.net/qq_37113604/article/details/81353626 https://blog.csdn.net/cyywxy/article/details/81151104 https://blog.csdn.net/cyywxy/article/details/81151104 https://www.cnblogs.com/tjudzj/p/4459443.html https://www.cnblogs.com/jiangyi-uestc/p/5682699.html https://www.cnblogs.com/cielosun/p/6684775.html https://www.cnblogs.com/dadonggg/p/7799344.html https://blog.csdn.net/qq_42090683/article/details/83505979 https://www.nowcoder.com/questionTerminal/6bd3857199564b3fb2d3fee4f4de06ea?pos=134&amp;mutiTagIds=570&amp;orderByHotValue=0&amp;done=0 https://blog.csdn.net/gaoyong_stone/article/details/79540242","tags":[{"name":"Java","slug":"Java","permalink":"http://www.ylovex.cn/tags/Java/"}]},{"title":"操作系统基础","date":"2019-07-21T00:03:18.000Z","path":"2019/07/21/操作系统基础/","text":"操作系统基础操作系统是计算机系统中的一个系统软件，是一些程序模块的集合 对于使用者：提供了一个计算机用户与计算机硬件系统之间的接口，使计算机系统更易于使用 对于资源管理者：有效地控制和管理计算机系统中的各种硬件和软件资源，使之得到更加有效的利用 合理地组织计算机系统的工作流程，以改善系统性能（响应时间、系统吞吐量等） 计算机系统组成 硬件（CPU、内存、IO设备）提供基本的运算资源 系统软件：操作系统、编译系统 应用程序（字处理、电子表格、浏览器） 用户（操作员、其他计算机）使用计算机解决问题 基本功能处理机管理 进程（线程）控制 进程（线程）同步 进程通信 进程（线程）调度 存储器管理 任务 为多道程序的并发提供良好的环境 便于用户使用存储器 提高存储器利用率 为尽量多的用户提供足够大的存储空间 功能 内存分配：静态和动态分配 内存保护 地址影射 内存扩充 设备管理 任务 为用户程序分配I/O设备 完成用户程序请求的I/O操作 提高CPU和I/O设备的利用率：中断；通道 改善人机界面 功能 缓冲管理 设备分配 设备处理 虚拟设备功能 文件管理 文件存储空间的管理 目录管理 文件读、写管理 文件保护 向用户提供接口 作业控制 作业调度 作业控制 批量型作业 终端型作业 存储器管理地址空间和存储空间地址空间：源程序经过编译后得到的目标程序，存在于它所限定的地址范围内，这个范围称为地址空间。简言之，地址空间是逻辑地址的集合 存储空间：是指主存中一系列存储信息的物理单元的集合，这些单元的编号称为物理地址或绝对地址。简言之，存储空间是物理地址的集合 存储分配的三种方式直接指定方式：程序员在编写程序时候，或者编译程序（汇编程序）对源程序进行编译（汇编）时，所用的是实际地址 静态分配：程序员编程时，或由编译程序产生的目的程序，均可从其地址空间的零地址开始；当装配程序对其进行连接装入时才确定它们在主存中的地址 动态分配：作业在存储空间中的位置，在其装入时候确定，在其执行过程中可根据需要申请附加存储空间，而且一个作业已占用的部分区域不再需要时候，可以要求归还系统 单一连续区存储管理内存分为两个区域：系统区、用户区。应用程序装入到用户区，可使用用户区全部空间 最简单，适用于单用户、单任务的OS。CP/M和DOS 优点是易于管理；缺点是对要求内存空间少的程序，造成内存浪费，程序全部装入，很少使用的程序部分也占用内存 分区式分配把内存分为一些大小相等或不等的分区，每个应用程序占用一个或几个分区。操作系统占用其中一个分区 适用于多道程序系统和分时系统，支持多个程序并发执行，但难以进行内存分区的共享 固定式分区：当系统初始化 式，把存储空间划分成若干个任意大小的区域 ；然后，把这些区域分配给每个用户作业。 把内存划分为若干个固定大小的连续分区。 分区大小相等：只适合于多个相同程序的并发执行 （处理多个类型相同的对象）。分区大小不等：多个小分区、适量的中等分区、少 量的大分区。根据程序的大小，分配当前空闲的、 适当大小的分区。 优点：易于实现，开销小 缺点：内碎片造成浪费，分区总数固定，限制了并发执行程序数目 采用的数据结构：分区表–记录分区的大小和使用情况 可变式分区：分区的边界可以移动，即分区的大小可变 优点：没有内碎片 缺点：有外碎片 可变式分区的分配策略 最佳适应算法（Best Fit）：为一个作业选择分区时 ，总是寻找其大小最接近于作业所要求的存储区域。 最坏适应算法（Worst Fit）：为作业选择存储区域时 ，总是寻找最大的空白区 首次适应算法（First Fit）：每个空白区按其在存储 空间中地址递增的顺序连在一起，在为作业分配存储 区域时，从这个空白区域链的始端开始查找，选择第 一个足以满足请求的空白块。 下次适应算法（Next Fit）：把存储空间中空白区构 成一个循环链，每次为存储请求查找合适的分区时， 总是从上次查找结束的地方开始，只要找到一个足够 大的空白区，就将它划分后分配出去。 可重定位分区分配定时的或在内存紧张时， 移动某些已分配区中的信息，把存储空间中所 有的空白区合并为一个大的连续区。 多重分区分配一个作业往往由相对独立的程序 段和数据段组成，将这些片断分别装入到存储空 间中不同的区域内的分配方式 覆盖管理就是把一个大的程序划 分成一系列的覆盖，每个覆盖是一个相对独立 的程序单位。把程序执行时并不要求同时装入 主存的覆盖组成一组，称其为覆盖段，这个覆 盖段被分配到同一个存储区域。这个存储区域 称之为覆盖区，它与覆盖段一一对应。 缺点：编程时必须划分程序模块和确定程序模 块之间的覆盖关系，增加编程复杂度。从外存 装入覆盖文件，以时间延长来换取空间节省。 交换广义的说，所谓交换就是把暂时不用的 某个（或某些）程序及其数据的部分或全部从 主存移到辅存中去，以便腾出必要的存储空间 ；接着把指定程序或数据从辅存读到相应的主 存中，并将控制转给它，让其在系统上运行 优点：增加并发运行的程序数目，并且给用户 提供适当的响应时间；编写程序时不影响程序 结构 缺点：对换入和换出的控制增加处理机开销； 程序整个地址空间都进行传送，没有考虑执行 过程中地址访问的统计特性。 分页式存储管理页：在分页存储管理系统中，把每个作业的地址 空间分成一些大小相等的片，称之为页面或页。 存储块：在分页存储管理系统中，把主存的存储 空间也分成与页面相同大小的片，这些片称为存 储块，或称为页框 纯分页系统在调度一个作业时，必须把它的所有页一次装到主 存的页框内；如果当时页框数不足，则该作业必须 等待，系统再调度另外作业 优点： 没有外碎片，每个内碎片不超过页大小。 一个程序不必连续存放。便于改变程序占用空间的大小（ 主要指随着程序运行而动态生成的数据增多，要求地址空间相应增长，通常由系统调用完成而不是操作系统自动完成）。 缺点：程序全部装入内存 页表数据结构进程页表：每个进程有一个页表，描述该进程占用的物理页面及逻辑排列顺序 物理页面表：整个系统有一个物理页面表，描 述物理内存空间的分配使用状况。 请求表：整个系统有一个请求表，描述系统内 各个进程页表的位置和大小，用于地址转换， 也可以结合到各进程的PCB里； 分段式存储管理分段地址空间：一个段可定义为一组逻辑信息，每个作业的地 址空间是由一些分段构成的，每段都有自己的 名字，且都是一段连续的地址空间 地址结构：段号S + 位移量W 缺点： 处理机要为地址变换花费时间；要为表格提供附加 的存储空间。 为满足分段的动态增长和减少外零头，要采用拼接 手段。 在辅存中管理不定长度的分段困难较多 。 分段的最大尺寸受到主存可用空间的限制。 分页和分段的比较 分页的作业的地址空间是单一的线性地址空间 ，分段作业的地址空间是二维的。 “页”是信息的“物理”单位，大小固定。“ 段”是信息的逻辑单位，即它是一组有意义的信息，其长度不定。 分页活动用户是看不见的，而是系统对于主存 的管理。分段是用户可见的（分段可以在用户 编程时确定，也可以在编译程序对源程序编译 时根据信息的性质来划分）。 段页式存储管理用分段方法来分配和管理虚拟存储器 ，而用分页方法来分配和管理实存储器 一个程序首先被分成若干程序段，每一段赋予不 同的分段标识符，然后，对每一分段又分成若干个固定大小的页面 虚拟存储器局部性原理指程序在执行过程中的一个较短时期，所执行的指令 地址和指令的操作数地址，分别局限于一定区域。还 可以表现为： 时间局部性，即一条指令的一次执行和下次执行，一 个数据的一次访问和下次访问都集中在一个较短时期内 空间局部性，即当前指令和邻近的几条指令，当前访 问的数据和邻近的数据都集中在一个较小区域内 虚拟存储技术在程序装入时，不必将其全部读入到内存，而 只需将当前需要执行的部分页或段读入到内存 ，就可让程序开始执行。 在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页或段调入到内存，然后继续执行程序。 另一方面，操作系统将内存中暂时不使用的页 或段调出保存在外存上，从而腾出空间存放将 要装入的程序以及将要调入的页或段――具有 请求调入和置换功能，只需程序的一部分在内 存就可执行，对于动态链接库也可以请求调入 优点： 可在较小的可用内存中执行较大的用户程序； 可在内存中容纳更多程序并发执行 不必影响编程时的程序结构（与覆盖技术比较） 提供给用户可用的虚拟内存空间通常大于物理内存(real memory) 特征： 离散性：物理内存分配的不连续，虚拟地址空 间使用的不连续（数据段和栈段之间的空闲空 间，共享段和动态链接库占用的空间） 多次性 对换性：与交换的比较：调入和调出是对部分 虚拟地址空间进行 虚拟性：通过物理内存和快速外存相结合，提 供大范围的虚拟地址空间 。范围大，但占用容量不超过物理内存和外存交换区 容量之和 。占用容量包括：进程地址空间中的各个段，操作系 统代码 请求式分页系统在运行作业之前，只要求把当前需要的一部分 页面装入主存。当需要其它的页时，可自动的 选择一些页交换倒辅存去，同时把所需的页调 入主存。 虚拟存储系统：控制自动页面交换而用户作业 意识不到的那个机构，成为虚拟存储系统 页面调入策略请求式提取：仅当需要时才提取页面的策略 预先调页：事先提取页面的策略。 页面置换策略先进先出算法选择建立最早的页面被置换。可以通过链表来表示各页 的建立时间先后。性能较差。较早调入的页往往是经常 被访问的页，这些页在FIFO算法下被反复调入和调出。 并且有Belady现象。 最近最久不用的页面置换算法选择内存中最久未使用的页面被置换。这是局部性 原理的合理近似，性能接近最佳算法。但由于需要 记录页面使用时间的先后关系，硬件开销太大。硬 件机构如： 一个特殊的栈：把被访问的页面移到栈顶，于是栈底的是 最久未使用页面。 每个页面设立移位寄存器：被访问时左边最高位置1，定 期右移并且最高位补0，于是寄存器数值最小的是最久未 使用页面。 Clock算法也称最近未使用算法(NRU, Not Recently Used)，它是LRU 和FIFO的折衷 每页有一个使用标志位(use bit)，若该页被访问则置user bit=1。 置换时采用一个指针，从当前指针位置开始按地址先后检 查各页，寻找use bit=0的页面作为被置换页。 指针经过的user bit=1的页都修改user bit=0，最后指针停留 在被置换页的下一个页。 最不常用算法(LFU, Least Frequently Used)选择到当前时间为止被访问次数最少的页面被置换； 每页设置访问计数器，每当页面被访问时，该页面的访 问计数器加1； 发生缺页中断时，淘汰计数值最小的页面，并将所有计 数清零； 页面缓冲算法它是对FIFO算法的发展，通过被置换页面的缓冲， 有机会找回刚被置换的页面； 被置换页面的选择和处理：用FIFO算法选择被置换页，把被置换的页面放入两个链表之一。即：如果 页面未被修改，就将其归入到空闲页面链表的末尾 ，否则将其归入到已修改页面链表 进程和线程进程是程序在一个数据集合上运行的过程，它是系 统进行资源分配和调度的一个独立单位。 特征： 动态性 并发性 独立性 异步性 结构特征：程序段，数据段，进程控制块PCB 一个进程应该包括： 程序的代码 程序的数据 PC中的值，用来指示下一条将运行的指令 一组通用的寄存器的当前值，堆、栈 一组系统资源 进程与程序的区别 进程是动态的，程序是静态的：程序是有序代码的集 合；进程是程序的执行。通常进程不可在计算机之间 迁移；而程序通常对应着文件、静态和可以复制。 进程是暂时的，程序的永久的：进程是一个状态变化 的过程，程序可长久保存。 进程与程序的组成不同：进程的组成包括程序、数据 和进程控制块（即进程状态信息）。 进程与程序的对应关系：通过多次执行，一个程序可 对应多个进程；通过调用关系，一个进程可包括多个程序。 线程是进程中的一个实体，是一个个CPU调度和分派的单位 ，基本上不拥有资源， 只有必不可少的少量资源 ，可以与其他同进程的 线程共享进程拥有的 所有资源 进程和线程区别区别： 线程程序任务调度和执行的最小单位。进程是资源分配的最小单位 进程拥有独立的栈堆空间和数据段，启动一个新的进程必须分配给它独立的地址空间，系统开销大。线程拥有独立的栈空间，但是共享数据段，开销小，切换速度快，效率高。 进程间相对独立，安全性高。线程间依赖性比较强，一个线程死掉等于整个进程死掉。 进程间相对独立，通信机制较复杂。线程通信机制由于共享数据段，通信机制方便。 线程必定只能属于一个进程，而进程可以拥有多个线程而且至少拥有一个线程。 线程和进程场景选择： 创建和销毁一个进程代价很大，需要频繁创建销毁优先使用线程。 线程切换速度快，在需要大量计算、切换频繁时用线程，耗时的操作使用线程可提高应用程序的响应。 对CPU系统的效率上线程占有，所以可能要发展到多级分布的用进程、多核分布用线程。 并行操作用线程。 需要更稳定安全时，选择进程，需要速度时，选线程。 对于线程弄清两点是非常重要的： 线程之间有无先后访问顺序（线程依赖关系） 多个线程共享访问一个变量（同步互斥问题） 另外通常我们只会去说同一进程的多个线程共享进程的资源，但是每个线程特有的部分却很少提及，除了标识线程的id，每个线程还有自己的独立栈空间，线程彼此之间是无法访问其他线程栈上内容的。而作为处理机调度的最小单位，线程调度只需要保存线程栈、寄存器数据和PC即可，相比进程切换开销要小很多。 进程的优劣：对于在父、子进程间共享状态信息，进程有一个非常清晰的模型：共享文件表，但是不共享用户地址空间。进程有独立的地址空间既是优点也是缺点。优点：一个进程不可能不小心覆盖另一个进程的虚拟内存。缺点：独立的地址空间使得进程共享状态信息变得更加困难。为了共享信息，必须使用显示的IPC（进程间通信）机制。而进程控制和IPC的开销很高。 进程创建和结束进程创建有两种方式，一种是操作系统创建的，一种是父进程创建的。 从计算机启动到终端执行程序的过程为：0号进程 -&gt; 1号内核进程 -&gt; 1号用户进程(init进程) -&gt; getty进程 -&gt; shell进程 -&gt; 命令行执行进程。所以我们在命令行中通过 ./program执行可执行文件时，所有创建的进程都是shell进程的子进程，这也就是为什么shell一关闭，在shell中执行的进程都自动被关闭的原因。 相关接口： 创建进程：pid_t fork(void);返回值：出错返回-1；父进程中返回pdi&gt;0；子进程中pid ==0 结束进程：void exit(int status)status是退出状态，保存在全局变量，通常0表示正常退出 获取PID： pid_t getpid(void)返回调用者pid 获得父进程pid： pid_t getppid(void)返回父进程pid 如何创建新进程在linux中主要提供了fork，vfork，clone三个进程创建方法。 在linux源码中这是哪个调用的执行过程是执行fork,vfork,clone时，通过一个系统调用表映射到sys_fork(),sys_vfork(),sys_clone()，再在这三个函数中去调用do_fork()去做具体的创建进程工作。 fork:现在Linux中是采取了copy-on-write(COW写时复制)技术，为了降低开销，fork最初并不会真的产生两个不同的拷贝，因为在那个时候，大量的数据其实完全是一样的。写时复制是在推迟真正的数据拷贝。若后来确实发生了写入，那意味着parent和child的数据不一致了，于是产生复制动作，每个进程拿到属于自己的那一份，这样就可以降低系统调用的开销。 vfork()：vfork系统调用不同于fork，用vfork创建的子进程与父进程共享地址空间，也就是说子进程完全运行在父进程的地址空间上，如果这时子进程修改了某个变量，这将影响到父进程。 但此处有一点要注意的是用vfork()创建的子进程必须显示调用exit()来结束，否则子进程将不能结束，而fork()则不存在这个情况。 用 vfork创建子进程后，父进程会被阻塞直到子进程调用exec(exec，将一个新的可执行文件载入到地址空间并执行之。)或exit。vfork的好处是在子进程被创建后往往仅仅是为了调用exec执行另一个程序，因为它就不会对父进程的地址空间有任何引用，所以对地址空间的复制是多余的 ，因此通过vfork共享内存可以减少不必要的开销。 clone()：系统调用fork()和vfork()是无参数的，而clone()则带有参数。fork()是全部复制，vfork()是共享内存，而clone() 是则可以将父进程资源有选择地复制给子进程，而没有复制的数据结构则通过指针的复制让子进程共享. fork()返回值fork()之前，只有一个进程在执行这段代码，但是在该条语句后，就变成了两个进程在执行了，这两个进程代码部分完全相同。Fork仅仅被调用一次，但却能够返回两次，它有三种不同的返回值：1.父进程中，fork返回新创建的子进程ID。2.子进程中，fork返回0。3.出现错误，fork返回负值。 进程的状态 就绪状态：进程已获得除处理机外的所需资源，等待分配处理机资源；只要分配CPU就可执行。 执行状态：占用处理机资源；处于此状态的进程的 数目小于等于CPU的数目。在没有其他进程可以执 行时（如所有进程都在阻塞状态），通常会自动执 行系统的idle进程（相当于空操作）。 阻塞状态：正在执行的进程，由于发生某种事件而 暂时无法执行，便放弃处理机处于暂停状态。 就绪–&gt;运行： 时间一到，调度程序选择一个进程运行 运行–&gt; 就绪 ： 运行进程用完了时间片 运行进程被中断，因为一高优先级进程处于就绪状态 运行–&gt; 阻塞 ： 当一进程所需的东西必须等待时 OS尚未完成服务 对一资源的访问尚不能进行 初始化I/O 且必须等待结果 等待某一进程提供输入(IPC) 阻塞–&gt; 就绪 ： 当所等待的事件发生时候 孤儿进程、僵尸进程和守护进程父进程在调用fork接口之后和子进程独立开，之后子进程和父进程就以未知的顺序向下执行（异步过程）。所以父进程和子进程都有可能先执行完。当父进程先结束，子进程此时就会变成孤儿进程，不过这种情况问题不大，孤儿进程会自动向上被init进程收养，init进程完成对状态收集工作。而且这种过继的方式也是守护进程能够实现的因素。如果子进程先结束，父进程并未调用wait或者waitpid获取进程状态信息，那么子进程描述符就会一直保存在系统里，这种进程称为僵尸进程。 相关接口： 回收进程（1）： pid_t wait(int *status) 一旦调用wait（），就会立刻阻塞自己，wait（）自动分析某个子进程是否退出，如果找到僵尸进程就会负责收集和销毁，如果没有找到就一直阻塞在这里。 status：指向子进程结束状态值。 回收进程（2）： pid_t waitpid(pid_t pid,int *status,int options) 返回值：返回pid：返回收集的子进程id。返回-1：出错 返回0：没有被收集的子进程 pid：子进程识别码，控制等待哪些子进程。 pid &lt; -1,等待进程组识别码为pid绝对值的任何进程 Pid = -1，等待任何子进程 Pid = 0，等待进程组识别码与目前进程相同的任何子进程 Pid&gt;0 ，等待任何子进程识别码为pid的子进程 status： 指向返回码的指针 options： 选项决定父进程调用waitpid后的状态 options = WNOHANG, 即使没有子进程退出也立即返回。 options = WUNYRACED, 子进程进入暂停马上返回，但结束状态不予理会 守护进程： 定义：守护进程是脱离终端并在后台运行的进程，执行过程中信息不会显示在终端上并且也不会被终端发出的信号打断。 操作步骤：创建子进程，父进程退出：fork() + if(pid &gt; 0){exit(0);}，使子进程称为孤儿进程被init进程收养。 在子进程中创建新会话：setsid()。 改变当前目录结构为根：chdir(“/“)。 重设文件掩码：umask(0)。 关闭文件描述符：for(int i = 0; i &lt; 65535; ++i){close(i);}。 多进程每一个进程是资源分配的基本单位。进程结构由以下几个部分组成：代码段、堆栈段、数据段。代码段是静态的二进制代码，多个程序可以共享。实际上在父进程创建子进程之后，父、子进程除了pid外，几乎所有的部分几乎一样，子进程创建时拷贝父进程PCB中大部分内容，而PCB的内容实际上是各种数据、代码的地址或索引表地址，所以复制了PCB中这些指针实际就等于获取了全部父进程可访问数据。所以简单来说，创建新进程需要复制整个PCB，之后操作系统将PCB添加到进程核心堆栈底部，这样就可以被操作系统感知和调度了。 父、子进程共享全部数据，但并不是说他们就是对同一块数据进行操作，子进程在读写数据时会通过写时复制机制将公共的数据重新拷贝一份，之后在拷贝出的数据上进行操作。如果子进程想要运行自己的代码段，还可以通过调用execv()函数重新加载新的代码段，之后就和父进程独立开了。我们在shell中执行程序就是通过shell进程先fork()一个子进程再通过execv()重新加载新的代码段的过程。 进程通信进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。 IPC的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC 管道通常指无名管道，是 UNIX 系统IPC最古老的形式 特点： 它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。 它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。 #include &lt;unistd.h&gt;int pipe(int fd[2]); // 返回值：若成功返回0，失败返回-1 原型：当一个管道建立时，它会创建两个文件描述符：fd[0]为读而打开，fd[1]为写而打开。如下图 要关闭管道只需将这两个文件描述符关闭即可。 例子：单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。如下图所示： 若要数据流从父进程流向子进程，则关闭父进程的读端（fd[0]）与子进程的写端（fd[1]）；反之，则可以使数据流从子进程流向父进程. 123456789101112131415161718192021222324252627282930313233#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt; #define MAXLINE (2014) int main(void)&#123; int n,fd[2];//保存管道返回的两个文件描述符 pid_t pid; char line[MAXLINE]; if(pipe(fd)&lt;0)//创建管道,fd[0]是读端，fd[1]是写端。 printf(&quot;pipe error&quot;); if((pid=fork())&lt;0)//创建进程 printf(&quot;fock error&quot;);//创建进程失败 else if(pid&gt;0)//pid大于零，为父进程，pid的值是子进程的 &#123; close(fd[0]);//关闭读端 printf(&quot;#the parent process pid %d\\n&quot;,getpid());//返回当前进程的id printf(&quot;#the children pid is %d\\n&quot;,pid); printf(&quot;#the process write to pipe: hello world\\n&quot;); write(fd[1],&quot;hello world\\n&quot;,12);//向写端写入12个字节数据 &#125; else &#123; close(fd[1]);//关闭写端 printf(&quot;$the children process pid %d\\n&quot;,getpid()); printf(&quot;$the parent process pid %d\\n&quot;,getppid()); n = read(fd[0],line,MAXLINE); write(STDOUT_FILENO,line,n);//把数据写入标准输出文件描述符 &#125; exit(0);&#125; FIFO也称为命名管道，它是一种文件类型 特点： FIFO可以在无关的进程之间交换数据，与无名管道不同。 FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。 原型： 123#include &lt;sys/stat.h&gt;// 返回值：成功返回0，出错返回-1int mkfifo(const char *pathname, mode_t mode); 其中的 mode 参数与open函数中的 mode 相同。一旦创建了一个 FIFO，就可以用一般的文件I/O函数操作它。 当 open 一个FIFO时，是否设置非阻塞标志（O_NONBLOCK）的区别： 若没有指定O_NONBLOCK（默认），只读 open 要阻塞到某个其他进程为写而打开此 FIFO。类似的，只写 open 要阻塞到某个其他进程为读而打开它。 若指定了O_NONBLOCK，则只读 open 立即返回。而只写 open 将出错返回 -1 如果没有进程已经为读而打开该 FIFO，其errno置ENXIO。 例子：FIFO的通信方式类似于在进程中使用文件来传输数据，只不过FIFO类型文件同时具有管道的特性。在数据读出时，FIFO管道中同时清除数据，并且“先进先出”。下面的例子演示了使用 FIFO 进行 IPC 的过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667write_fifo.c#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt; // exit#include&lt;fcntl.h&gt; // O_WRONLY#include&lt;sys/stat.h&gt;#include&lt;time.h&gt; // time#include &lt;unistd.h&gt;int main()&#123; int fd; int n, i; char buf[1024]; time_t tp; printf(&quot;I am %d process.\\n&quot;, getpid()); // 说明进程ID if((fd = open(&quot;fifo1&quot;, O_WRONLY)) &lt; 0) // 以写打开一个FIFO &#123; perror(&quot;Open FIFO Failed&quot;); exit(1); &#125; for(i=0; i&lt;10; ++i) &#123; time(&amp;tp); // 取系统当前时间 n=sprintf(buf,&quot;Process %d&apos;s time is %s&quot;,getpid(),ctime(&amp;tp)); printf(&quot;Send message: %s&quot;, buf); // 打印 if(write(fd, buf, n+1) &lt; 0) // 写入到FIFO中 &#123; perror(&quot;Write FIFO Failed&quot;); close(fd); exit(1); &#125; sleep(1); // 休眠1秒 &#125; close(fd); // 关闭FIFO文件 return 0;&#125;read_fifo.c#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;errno.h&gt;#include&lt;fcntl.h&gt;#include&lt;sys/stat.h&gt;int main()&#123; int fd; int len; char buf[1024]; if(mkfifo(&quot;fifo1&quot;, 0666) &lt; 0 &amp;&amp; errno!=EEXIST) // 创建FIFO管道 perror(&quot;Create FIFO Failed&quot;); if((fd = open(&quot;fifo1&quot;, O_RDONLY)) &lt; 0) // 以读打开FIFO &#123; perror(&quot;Open FIFO Failed&quot;); exit(1); &#125; while((len = read(fd, buf, 1024)) &gt; 0) // 读取FIFO管道 printf(&quot;Read message: %s&quot;, buf); close(fd); // 关闭FIFO文件 return 0;&#125; 在两个终端里用 gcc 分别编译运行上面两个文件，可以看到结果如下： 1234567891011121314151617181920212223[cheesezh@localhost]$ ./write_fifo I am 5954 process.Send message: Process 5954&apos;s time is Mon Apr 20 12:37:28 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:29 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:30 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:31 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:32 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:33 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:34 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:35 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:36 2015Send message: Process 5954&apos;s time is Mon Apr 20 12:37:37 2015[cheesezh@localhost]$ ./read_fifo Read message: Process 5954&apos;s time is Mon Apr 20 12:37:28 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:29 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:30 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:31 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:32 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:33 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:34 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:35 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:36 2015Read message: Process 5954&apos;s time is Mon Apr 20 12:37:37 2015 上述例子可以扩展成客户进程—服务器进程通信的实例，write_fifo的作用类似于客户端，可以打开多个客户端向一个服务器发送请求信息，read_fifo类似于服务器，它适时监控着FIFO的读端，当有数据时，读出并进行处理，但是有一个关键的问题是，每一个客户端必须预先知道服务器提供的FIFO接口，下图显示了这种安排： 消息队列是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标识。 特点： 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。 消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。 原型： 123456789#include &lt;sys/msg.h&gt;// 创建或打开消息队列：成功返回队列ID，失败返回-1int msgget(key_t key, int flag);// 添加消息：成功返回0，失败返回-1int msgsnd(int msqid, const void *ptr, size_t size, int flag);// 读取消息：成功返回消息数据的长度，失败返回-1int msgrcv(int msqid, void *ptr, size_t size, long type,int flag);// 控制消息队列：成功返回0，失败返回-1int msgctl(int msqid, int cmd, struct msqid_ds *buf); 在以下两种情况下，msgget将创建一个新的消息队列： 如果没有与键值key相对应的消息队列，并且flag中包含了IPC_CREAT标志位。 key参数为IPC_PRIVATE。 函数msgrcv在读取消息队列时，type参数有下面几种情况 type == 0，返回队列中的第一个消息； type &gt; 0，返回队列中消息类型为 type 的第一个消息； type &lt; 0，返回队列中消息类型值小于或等于 type 绝对值的消息，如果有多个，则取类型值最小的消息 可以看出，type值非 0 时用于以非先进先出次序读消息。也可以把 type 看做优先级的权值 例子：下面写了一个简单的使用消息队列进行IPC的例子，服务端程序一直在等待特定类型的消息，当收到该类型的消息以后，发送另一种特定类型的消息作为反馈，客户端读取该反馈并打印出来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106msg_server.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/msg.h&gt;// 用于创建一个唯一的key#define MSG_FILE &quot;/etc/passwd&quot;// 消息结构struct msg_form &#123; long mtype; char mtext[256];&#125;;int main()&#123; int msqid; key_t key; struct msg_form msg; // 获取key值 if((key = ftok(MSG_FILE,&apos;z&apos;)) &lt; 0) &#123; perror(&quot;ftok error&quot;); exit(1); &#125; // 打印key值 printf(&quot;Message Queue - Server key is: %d.\\n&quot;, key); // 创建消息队列 if ((msqid = msgget(key, IPC_CREAT|0777)) == -1) &#123; perror(&quot;msgget error&quot;); exit(1); &#125; // 打印消息队列ID及进程ID printf(&quot;My msqid is: %d.\\n&quot;, msqid); printf(&quot;My pid is: %d.\\n&quot;, getpid()); // 循环读取消息 for(;;) &#123; msgrcv(msqid, &amp;msg, 256, 888, 0);// 返回类型为888的第一个消息 printf(&quot;Server: receive msg.mtext is: %s.\\n&quot;, msg.mtext); printf(&quot;Server: receive msg.mtype is: %d.\\n&quot;, msg.mtype); msg.mtype = 999; // 客户端接收的消息类型 sprintf(msg.mtext, &quot;hello, I&apos;m server %d&quot;, getpid()); msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); &#125; return 0;&#125;msg_client.c#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/msg.h&gt;// 用于创建一个唯一的key#define MSG_FILE &quot;/etc/passwd&quot;// 消息结构struct msg_form &#123; long mtype; char mtext[256];&#125;;int main()&#123; int msqid; key_t key; struct msg_form msg; // 获取key值 if ((key = ftok(MSG_FILE, &apos;z&apos;)) &lt; 0) &#123; perror(&quot;ftok error&quot;); exit(1); &#125; // 打印key值 printf(&quot;Message Queue - Client key is: %d.\\n&quot;, key); // 打开消息队列 if ((msqid = msgget(key, IPC_CREAT|0777)) == -1) &#123; perror(&quot;msgget error&quot;); exit(1); &#125; // 打印消息队列ID及进程ID printf(&quot;My msqid is: %d.\\n&quot;, msqid); printf(&quot;My pid is: %d.\\n&quot;, getpid()); // 添加消息，类型为888 msg.mtype = 888; sprintf(msg.mtext, &quot;hello, I&apos;m client %d&quot;, getpid()); msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); // 读取类型为777的消息 msgrcv(msqid, &amp;msg, 256, 999, 0); printf(&quot;Client: receive msg.mtext is: %s.\\n&quot;, msg.mtext); printf(&quot;Client: receive msg.mtype is: %d.\\n&quot;, msg.mtype); return 0;&#125; 信号量与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。 特点： 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。 支持信号量组。 原型： 最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二值信号量（Binary Semaphore）。而可以取多个正整数的信号量被称为通用信号量。 Linux 下的信号量函数都是在通用的信号量数组上进行操作，而不是在一个单一的二值信号量上进行操作。 1234567#include &lt;sys/sem.h&gt;// 创建或获取一个信号量组：若成功返回信号量集ID，失败返回-1int semget(key_t key, int num_sems, int sem_flags);// 对信号量组进行操作，改变信号量的值：成功返回0，失败返回-1int semop(int semid, struct sembuf semoparray[], size_t numops); // 控制信号量的相关信息int semctl(int semid, int sem_num, int cmd, ...); 当semget创建新的信号量集合时，必须指定集合中信号量的个数（即num_sems），通常为1； 如果是引用一个现有的集合，则将num_sems指定为 0 。 在semop函数中，sembuf结构的定义如下： 123456struct sembuf &#123; short sem_num; // 信号量组中对应的序号，0～sem_nums-1 short sem_op; // 信号量值在一次操作中的改变量 short sem_flg; // IPC_NOWAIT, SEM_UNDO&#125; 其中 sem_op 是一次操作中的信号量的改变量： 若sem_op &gt; 0，表示进程释放相应的资源数，将 sem_op 的值加到信号量的值上。如果有进程正在休眠等待此信号量，则换行它们。 若sem_op &lt; 0，请求 sem_op 的绝对值的资源 如果相应的资源数可以满足请求，则将该信号量的值减去sem_op的绝对值，函数成功返回。 当相应的资源数不能满足请求时，这个操作与sem_flg有关。 sem_flg 指定IPC_NOWAIT，则semop函数出错返回EAGAIN。 sem_flg 没有指定IPC_NOWAIT，则将该信号量的semncnt值加1，然后进程挂起直到下述情况发生： 当相应的资源数可以满足请求，此信号量的semncnt值减1，该信号量的值减去sem_op的绝对值。成功返回； 此信号量被删除，函数smeop出错返回EIDRM； 进程捕捉到信号，并从信号处理函数返回，此情况下将此信号量的semncnt值减1，函数semop出错返回EINTR 若sem_op == 0，进程阻塞直到信号量的相应值为0： 当信号量已经为0，函数立即返回。 如果信号量的值不为0，则依据sem_flg决定函数动作： 信号量值为0，将信号量的semzcnt的值减1，函数semop成功返回； 此信号量被删除，函数smeop出错返回EIDRM； 进程捕捉到信号，并从信号处理函数返回，在此情况将此信号量的semncnt值减1，函数semop出错返回EINTR 在semctl函数中的命令有多种，这里就说两个常用的： SETVAL：用于初始化信号量为一个已知的值。所需要的值作为联合semun的val成员来传递。在信号量第一次使用之前需要设置信号量。 IPC_RMID：删除一个信号量集合。如果不删除信号量，它将继续在系统中存在，即使程序已经退出，它可能在你下次运行此程序时引发问题，而且信号量是一种有限的资源。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;sys/sem.h&gt;// 联合体，用于semctl初始化union semun&#123; intval; /*for SETVAL*/ struct semid_ds *buf; unsigned short *array;&#125;;// 初始化信号量int init_sem(int sem_id, int value)&#123; union semun tmp; tmp.val = value; if(semctl(sem_id, 0, SETVAL, tmp) == -1) &#123; perror(&quot;Init Semaphore Error&quot;); return -1; &#125; return 0;&#125;// P操作:// 若信号量值为1，获取资源并将信号量值-1 // 若信号量值为0，进程挂起等待int sem_p(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = -1; /*P操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror(&quot;P operation Error&quot;); return -1; &#125; return 0;&#125;// V操作：// 释放资源并将信号量值+1// 如果有进程正在挂起等待，则唤醒它们int sem_v(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = 1; /*V操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror(&quot;V operation Error&quot;); return -1; &#125; return 0;&#125;// 删除信号量集int del_sem(int sem_id)&#123; union semun tmp; if(semctl(sem_id, 0, IPC_RMID, tmp) == -1) &#123; perror(&quot;Delete Semaphore Error&quot;); return -1; &#125; return 0;&#125;int main()&#123; int sem_id; // 信号量集ID key_t key; pid_t pid; // 获取key值 if((key = ftok(&quot;.&quot;, &apos;z&apos;)) &lt; 0) &#123; perror(&quot;ftok error&quot;); exit(1); &#125; // 创建信号量集，其中只有一个信号量 if((sem_id = semget(key, 1, IPC_CREAT|0666)) == -1) &#123; perror(&quot;semget error&quot;); exit(1); &#125; // 初始化：初值设为0资源被占用 init_sem(sem_id, 0); if((pid = fork()) == -1) perror(&quot;Fork Error&quot;); else if(pid == 0) /*子进程*/ &#123; sleep(2); printf(&quot;Process child: pid=%d\\n&quot;, getpid()); sem_v(sem_id); /*释放资源*/ &#125; else /*父进程*/ &#123; sem_p(sem_id); /*等待资源*/ printf(&quot;Process father: pid=%d\\n&quot;, getpid()); sem_v(sem_id); /*释放资源*/ del_sem(sem_id); /*删除信号量集*/ &#125; return 0;&#125; 上面的例子如果不加信号量，则父进程会先执行完毕。这里加了信号量让父进程等待子进程执行完以后再执行。 共享内存指两个或多个进程共享一个给定的存储区。 特点： 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取。 因为多个进程可以同时操作，所以需要进行同步。 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问。 原型： 123456789#include &lt;sys/shm.h&gt;// 创建或获取一个共享内存：成功返回共享内存ID，失败返回-1int shmget(key_t key, size_t size, int flag);// 连接共享内存到当前进程的地址空间：成功返回指向共享内存的指针，失败返回-1void *shmat(int shm_id, const void *addr, int flag);// 断开与共享内存的连接：成功返回0，失败返回-1int shmdt(void *addr); // 控制共享内存的相关信息：成功返回0，失败返回-1int shmctl(int shm_id, int cmd, struct shmid_ds *buf); 当用shmget函数创建一段共享内存时，必须指定其 size；而如果引用一个已存在的共享内存，则将 size 指定为0 。 当一段共享内存被创建以后，它并不能被任何进程访问。必须使用shmat函数连接该共享内存到当前进程的地址空间，连接成功后把 共享内存区对象映射到调用进程的地址空间，随后可像本地空间一样访问。 shmdt函数是用来断开shmat建立的连接的。注意，这并不是从系统中删除该共享内存，只是当前进程不能再访问该共享内存而已。 shmctl函数可以对共享内存执行多种操作，根据参数 cmd 执行相应的操作。常用的是IPC_RMID（从系统中删除该共享内存）。 例子： 下面这个例子，使用了【共享内存+信号量+消息队列】的组合来实现服务器进程与客户进程间的通信。 共享内存用来传递数据； 信号量用来同步； 消息队列用来 在客户端修改了共享内存后 通知服务器读取。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309server.c#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;sys/shm.h&gt; // shared memory#include&lt;sys/sem.h&gt; // semaphore#include&lt;sys/msg.h&gt; // message queue#include&lt;string.h&gt; // memcpy// 消息队列结构struct msg_form &#123; long mtype; char mtext;&#125;;// 联合体，用于semctl初始化union semun&#123; int val; /*for SETVAL*/ struct semid_ds *buf; unsigned short *array;&#125;;// 初始化信号量int init_sem(int sem_id, int value)&#123; union semun tmp; tmp.val = value; if(semctl(sem_id, 0, SETVAL, tmp) == -1) &#123; perror(&quot;Init Semaphore Error&quot;); return -1; &#125; return 0;&#125;// P操作:// 若信号量值为1，获取资源并将信号量值-1 // 若信号量值为0，进程挂起等待int sem_p(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = -1; /*P操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror(&quot;P operation Error&quot;); return -1; &#125; return 0;&#125;// V操作：// 释放资源并将信号量值+1// 如果有进程正在挂起等待，则唤醒它们int sem_v(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = 1; /*V操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror(&quot;V operation Error&quot;); return -1; &#125; return 0;&#125;// 删除信号量集int del_sem(int sem_id)&#123; union semun tmp; if(semctl(sem_id, 0, IPC_RMID, tmp) == -1) &#123; perror(&quot;Delete Semaphore Error&quot;); return -1; &#125; return 0;&#125;// 创建一个信号量集int creat_sem(key_t key)&#123; int sem_id; if((sem_id = semget(key, 1, IPC_CREAT|0666)) == -1) &#123; perror(&quot;semget error&quot;); exit(-1); &#125; init_sem(sem_id, 1); /*初值设为1资源未占用*/ return sem_id;&#125;int main()&#123; key_t key; int shmid, semid, msqid; char *shm; char data[] = &quot;this is server&quot;; struct shmid_ds buf1; /*用于删除共享内存*/ struct msqid_ds buf2; /*用于删除消息队列*/ struct msg_form msg; /*消息队列用于通知对方更新了共享内存*/ // 获取key值 if((key = ftok(&quot;.&quot;, &apos;z&apos;)) &lt; 0) &#123; perror(&quot;ftok error&quot;); exit(1); &#125; // 创建共享内存 if((shmid = shmget(key, 1024, IPC_CREAT|0666)) == -1) &#123; perror(&quot;Create Shared Memory Error&quot;); exit(1); &#125; // 连接共享内存 shm = (char*)shmat(shmid, 0, 0); if((int)shm == -1) &#123; perror(&quot;Attach Shared Memory Error&quot;); exit(1); &#125; // 创建消息队列 if ((msqid = msgget(key, IPC_CREAT|0777)) == -1) &#123; perror(&quot;msgget error&quot;); exit(1); &#125; // 创建信号量 semid = creat_sem(key); // 读数据 while(1) &#123; msgrcv(msqid, &amp;msg, 1, 888, 0); /*读取类型为888的消息*/ if(msg.mtext == &apos;q&apos;) /*quit - 跳出循环*/ break; if(msg.mtext == &apos;r&apos;) /*read - 读共享内存*/ &#123; sem_p(semid); printf(&quot;%s\\n&quot;,shm); sem_v(semid); &#125; &#125; // 断开连接 shmdt(shm); /*删除共享内存、消息队列、信号量*/ shmctl(shmid, IPC_RMID, &amp;buf1); msgctl(msqid, IPC_RMID, &amp;buf2); del_sem(semid); return 0;&#125;client.c#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;sys/shm.h&gt; // shared memory#include&lt;sys/sem.h&gt; // semaphore#include&lt;sys/msg.h&gt; // message queue#include&lt;string.h&gt; // memcpy// 消息队列结构struct msg_form &#123; long mtype; char mtext;&#125;;// 联合体，用于semctl初始化union semun&#123; int val; /*for SETVAL*/ struct semid_ds *buf; unsigned short *array;&#125;;// P操作:// 若信号量值为1，获取资源并将信号量值-1 // 若信号量值为0，进程挂起等待int sem_p(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = -1; /*P操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror(&quot;P operation Error&quot;); return -1; &#125; return 0;&#125;// V操作：// 释放资源并将信号量值+1// 如果有进程正在挂起等待，则唤醒它们int sem_v(int sem_id)&#123; struct sembuf sbuf; sbuf.sem_num = 0; /*序号*/ sbuf.sem_op = 1; /*V操作*/ sbuf.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sbuf, 1) == -1) &#123; perror(&quot;V operation Error&quot;); return -1; &#125; return 0;&#125;int main()&#123; key_t key; int shmid, semid, msqid; char *shm; struct msg_form msg; int flag = 1; /*while循环条件*/ // 获取key值 if((key = ftok(&quot;.&quot;, &apos;z&apos;)) &lt; 0) &#123; perror(&quot;ftok error&quot;); exit(1); &#125; // 获取共享内存 if((shmid = shmget(key, 1024, 0)) == -1) &#123; perror(&quot;shmget error&quot;); exit(1); &#125; // 连接共享内存 shm = (char*)shmat(shmid, 0, 0); if((int)shm == -1) &#123; perror(&quot;Attach Shared Memory Error&quot;); exit(1); &#125; // 创建消息队列 if ((msqid = msgget(key, 0)) == -1) &#123; perror(&quot;msgget error&quot;); exit(1); &#125; // 获取信号量 if((semid = semget(key, 0, 0)) == -1) &#123; perror(&quot;semget error&quot;); exit(1); &#125; // 写数据 printf(&quot;***************************************\\n&quot;); printf(&quot;* IPC *\\n&quot;); printf(&quot;* Input r to send data to server. *\\n&quot;); printf(&quot;* Input q to quit. *\\n&quot;); printf(&quot;***************************************\\n&quot;); while(flag) &#123; char c; printf(&quot;Please input command: &quot;); scanf(&quot;%c&quot;, &amp;c); switch(c) &#123; case &apos;r&apos;: printf(&quot;Data to send: &quot;); sem_p(semid); /*访问资源*/ scanf(&quot;%s&quot;, shm); sem_v(semid); /*释放资源*/ /*清空标准输入缓冲区*/ while((c=getchar())!=&apos;\\n&apos; &amp;&amp; c!=EOF); msg.mtype = 888; msg.mtext = &apos;r&apos;; /*发送消息通知服务器读数据*/ msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); break; case &apos;q&apos;: msg.mtype = 888; msg.mtext = &apos;q&apos;; msgsnd(msqid, &amp;msg, sizeof(msg.mtext), 0); flag = 0; break; default: printf(&quot;Wrong input!\\n&quot;); /*清空标准输入缓冲区*/ while((c=getchar())!=&apos;\\n&apos; &amp;&amp; c!=EOF); &#125; &#125; // 断开连接 shmdt(shm); return 0;&#125; 五种通讯方式总结 管道：速度慢，容量有限，只有父子进程能通讯 FIFO：任何进程间都能通讯，但速度慢 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题 信号量：不能传递复杂消息，只能用来同步 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存 共享内存，管道，socket等进程间通信方式的优缺点共享内存可以说是最有用的进程间通信方式，也是最快的IPC形式。两个不同进程A、B共享内存的意思是，同一块物理内存被映射到进程A、B各自的进程地址空间。 进程A可以即时看到进程B对共享内存中数据的更新，反之亦然。由于多个进程共享同一块内存区域，必然需要某种同步机制，互斥锁和信号量都可以。 采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。 对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据： 一次从输入文件到共享内存区， 另一次从共享内存区到输出文件。 实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回 文件的。因此，采用共享内存的通信方式效率是非常高的。 进程间通信的方式有很多，常见的有信号量，消息队列，管道，共享内存，和socket等，这里我们主要讨论管道，共享内存，和socket，其他的比较简单只做简单的介绍。 信号量：信号量实际上是一个计数器，通常在多线程或者多进程开发中会用到，主要用来控制多线程多进程对于共享资源访问，通常配合锁来实现同时只有一个进程或者线程操作共享资源，防止数据的不同步。 消息队列：消息队列是消息的链表，存放在内核中并由消息队列表示符，我们可以在两个进程之间通过消息队列来实现进程间通信。不过消息队列在工作中好像并不怎么常用。 接下来主要谈谈剩下的三种，这些是我们经常会用到的。 管道分为有名管道和无名管道两种 无名管道 ：主要用于父进程与子进程之间，或者两个兄弟进程之间。在linux系统中可以通过系统调用建立起一个单向的通信管道，且这种关系只能由父进程来建立。因此，每个管道都是单向的，当需要双向通信时就需要建立起两个管道。管道两端的进程均将该管道看做一个文件，一个进程负责往管道中写内容，而另一个从管道中读取。这种传输遵循“先入先出”（FIFO）的规则。 有名管道：命名管道是为了解决无名管道只能用于近亲进程之间通信的缺陷而设计的。命名管道是建立在实际的磁盘介质或文件系统（而不是只存在于内存中）上有自己名字的文件，任何进程可以在任何时间通过文件名或路径名与该文件建立联系。为了实现命名管道，引入了一种新的文件类型——FIFO文件（遵循先进先出的原则）。实现一个命名管道实际上就是实现一个FIFO文件。命名管道一旦建立，之后它的读、写以及关闭操作都与普通管道完全相同。虽然FIFO文件的inode节点在磁盘上，但是仅是一个节点而已，文件的数据还是存在于内存缓冲页面中，和普通管道相同。 管道有很多致命的缺点，比如只能在具有亲缘关系的进程间通信，只能单向传输数据，另外管道的缓冲区是有限的（管道制存在于内存中，在管道创建时，为缓冲区分配一个页面大小，管道所传送的是无格式字节流，这就要求管道的读出方和写入方必须事先约定好数据的格式，最后就是管道操作不当很容易阻塞。因此管道虽然偶尔会见到，但是很少人会用。 共享内存：这个是经常用的，共享内存号称是最快的进程间通信方式，她在系统内存中开辟一块内存区，分别映射到各个进程的虚拟地址空间中，任何一个进程操作了内存区都会反映到其他进程中，各个进程之间的通信并没有像copy数据一样从内核到用户，再从用户到内核的拷贝。这种方式可以像访问自己的私有空间一样访问共享内存区，但是这事这种特性加大了共享内存的编程难度，对于数据的同步问题是一个难点，没有一定的经验很容易造成数据的混乱。但是我们可以使用一个折中的方法，我们可以结合它和管道来使用。 举个例子进程A和B通信，如果我们用一块共享内存区来实现它们的通信，对于数据的同步是个令人头疼的问题，但是我们可以用两个共享内存区。 内存区 1 ，A-&gt;B,A只能写数据，B只能读数据 内存区 2， B-&gt;A,A只能读数据，B只能写数据 这样就不会因为，多个进程同时写一块内存造成数据的混乱了，看起来是不是有点像管道，其实就是管道的机制，但是不同的是，她的速度要比管道快的多，他的数据大小没有限制（当然不能超过系统的内存大小），当然也不会有阻塞问题。但是这种方式也有明显的缺点，它只适合点对点的通信，如果要多个进程间通信，内存区的数量会呈线性增长，会造成数据的冗余，并且管理起来也会变得困难,如果你的进程数量在各位数着中方式是一个好的选择，否则就要采用一块共享内存，同时做好数据的同步了。 最后一点，通过名字就知道它是基于内存的，所以他只能在同一主机上使用，如果我们要做分布式应用或者跨物理机通信，那么socket就是我们唯一的选择了。 socket是一种面相网络的一种进程间通信方式，只要有网络存在，它可以跨越任何限制。socket编程是一个宽泛的说法，对于我们程序猿来说tcp，udp，http是我们经常用的一些网络协议。当然socket也是我们用的最多的，他的限制住要在与带宽，网络延时和连接数量的限制等。这也是我们在开发服务程序时都要面对c10k问题的原因。 进程同步信号量、管程、会合、分布式系统 信号量用于进程间传递信号的一个整数值。在信号量上只有三种操作可以进行：初始化，P操作和V操作，这三种操作都是原子操作。 P操作(递减操作)可以用于阻塞一个进程，V操作(增加操作)可以用于解除阻塞一个进程。 基本原理是两个或多个进程可以通过简单的信号进行合作，一个进程可以被迫在某一位置停止，直到它接收到一个特定的信号。该信号即为信号量s。 为通过信号量s传送信号，进程可执行原语semSignal(s);为通过信号量s接收信号，进程可执行原语semWait(s);如果相应的信号仍然没有发送，则进程被阻塞，直到发送完为止。 管程管程是由一个或多个过程、一个初始化序列和局部数据组成的软件模块，其主要特点如下： 局部数据变量只能被管程的过程访问，任何外部过程都不能访问。 一个进程通过调用管程的一个过程进入管程。 在任何时候，只能有一个进程在管程中执行，调用管程的任何其他进程都被阻塞，以等待管程可用。 管程通过使用条件变量提供对同步的支持，这些条件变量包含在管程中，并且只有在管程中才能被访问。有两个函数可以操作条件变量： cwait(c)：调用进程的执行在条件c上阻塞，管程现在可被另一个进程使用。 csignal(c)：恢复执行在cwait之后因为某些条件而阻塞的进程。如果有多个这样的进程，选择其中一个；如果没有这样的进程，什么以不做 会合一个进程可以有许多入口，一个入口对应一段程序，一个进程可 以调用另一个进程的入口。当一个进程调用另一个进程的入口， 而且被调用的进程已准备好接受这个调用时，会合就发生了。当 调用者发出调用请求时，被调用的进程未准备接受这个调用时， 则调用者等待；反之，当被调用者准备接受调用，而当前尚无调用者时，则被调用者等待。即先到达会合处等待后到达者。当多 个进程调用同一个进程的同一个入口时，被调用者按先来先服务 （FCFS）的次序接受调用。入口处可以携带调用参数，还可以有 返回参数，以实现信息的交换。被调用者可以选择会合的入口。 进程中线程同步 线程同步的四种方法： 临界区（Critical Section）通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。 优点：保证在某一时刻只有一个线程能访问数据的简便办法 缺点：虽然临界区同步速度很快，但却只能用来同步本进程内的线程，而不可用来同步多个进程中的线程。 互斥量（Mutex）为协调共同对一个共享资源的单独访问而设计的。 互斥量跟临界区很相似，比临界区复杂，互斥对象只有一个，只有拥有互斥对象的线程才具有访问资源的权限。 优点：使用互斥不仅仅能够在同一应用程序不同线程中实现资源的安全共享，而且可以在不同应用程序的线程之间实现对资源的安全共享。 缺点：互斥量是可以命名的，也就是说它可以跨越进程使用，所以创建互斥量需要的资源更多，所以如果只为了在进程内部是用的话使用临界区会带来速度上的优势并能够减少资源占用量。因为互斥量是跨进程的互斥量一旦被创建，就可以通过名字打开它。通过互斥量可以指定资源被独占的方式使用，但如果有下面一种情况通过互斥量就无法处理，比如现在一位用户购买了一份三个并发访问许可的数据库系统，可以根据用户购买的访问许可数量来决定有多少个线程/进程能同时进行数据库操作，这时候如果利用互斥量就没有办法完成这个要求，信号量对象可以说是一种资源计数器。 信号量（Semaphore）为控制一个具有有限数量用户资源而设计。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。互斥量是信号量的一种特殊情况，当信号量的最大资源数=1就是互斥量了。 优点：适用于对Socket（套接字）程序中线程的同步。（例如，网络上的HTTP服务器要对同一时间内访问同一页面的用户数加以限制，只有不大于设定的最大用户数目的线程能够进行访问，而其他的访问企图则被挂起，只有在有用户退出对此页面的访问后才有可能进入。） 缺点：信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点；信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重了程序员的编码负担； 核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和纠正。 事件（Event）用来通知线程有一些事件已发生，从而启动后继任务的开始。 优点：事件对象通过通知操作的方式来保持线程的同步，并且可以实现不同进程中的线程同步操作。 临界区不是内核对象，只能用于进程内部的线程同步，是用户方式的同步。互斥、信号量是内核对象可以用于不同进程之间的线程同步（跨进程同步）。互斥其实是信号量的一种特殊形式。互斥可以保证在某一时刻只有一个线程可以拥有临界资源。信号量可以保证在某一时刻有指定数目的线程可以拥有临界资源。 线程的创建和结束在一个文件内的多个函数通常都是按照main函数中出现的顺序来执行，但是在分时系统下，我们可以让每个函数都作为一个逻辑流并发执行，最简单的方式就是采用多线程策略。在main函数中调用多线程接口创建线程，每个线程对应特定的函数（操作），这样就可以不按照main函数中各个函数出现的顺序来执行，避免了忙等的情况。线程基本操作的接口如下。 创建线程int pthread_create(pthread_t pthread, const pthread_attr_t *attr, void *(start_routine)(void *), void *agr); 创建一个线程pthread和start_routine不可或缺，分别用于标识线程和执行入口，其他可以填NULL。 pthread：用来返回线程的id， *pthread值即为tid，类型为 pthread_t = unsigned long int attr：指向线程属性结构体的指针，用于改变所创建线程的属性，填NULL使用默认值 start_routine：线程执行函数的首地址，传入函数指针 arg：通过地址传递来传递函数参数，这里是无符号类型指针，可以传任意类型变量的地址，在被传入函数中先强制类型转换成所需类型即可。 获取线程IDpthread_t pthread_self(); 等待线程结束int pthread_join(pthread_t tid, void** reval) 主线程调用，等待子线程退出并回收资源，类似于进程中wait/waitpid回收僵尸进程，调用pthread_join线程会被阻塞 tid：创建线程时通过指针得到tid值 reval：指向返回值的指针 线程结束pthread_exit(void *retval) 子线程执行，用来结束当前线程并通过retval传递返回值，该返回值可通过pthread_join获得 分离线程主线程、子线程均可调用。主线程中pthread_detach(tid),子线程中pthread_detach(pthread_self()),调用后和主线程分离，子线程结束时自己立即回收资源。 线程属性对象类型为pthread_attr_t，结构体定义如下： 123456789101112typedef struct&#123; int etachstate; // 线程分离的状态 int schedpolicy; // 线程调度策略 struct sched_param schedparam; // 线程的调度参数 int inheritsched; // 线程的继承性 int scope; // 线程的作用域 // 以下为线程栈的设置 size_t guardsize; // 线程栈末尾警戒缓冲大小 int stackaddr_set; // 线程的栈设置 void * stackaddr; // 线程栈的位置 size_t stacksize; // 线程栈大小&#125;pthread_arrt_t； 线程状态新建状态、就绪状态、运行状态、阻塞状态(等待阻塞、同步阻塞、其他阻塞)、死亡状态 新建状态(New)：新创建了一个线程对象。 就绪状态(Runnable)：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于“可运行线程池”中，变得可运行，只等待获取CPU的使用权。即在就绪状态的进程除CPU之外，其它的运行所需资源都已全部获得。 运行状态(Running)：就绪状态的线程获取了CPU，执行程序代码。 阻塞状态(Blocked)：阻塞状态是线程因某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。 等待阻塞：运行的线程执行wait()方法，该线程会释放占用的所有资源，JVM会把该线程放入“等待池”中。进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()或notifyAll()方法才能被唤醒，唤醒后进入“锁池”中，通过获取锁状态来判断是否进入就绪状态 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入“锁池”中。 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。 死亡状态(Dead)：线程执行完了或者因异常退出了run()方法，该线程结束生命周期 线程共享进程哪些线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。 线程之间特有的：每个线程都有自己独立的线程上下文，包括线程ID、栈、栈指针、程序计数器、条件码和通用目的寄存器值。 线程之间共有的：共享进程上下文的剩余部分，包括只读文本（代码）、读/写数据、堆以及所有的共享库代码和数据区域。线程也共享相同的打开文件的集合。 线程间通信共享内存：共享内存这种方式比较常见，我们经常会设置一个共享变量。然后多个线程去操作同一个共享变量。从而达到线程通讯的目的。 消息传递：不同的线程之间通过显式的发送消息来达到交互目的。消息传递最有名的方式应该是actor模型了。每个actor都有一个收件箱（消息队列）用来保存收到其他actor传递来的消息。 处理机调度调度的类型与模型、调度算法、实时系统中的调度、多处理机调度 调度类型高级调度又称为“宏观调度”、“作业调度”。从用 户工作流程的角度，一次提交的若干个作业，对每个作 业进行调度。时间上通常是分钟、小时或天。 中级调度内外存交换：又称为“中级调度”。从存储器资源的角 度。将进程的部分或全部换出到外存上，将当前所需部 分换入到内存。指令和数据必须在内存里才能被CPU直 接访问。 低级调度低级调度：又称为“微观调度”、“进程或线程 调度”。从CPU资源的角度，执行的单位。时间上 通常是毫秒。因为执行频繁，要求在实现时达到 高效率。 何时进行调度 当一个新的进程被创建时，是执行新进程还是继 续执行父进程？ 当一个进程运行完毕时； 当一个进程由于I/O、信号量或其他的某个原因 被阻塞时； 当一个I/O中断发生时，表明某个I/O操作已经完 成，而等待该I/O操作的进程转入就绪状态； 在分时系统中，当一个时钟中断发生时 何时进行切换只要OS取得对CPU的控制，进程切换就可能发生: 用户调用：来自程序的显式请求(如：打开文件)， 该进程多半会被阻塞 陷阱：最末一条指令导致出错，会引起进程移至退出状态 中断：外部因素影响当前指令的执行，控制被转移 至中断处理程序 在进程（上下文）中切换的步骤： 保存处理器的上下文，包括程序计数器和其它寄 存器 用新状态和其它相关信息更新正在运行进程的 PCB 把进程移至合适的队列-就绪、阻塞 选择另一个要执行的进程 更新被选中进程的PCB 从被选中进程中重装入CPU 上下文 面向用户的调度性能准则周转时间：作业从提交到完成（得到结果）所经 历的时间。包括：在收容队列中等待，CPU上执行 ，就绪队列和阻塞队列中等待，结果输出等待－ －批处理系统 •外存等待时间、就绪等待时间、CPU执行时间、 I/O操作时间 •平均周转时间、带权平均周转时间（T/Ts) 响应时间：用户输入一个请求（如击键）到系统 给出首次响应（如屏幕显示）的时间－－分时系 统 截止时间：开始截止时间和完成截止时间－－实时系 统，与周转时间有些相似。 优先级：可以使关键任务达到更好的指标。 公平性：不因作业或进程本身的特性而使上述指标过 分恶化。如长作业等待很长时间。 面向系统的调度性能准则吞吐量：单位时间内所完成的作业数，跟作业本 身特性和调度算法都有关系－－批处理系统 •平均周转时间不是吞吐量的倒数，因为并发执行的 作业在时间上可以重叠。如：在2小时内完成4个作 业，而平均周转时间是1.25小时，则吞吐量是2个作 业/小时 处理机利用率：－－大中型主机 各种资源的均衡利用：如CPU繁忙的作业和I/O繁 忙（指次数多，每次时间短）的作业搭配－－大 中型主机 调度算法通常将作业或进程归入各种就绪或阻塞队列。有的算 法适用于作业调度，有的算法适用于进程调度，有的 两者都适应 不可抢占式方式 ，一旦处理器分配给一个进程，它就一直占用处理器 ，直到该进程自己因调用原语操作或等待I/O等原 因而进入阻塞状态，或时间片用完时才让出处理器 ，重新进行 抢占式方式 ，就绪队列中一旦有优先级高于当前运行进程优先级 的进程存在时，便立即进行进程调度，把处理器转 给优先级高的进程 先来先服务(FCFS, First Come First Service)这是最简单的调度算法，按先后顺序调度。 按照作业提交或进程变为就绪状态的先后次序，分 派CPU； 当前作业或进程占用CPU，直到执行完或阻塞，才 出让CPU（非抢占方式）。 在作业或进程唤醒后（如I/O完成），并不立即恢 复执行，通常等到当前作业或进程出让CPU。最简 单的算法。 FCFS的特点 比较有利于长作业，而不利于短作业。 有利于CPU繁忙的作业，不利于I/O繁忙的作业。 短作业优先(SJF, Shortest Job First)又称为“短进程优先”SPN(Shortest Process Next)； 这是对FCFS算法的改进，其目标是减少平均周转时间。 对预计执行时间短的作业（进程）优先分派处理机。通常 后来的短作业不抢先正在执行的作业。 优点： 比FCFS改善平均周转时间和平均带权周转时间，缩 短作业的等待时间； 提高系统的吞吐量； 缺点： 对长作业非常不利，可能长时间得不到执行； 未能依据作业的紧迫程度来划分执行的优先级； 难以准确估计作业（进程）的执行时间，从而影响 调度性能。 时间片轮转(Round Robin)算法本算法主要用于微观调度，设计目标是提高资源利用率。其基本 思路是通过时间片轮转，提高进程并发性和响应 时间特性，从而提高资源利用率； 将系统中所有的就绪进程按照FCFS原则，排成 一个队列。 每次调度时将CPU分派给队首进程，让其执行 一个时间片。时间片的长度从几个ms到几百ms 。 在一个时间片结束时，发生时钟中断。 调度程序据此暂停当前进程的执行，将其送到 就绪队列的末尾，并通过上下文切换执行当前 的队首进程。 进程可以未使用完一个时间片，就出让CPU（ 如阻塞）。 时间片长度变化的影响 •过长－&gt;退化为FCFS算法，进程在一个时间片内都 执行完，响应时间长。 •过短－&gt;用户的一次请求需要多个时间片才能处理 完，上下文切换次数增加，响应时间长。 对响应时间的要求：T(响应时间)=N(进程数目 )*q(时间片) 就绪进程的数目：数目越多，时间片越小 系统的处理能力：应当使用户输入通常在一个 时间片内能处理完，否则使响应时间，平均周 转时间和平均带权周转时间延长 优先级算法(Priority Scheduling)本算法是平衡各进程对响应时间的要求。适用于作业调度和 进程调度，可分成抢先式和非抢先式 静态优先级：创建进程时就确定，直到进程终止前都不改变。通常是 一个整数。依据： •进程类型（系统进程优先级较高） •对资源的需求（对CPU和内存需求较少的进程，优先级较 高） •用户要求（紧迫程度和付费多少） 动态优先级：在创建进程时赋予的优先级，在进程运行过程中 可以自动改变，以便获得更好的调度性能。如： •在就绪队列中，等待时间延长则优先级提高，从而 使优先级较低的进程在等待足够的时间后，其优先 级提高到可被调度执行； •进程每执行一个时间片，就降低其优先级，从而一 个进程持续执行时，其优先级降低到出让CPU。 高响应比优先调度算法：响应比=(执行时间＋等待时间）/执行时间；等待时间相同，短作业优先 ；要求服务时间相同，优先权决定于等待时间，（ FCFS) ；长作业等待时间长，优先权提高 多级队列算法(Multiple-level Queue)本算法引入多个就绪队列，通过各队列的区别对待 ，达到一个综合的调度目标； •根据作业或进程的性质或类型的不同，将就绪队列再分为 若干个子队列。 •每个作业固定归入一个队列。 不同队列可有不同的优先级、时间片长度、调度策 略等；在运行过程中还可改变进程所在队列。如： 系统进程、用户交互进程、批处理进程等。 多级反馈队列算法(Round Robin with Multiple Feedback)多级反馈队列算法时间片轮转算法和优先级算法的综合 和发展。优点： •为提高系统吞吐量和缩短平均周转时间而照顾短进程 •为获得较好的I/O设备利用率和缩短响应时间而照顾I/O 型进程 •不必估计进程的执行时间，动态调节 设置多个就绪队列，分别赋予不同的优先级，如逐级 降低，队列1的优先级最高。每个队列执行时间片的长 度也不同，规定优先级越低则时间片越长，如逐级加倍 新进程进入内存后，先投入队列1的末尾，按FCFS算法 调度；若按队列1一个时间片未能执行完，则降低投入 到队列2的末尾，同样按FCFS算法调度；如此下去，降 低到最后的队列，则按“时间片轮转”算法调度直到 完成。 仅当较高优先级的队列为空，才调度较低优先级的队 列中的进程执行。如果进程执行时有新进程进入较高 优先级的队列，则抢先执行新进程，并把被抢先的进 程投入原队列的末尾 死锁死锁是指多个进程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。例如，在某一个计算机系统中只有一台打印机和一台输入 设备，进程P1正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程P2 所占用，而P2在未释放打印机之前，又提出请求使用正被P1占用着的输入设备。这样两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态。 产生原因 系统资源的竞争 系统资源的竞争导致系统资源不足，以及资源分配不当，导致死锁。 进程运行推进顺序不合适 进程在运行过程中，请求和释放资源的顺序不当，会导致死锁。 死锁的四个必要条件 互斥条件：进程对于所分配到的资源具有排它性，即一个资源只能被一个进程占用，直到被该进程释放 请求和保持条件：一个进程因请求被占用资源而发生阻塞时，对已获得的资源保持不放。 不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用 循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。 避免死锁： 加锁顺序：当多个线程需要相同的一些锁，但是按照不同的顺序加锁，死锁就很容易发生。 加锁时限：另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行 死锁检测：死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。 死锁预防 我们可以通过破坏死锁产生的4个必要条件来 预防死锁，由于资源互斥是资源使用的固有特性是无法改变的。 破坏不可剥夺条件：一个进程不能获得所需要的全部资源时便处于等待状态， 破坏请求与保持条件：第一种方法静态分配即每个进程在开始执行时申请他所需要的全部资源。第二种是动态分配即每个进程在申请所需要的资源时他本身不沾油系统资源 破坏循环等待条件：采用资源有序分配基本思想是将系统中的所有资源顺序编号，将紧缺的、稀少的采用较大的编号吗，在申请资源时必须按照编号的顺序进行，一个进程只有在获得较小编号的资源才能申请较大编号的资源。 设备管理外设管理目的 提高效率：提高I/O访问效率，匹配CPU和多种不同处理速度 的外设 方便使用：方便用户使用，对不同类型的设备统一使用方法 ，协调对设备的并发使用 方便控制：方便OS内部对设备的控制：增加和删除设备，适 应新的设备类型 外设管理功能 提供设备使用的用户接口：命令接口和编程接口。 设备分配和释放：使用设备前，需要分配设备和相应的通道 、控制器。 设备的访问和控制：包括并发访问和差错处理。 I/O缓冲和调度：目标是提高I/O访问效率 I/O控制技术程序控制I/O(programmed I/O)I/O操作由程序发起，并等待操作完成。数据的每次读 写通过CPU。 缺点：在外设进行数据处理时，CPU只能等待。 中断驱动方式(interrupt-driven I/O)I/O操作由程序发起，在操作完成时（如数据可读或 已经写入）由外设向CPU发出中断，通知该程序。 数据的每次读写通过CPU。 优点：在外设进行数据处理时，CPU不必等待，可 以继续执行该程序或其他程序。 缺点：CPU每次处理的数据量少（通常不超过几个 字节），只适于数据传输率较低的设备。 直接存储访问方式(DMA, Direct Memory Access)由程序设置DMA控制器中的若干寄存器值（如内存始址 ，传送字节数），然后发起I/O操作，而后者完成内存 与外设的成批数据交换，在操作完成时由DMA控制器向 CPU发出中断。 优点：CPU只需干预I/O操作的开始和结束，而其中的 一批数据读写无需CPU控制，适于高速设备。 阻塞IO和非阻塞IO在进行网络编程时，我们常常见到同步(Sync)/异步(Async)，阻塞(Block)/非阻塞(Unblock)四种调用方式： 同步：所谓同步，就是在发出一个功能调用时，在没有得到结果之前，该调用就不返回。也就是必须一件一件事做,等前一件做完了才能做下一件事。例如普通B/S模式（同步）：提交请求-&gt;等待服务器处理-&gt;处理完毕返回 这个期间客户端浏览器不能干任何事 异步：异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。例如 ajax请求（异步）: 请求通过事件触发-&gt;服务器处理（这是浏览器仍然可以作其他事情）-&gt;处理完毕 阻塞：阻塞调用是指调用结果返回之前，当前线程会被挂起（线程进入非可执行状态，在这个状态下，cpu不会给线程分配时间片，即线程暂停运行）。函数只有在得到结果之后才会返回。有人也许会把阻塞调用和同步调用等同起来，实际上他是不同的。对于同步调用来说，很多时候当前线程还是激活的，只是从逻辑上当前函数没有返回而已。 例如，我们在socket中调用recv函数，如果缓冲区中没有数据，这个函数就会一直等待，直到有数据才返回。而此时，当前线程还会继续处理各种各样的消息。快递的例子：比如到你某个时候到A楼一层（假如是内核缓冲区）取快递，但是你不知道快递什么时候过来，你又不能干别的事，只能死等着。但你可以睡觉（进程处于休眠状态），因为你知道快递把货送来时一定会给你打个电话（假定一定能叫醒你）。 非阻塞：非阻塞和阻塞的概念相对应，指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。还是等快递的例子：如果用忙轮询的方法，每隔5分钟到A楼一层(内核缓冲区）去看快递来了没有。如果没来，立即返回。而快递来了，就放在A楼一层，等你去取。对象的阻塞模式和阻塞函数调用对象是否处于阻塞模式和函数是不是阻塞调用有很强的相关性，但是并不是一一对应的。阻塞对象上可以有非阻塞的调用方式，我们可以通过一定的API去轮询状 态，在适当的时候调用阻塞函数，就可以避免阻塞。而对于非阻塞对象，调用特殊的函数也可以进入阻塞调用。函数select就是这样的一个例子。 同步，就是我调用一个功能，该功能没有结束前，我死等结果。 异步，就是我调用一个功能，不需要知道该功能结果，该功能有结果后通知我（回调通知） 阻塞，就是调用我（函数），我（函数）没有接收完数据或者没有得到结果之前，我不会返回。 非阻塞， 就是调用我（函数），我（函数）立即返回，通过select通知调用者同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！ 阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！ 同步IO和异步IO的区别Linux系统中，所有的设备读写都可以看做文件的读写来操作，对文件的读写一般要经过内核态和用户态的切换，正因为有了切换才导致IO有同步和异步的说法。 通常IO分为两种：来自网络的IO；来自文件或设备的IO 阻塞IO和非阻塞IO的区别在于：应用程序的调用是否立即返回。 如何区别是同步IO还是异步IO？数据拷贝的时候是否阻塞；当请求被阻塞，就是同步IO，否则就是异步IO。 同步IO的特点： 同步IO指的是是用户进程触发IO操作并等待或者轮询的去查看IO操作是否就绪。 同步IO的执行者是IO操作的发起者，同步IO需要发起者进行内核态到用户态的数据拷贝过程，所以这里必须阻塞。 异步IO的特点： 异步IO是指用户进程触发IO操作以后就立即返回，继续做自己的事情，而当IO操作已经完成的时候会得到IO完成的通知。 异步IO的执行者是内核线程，内核线程会完成数据从内核态到用户态的拷贝，没有阻塞。 磁盘管理基本概念扇区（sector） 盘片被分成许多扇形的区域 磁道（track） 盘片上以盘片中心为圆心，不同半径的同心圆。 柱面（cylinder) •硬盘中，不同盘片相同半径的磁道所组成的圆柱。 每个磁盘有两个面，每个面都有一个磁头(head)。 磁盘调度算法先来先服务 最短寻道时间优先 提高磁盘I/O速度磁盘高速缓存的形式 •独立缓存 •以虚拟内存为缓存 数据交付 •直接交付 •指针交付 置换算法 周期性写回 •sync 文件系统文件系统是指操作系统中与文件管理有关的那部分软件 和被管理的文件以及实施管理所需要的一些数据结构的总体。 目的： 方便的文件访问和控制：以符号名称作为文件标识， 便于用户使用； 并发文件访问和控制：在多道程系统中支持对文件的 并发访问和控制； 统一的用户接口：在不同设备上提供同样的接口，方 便用户操作和编程； 多种文件访问权限：在多用户系统中的不同用户对同 一文件会有不同的访问权限； 优化性能：存储效率、检索性能、读写性能； 差错恢复：能够验证文件的正确性，并具有一定的差 错恢复能力； 操作系统为系统管理者和用户提供了对文件的透明存 取（按名存取） ，不必了解文件存放的物理机制和查找方法，只需给定一 个代表某段程序或数据的文件名称，文件系统就会自动 地完成对给定文件名称相对应的文件的有关操作 分布式Linux12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 ls -l 等同于 ll 显示当前目录下文件的属性 ls -d 仅列出目录 ls -al 显示当前目录下所有文件详细信息，包括隐藏文件 cd [~] [-] 切换目录 [~目前用户身份的主目录] [-前一个工作目录] chgrp 用户组 文件名 修改文件的用户组 chown 用户名 文件名 修改文件的所有者 chmod 770 文件名 修改文件的权限 cp A B 复制文件A为B rm A rm -r A 删除A 删除非空目录或文件A su root 切换为root用户 mkdir/rmdir 新建目录、删除一个空目录 mkdir -p test1/test2 创建多层空目录 mkdir -m 777 test2 创建目录时设定权限 touch 新建空的文件 man 命令 查询命令详细解释 bzip2 压缩文件 bunzip2 解压文件 nano 文本编辑器 pwd 显示当前目录 echo 打印 mv 文件名 目标位置 移动文件 mv A B 重命名A为B（目录或文件都可以） PATH=&quot;$PATH&quot;:/root 添加/root到环境变量中 vim 进入后按i可以输入 退出按ESC然后:wq 不保存退出 按ESC 然后:q! 一般模式中： /word 向下寻找word字符串 ?word 向上寻找word字符串 n 重复前一个查找 N 与 n反向重复查找 umask -S 查看目前用户在新建文件或目录时候的默认权限 find 搜索文件，很复杂，很多参数 tar -jcv -f 名字.tar.bz2 A 压缩“A”变成“名字.tar.bz2” tar -jtv -f 名字.tar.bz2 查询 tar -jxv -f 名字.tar.bz2 [-C 指定目录] 在当前目录解压 【-C 在指定目录解压】 groupadd A 新建用户组A groupdel A 删除用户组A groups [A] 查看自己所在的用户组，【查看A所在的用户组】usermod 该命令有很多参数，可以修改账号各个属性usermod -G XXX B 新建XXX用户组为B的支持用户组，B原来的用户组仍有（支持用户组不是当前用户组，有效用户组才是当前用户组） newgrp B 切换当前用户的有效用户组为B useradd A 新增用户A（必须要设置密码才能用） useradd -u 666 -g B -c &quot;XXX&quot; A 新增用户A，用户组为B，UID为666，账号全名是XXX passwd A 给用户A设置密码，若没有A，则是给自己设置密码，密码需要超过8个字符 echo &quot;XXX&quot; | passwd --stdin A 设置用户A的密码为XXX passwd -l A 使账号A密码失效（让其无法登陆） passwd -u A 使账号A密码恢复 passwd -S A 查询账号A密码状态 userdel -r A 删除用户A，连同用户主文件夹一起删除（慎用） setfacl -m u:A:rwx B 设置账户A针对文件B的权限为rwx（针对单独用户设置权限） setfacl -m g:A:rx B 设置用户组A针对文件B的权限为rx setfacl -b A 消除文件A的ACL权限 getfacl B 查询文件B的权限详情 ctrl+c 终止当前程序运行ctrl+alt+F1 切回图形界面ctrl+alt+F2-F7 切回命令行界面 yum install XXX CentOS的apt-get install XXX which XXX 检测某个XXX应用是否安装 reboot 重启服务器 ifconfig 查看Linux（包括本地虚拟机的Linux）的IP地址 shift+PgUp\\PgDn 命令行界面上下滚动启动命令 &amp; 在后台启动，不占用命令窗口，比如启动Redis的时候 ./redis-server &amp; kill -9 PID 关闭服务，比如某程序PID=6817 kill -9 6817 就关闭了这个服务 top 查看当前系统负载情况，如果是单核CPU 那么load average低于1说明没有线程等待netstat -nap| grep 5672 查看端口号5672是否被监听free -m 查看内存使用情况 ps -A 显示所有运行中的进程 netstat -nultp 查看当前正在使用的端口情况God status 查看当前部署的服务 god stop 服务名 停止服务 scp jinsong@IP地址:/路径 ./ 复制远程主机上的文件到当前目录 pwd 显示当前路径 top命令终端输入top之后，就是下面这样啦 前面是参数，后面就是进程和进程号之类的了 第一行：当前时间，系统运行时间，登录用户数量，平均负载（分别在5，10，15分钟内）这里是：早上9：37：19，系统运行了8分钟，1一个用户 第二行：显示了系统的进程总数，后面是相应的状态下的进程这里是：一共209个进程，1个是running状态，208个sleeping状态，0个stopped，0个zombie关于进程的状态，这里解释一下zombie：这个是僵尸进程，就是，这个进程其实已经结束了，它仅仅在进程列表中保留一个位置，记载该进程的状态信息等，僵尸进程不再占有内存空间，没有可执行程序，也不能被调用。。这个进程中存储着进程的各种信息，占用cpu啊，运行时间之类的。。。这个进程会被其父进程收集它的信息。。。 第三行：就是cpu的各种信息了参数说明如下：us：用户空间占cpu百分比sy：内核空间占cpu百分比ni：用户进程空间内改变过优先级的进程占用cpu百分比id：空闲cpu百分比wa：等待输入输出的cpu时间百分比hi：硬中断（处理硬件中断的cpu时间）si：软中断（处理软件中断的cpu时间）第四行、第五行：内存使用第一行：物理内存的使用，第二行：虚拟内存（交换空间）的使用。每一行的后面四个参数是：总的内存，已经使用的内存，空闲内存，缓冲内存第六行：表头，具体解释如下：PID： 进程ID进程的唯一标识符USER：进程ID 进程的唯一标识符PR：进程调度优先级，一个拥有更高进程优先级的进程拥有更大的机率得到处理器的处理。，”tr”值代表这些进程运行在实时态NI：进程的nice值（优先值）。越小意味着越高的优先级。VIRT：系统使用的虚拟内存RES：驻留内存大小，驻留内存是任务使用的非交换物理内存大小SHR：是进程使用的共享内存S：进程状态：D：不可中断的睡眠态R：运行态S：睡眠态T：被跟踪或已停止Z：僵尸态%CPU 自从上一次更新时到现在任务所使用的CPU时间百分比。%MEM 进程使用的可用物理内存百分比TIME+ 任务启动后到现在所使用的全部CPU时间，精确到百分之一秒。COMMAND 进程所使用的命令。 psps命令是最基本的进程查看命令，使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵尸、哪些进程占用了过多的资源等等。ps是显示瞬间进程的状态，并不动态连续；如果想对进程进行实时监控应该用top命令。 参数：-A ：所有的进程均显示出来，与 -e 具有同样的效用；-a ： 显示现行终端机下的所有进程，包括其他用户的进程；-u ：以用户为主的进程状态 ；x ：通常与 a 这个参数一起使用，可列出较完整信息。 输出格式规划：l ：较长、较详细的将该PID 的的信息列出；j ：工作的格式 (jobs format)-f ：做一个更为完整的输出 netstatnetstat命令用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 123456789101112131415161718192021222324252627282930列出所有端口情况[root@xiesshavip002 ~]# netstat -a # 列出所有端口[root@xiesshavip002 ~]# netstat -at # 列出所有TCP端口[root@xiesshavip002 ~]# netstat -au # 列出所有UDP端口列出所有处于监听状态的 Sockets[root@xiesshavip002 ~]# netstat -l # 只显示监听端口[root@xiesshavip002 ~]# netstat -lt # 显示监听TCP端口[root@xiesshavip002 ~]# netstat -lu # 显示监听UDP端口[root@xiesshavip002 ~]# netstat -lx # 显示监听UNIX端口显示每个协议的统计信息[root@xiesshavip002 ~]# netstat -s # 显示所有端口的统计信息[root@xiesshavip002 ~]# netstat -st # 显示所有TCP的统计信息[root@xiesshavip002 ~]# netstat -su # 显示所有UDP的统计信息显示 PID 和进程名称[root@xiesshavip002 ~]# netstat -p显示核心路由信息[root@xiesshavip002 ~]# netstat -rKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Ifacedefault gateway 0.0.0.0 UG 0 0 0 eth0192.168.130.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0[root@xiesshavip002 ~]# netstat -rn # 显示数字格式，不查询主机名称Kernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Iface0.0.0.0 192.168.130.1 0.0.0.0 UG 0 0 0 eth0192.168.130.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 awkawk是一个强大的文本分析工具。 相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 使用方法：awk ‘{patten + action}’ {filename} 尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。 awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。 通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。 find12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485查找文件find ./ -type f查找目录find ./ -type d查找名字为test的文件或目录find ./ -name test查找名字符合正则表达式的文件,注意前面的‘.*’(查找到的文件带有目录)find ./ -regex .*so.*\\.gz查找文件名匹配*.c的文件find ./ -name *.c查找文件更新日时在距现在时刻二天以内的文件find ./ -mtime -2查找文件更新日时在距现在时刻二天以上的文件find ./ -mtime +2查找文件更新日时在距现在时刻一天以上二天以内的文件find ./ -mtime 2查找文件更新日时在距现在时刻二分以内的文件find ./ -mmin -2查找文件更新日时在距现在时刻二分以上的文件find ./ -mmin +2查找文件更新日时在距现在时刻一分以上二分以内的文件find ./ -mmin 2查找空文件或空目录find ./ -empty查找权限为644的文件或目录(需完全符合)find ./ -perm 664查找用户/组权限为读写，其他用户权限为读(其他权限不限)的文件或目录find ./ -perm -664查找用户有写权限或者组用户有写权限的文件或目录find ./ -perm /220find ./ -perm /u+w,g+wfind ./ -perm /u=w,g=w查找所有者权限有读权限的目录或文件find ./ -perm -u=r查找用户组权限有读权限的目录或文件find ./ -perm -g=r查找其它用户权限有读权限的目录或文件find ./ -perm -o=r查找所有者为lzj的文件或目录find ./ -user lzj查找组名为gname的文件或目录find ./ -group gname查找文件的用户ID不存在的文件find ./ -nouser查找文件的组ID不存在的文件find ./ -nogroup查找文件size小于10个字节的文件或目录find ./ -size -10c查找文件size等于10个字节的文件或目录find ./ -size 10c查找文件size大于10个字节的文件或目录find ./ -size +10c查找文件size小于10k的文件或目录find ./ -size -10k查找文件size小于10M的文件或目录find ./ -size -10M查找文件size小于10G的文件或目录find ./ -size -10G grepLinux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 使用格式：grep [OPTIONS] PATTERN [FILE…] 例如：grep -i “s” /etc/passwd 常用参数：-c： 打印符合要求的行数（数目）-i ：忽略大小写-n：输出行和行号-v：打印不符合要求的行，即反选-A：后跟数字(有无空格都可以)，例如-A2 表示打印筛选行及前2行-B：后跟数字，例如-B2表示打印筛选行及后2行-C：后跟数字，例如-C2表示打印筛选行及前后各2行-o：只打印符合要求的内容，而非整行 wcwc命令的功能为统计指定文件中的字节数、字数、行数, 并将统计结果显示输出。 语法：wc [选项] 文件… 说明：该命令统计给定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。wc同时也给出所有指定文件的总统计数。字是由空格字符区分开的最大字符串。 该命令各选项含义如下： c 统计字节数。 l 统计行数。 w 统计字数。这些选项可以组合使用。输出列的顺序和数目不受选项的顺序和数目的影响。总是按下述顺序显示并且每项最多一列。行数、字数、字节数、文件名如果命令行中没有文件名，则输出中不出现文件名。统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 sedsed是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作，下面先了解一下sed的用法 sed命令行格式为： sed [-nefri] ‘command’ 输入文本 常用选项： -n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后， 则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 -e：直接在指令列模式上进行 sed 的动作编辑； -f：直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作； -r：sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法) -i：直接修改读取的档案内容，而不是由萤幕输出。 常用命令： a：新增，a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c：取代，c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d：删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p：列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～ s：取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！ head和tailhead [option] …filename… 选项：-n num 显示文件的前num行。 -c num 显示文件的前num个字节。 -c -n 显示文件除了最后n个字节的其他内容。 -q 隐藏文件名。 -v 显示文件名。tail [option] …filename… 选项：-n num 显示文件的后num行。 -r num 逆序显示filename最后10行。 -f 检视filename的尾部内容（相当于-n 10）。 正则表达式基本正则表达式：Basic REGEXP 1234567891011121314151617181920212223元字符 描述 ？ 匹配任意单个字符* 匹配任意字符[] 匹配指定范围内的任意单个字符[^] 匹配指定范围外的任意单个字符[:lower:] 小写字母[:upper:] 大写字母[:alpha:] 所有字母[:digit:] 数字[:alnum:] 所有数字和字母[:punct:] 标点符号[:space:] 空白字符\\? 匹配其前面的字符1次或0次\\&#123;m,n\\&#125; 匹配其前面的字符至少m次，至多n次^ 铆定行首，此字符后面的任意内容必须出现在行首$ 铆定行尾，此字符前面的任意内容必须出现在行尾^$ 表示空白行\\&lt;或\\b 铆定词首，其后面的任意字符必须作为单词的首部出现\\&gt;或\\b 铆定词尾，其前面的任意字符必须作为单词的尾部出现\\(\\) 分组\\(ab\\)* ab作为一个整体，可以出现任意次\\(ab\\).*\\1 引用第一个左括号以及与之对应的右括号所包括的所有内容\\(ab\\).*\\2 引用第二个左括号以及与之对应的右括号所包括的所有内容 扩展正则表达式：Extended REGEXP 1234567891011121314151617181920字符匹配. 匹配任意单个字符[] 匹配指定范围内的任意单个字符[^] 匹配指定范围外的任意单个字符次数匹配* 匹配其前字符任意次? 匹配其前字符0次或1次+ 匹配其前字符至少1次，类似于基本正则表达式\\&#123;1,\\&#125;&#123;m,n&#125; 匹配其前面的字符至少m次，至多n次位置铆定^ 行首$ 行尾\\&lt;或\\b 词首\\&gt;或\\b 词尾分组().*\\1\\2\\3 或者| or a|b ，a或者b ，有一个就行 C|cat--&gt; C或cat(C|c)at--&gt;Cat或cat 如何查找出现频率最高的100个IP地址查看日志中访问次数最多的前10个IPcat access_log | cut –d ‘ ’ –f 1 | sort | uniq –c | sort –nr | awk ‘{print $0}’ | head –n 100 | less 查看日志中出现100次以上的IPcat access_log | cut –d ‘ ’ –f 1 |sort |uniq -c | awk ‘{if($1&gt;100) print $0}’ | sort –nr | less linux如何统计文件中某个字符串出现的频率 grep+wcgrep –o targetStr finename | wc –l #单个字符串grep –o ‘targetStr1\\|targetStr2’ finename | wc –l #多个字符串 awkawk –v RS=”@#$j” ‘{print gsub(/targetstr/,”$”}’ filename linux启动的第一个进程init进程是内核启动的第一个进程，它是后续进程的发起者。 内核启动init进程的过程如下： 打开标准输入、标准输出、标准错误文件。 如果radmdisk_execute_command指定了要运行的程序，则启动它。 如果excute_command指定了要运行的程序，则启动它。 依次尝试执行/sbin/init、/etc/init、/bin/init、/bin/sh。 linux查看端口占用 lsof –i #查看所有的服务端口。 lsof –i:端口号 #查看占用端口 netstat –a #查看所有的服务端口。 netstat –an | grep 端口号 #检验下是不是已经打开了某端口。 linux查看CPU和内存使用 ps命令可以实时的现实各个进程的内存使用情况。 top命令提供了实时的运行中的程序的资源使用统计。 atop命令是一个终端环境的监控命令。 /proc/meminfo查看RAM使用情况最简单的方法是通过查看/proc/meminfo文件。 free命令是一个快速查看内存使用情况的方法，它是对/proc/meminfo收集到的信息的一个概述。 Linux查看系统负载命令 top uptime w vmstat Linux调试程序 printf语句。 查询(cpu信息，内存容量)。 跟踪工具- strace的和ltrace是两个在Linux中用来追踪程序的执行细节的跟踪工具。 GDB-来自自由软件基金会的调试器。当被调试的程序运行时，它给用户控制权去执行各种动作。比如:启动程序停在指定位置停在指定的条件检查所需信息改变程序中的数据。你也可以将一个崩溃的程序coredump附着到GDB并分析故障的原因。 Linux硬链接和软连接硬链接总结：（类似于shared_ptr智能指针） 具有相同inode（索引节点）号的多个文件互为硬链接文件； 删除硬链接文件或者删除源文件任意之一，文件实体并未被删除； 只有删除了源文件和所有对应的硬链接文件，文件实体才会被删除； 硬链接文件是文件的另一个入口； 可以通过给文件设置硬链接文件来防止重要文件被误删； 创建硬链接命令 ln 源文件 硬链接文件； 硬链接文件是普通文件，可以用rm删除； 对于静态文件（没有进程正在调用），当硬链接数为0时文件就被删除。注意：如果有进程正在调用，则无法删除或者即使文件名被删除但空间不会释放。 软连接总结： 软链接类似windows系统的快捷方式； 软链接里面存放的是源文件的路径，指向源文件； 删除源文件，软链接依然存在，但无法访问源文件内容； 软链接失效时一般是白字红底闪烁； 创建软链接命令 ln -s 源文件 软链接文件； 软链接和源文件是不同的文件，文件类型也不同，inode号也不同； 软链接的文件类型是“l”，可以用rm删除。 linux文件系统网络文件系统：如 nfs、cifs 等；磁盘文件系统：如 ext4、ext3 等；特殊文件系统：如 proc、sysfs、ramfs、tmpfs 等。 core dump当程序运行过程中异常终止或崩溃，操作系统会将程序当时的内存状态记录下来，保存在一个文件中，这种行为就叫做core dump（核心转储）。但实际上，除了内存信息之外，还有些关键的程序运行状态也会同时 dump 下来，例如寄存器信息（包括程序指针、栈指针等）、内存管理信息、其他处理器和操作系统状态和信息。core dump文件可以再现程序出错时的情景。 参考《操作系统实用教程》 https://blog.csdn.net/guowenyan001/article/details/9190585 https://blog.csdn.net/u014303647/article/details/88752856 https://blog.csdn.net/zhyfxy/article/details/70157248 https://blog.csdn.net/u012349696/article/details/51154364 https://blog.csdn.net/u010318270/article/details/81058090 https://www.cnblogs.com/lustar/p/7716165.html https://blog.csdn.net/Jacoob1024/article/details/81097721 https://blog.csdn.net/u011726005/article/details/82670730 https://blog.csdn.net/wujiafei_njgcxy/article/details/77116175 https://blog.csdn.net/lovenankai/article/details/6874475 http://www.cnblogs.com/zgq0/p/8780893.html http://blog.csdn.net/fengye245/article/details/7783717 https://blog.csdn.net/qq_38211852/article/details/80211169 https://www.jianshu.com/p/6a6845464770 https://blog.csdn.net/qq546770908/article/details/53082870 https://blog.csdn.net/misszhoudandan/article/details/81173046 https://blog.csdn.net/Misszhoudandan/article/details/81193227 https://www.cnblogs.com/hadoop-dev/p/6899171.html https://www.cnblogs.com/bopo/p/9228834.html https://www.cnblogs.com/Peter2014/p/7594504.html https://www.cnblogs.com/bokeyuan-dlam/articles/9157857.html https://blog.csdn.net/qq_36357820/article/details/76606113 https://www.cnblogs.com/zhuiluoyu/p/6154898.html https://www.cnblogs.com/CEO-H/p/7794306.html https://blog.csdn.net/chuhongcai/article/details/53931371 https://blog.csdn.net/qq43599939/article/details/78873150 https://www.cnblogs.com/ginvip/p/6376049.html https://blog.csdn.net/freeking101/article/details/53404897 http://www.cnblogs.com/csj2018/p/9158963.html https://www.cnblogs.com/bigbean/p/3669739.html https://www.cnblogs.com/xiaoleiel/p/8349487.html https://www.cnblogs.com/ftl1012/p/netstat.html https://www.cnblogs.com/wxgblogs/p/6591980.html https://blog.csdn.net/abc15766228491/article/details/79339208","tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://www.ylovex.cn/tags/操作系统/"}]},{"title":"java多线程基础","date":"2019-07-16T13:55:11.000Z","path":"2019/07/16/java多线程基础/","text":"Java多线程基础并行基础概念同步和异步同步和异步通常是形容一次方法的调用，同步方法调用一旦开始，调用者必须等到方法调用返回后才能继续后续的行为；异步调用更像一个消息传递，一旦开始，方法调用就会立即放回，调用者可以继续后续的操作，而异步方法通常会在另外一个线程中“真实”的执行。 并发与并行并发侧重于多个任务交替执行，并行是真实的同时执行，真实的并行只可能出现在多核CPU中 临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用，但是一次只能有一个线程使用，一旦临界区资源被占用，其他线程想到使用这个资源必须等待 阻塞和非阻塞当一个线程占用了临界区资源，其他所以需要这个资源的线程就必须在这个临界区中进行等待，等待会导致线程挂起，这种情况就是阻塞。 死锁、饥饿、活锁死锁是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。 饥饿是某一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行。 活锁是两个线程主动将资源释放给对方用，那么就会出现资源不断在两个线程中跳动，而没有一个线程可以同时拿到所有资源而正常执行。 并发级别可以分为阻塞、无饥饿、无障碍、无锁、无等待等 一个线程是阻塞的，那么在其他线程释放资源之前，当前线程无法继续执行。当使用synchronized关键字或者重入锁，得到的就是阻塞的线程 如果线程之间是有优先级的，那么线程调度的时候总会倾向于满足高优先级的线程，对于非公平锁来说，系统允许高优先级的线程插队。这样有可能导致低优先级线程产生饥饿。但如果锁是公平的，满足先来后到，那么饥饿就不会产生 无障碍是一种最弱的非阻塞调度。两个线程如果是无障碍的执行，那么他们不会因为临界区的问题导致一方挂起，对于无障碍线程，当检测到多个线程修改共享数据就会立即对自己所做的修改进行回滚，确保数据安全，如果没有数据竞争发生就可以顺利完成任务 无锁的并行都是无障碍的，在无锁的情况下，所有的线程都尝试对临界区进行访问，但不同的是无锁的并发保证必然有一个线程能够在有限步内完成操作离开临界区 无等待在无锁的基础上更进一步，要求所有的线程都必须在有限步内完成，一种典型的无等待结构就是RCU（Read-Copy-Update）基本思想是对数据的读可以不就控制，但在写数据的时候，先取得原始数据的副本，接着只修改副本数据，修改完成后，在合适的时机回写数据 原子性是指一个操作是不可中断的，即使是多个线程一起执行的时候，一个操作一旦开始就不会被其他线程干扰 可见性是指一个线程修改了某一个共享变量的值，其他线程是否能够立即知道这个修改 有序性程序在执行时，可能会进行指令重排，重排后的指令与原指令的顺序未必一致 Java并行基础进程与线程进程是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位 线程是程序执行的最小单位，使用多线程而不是多进程进行并发程序设计是因为线程间的切换和调度的成本远小于进程 线程生命周期 New状态当使用new创建一个Thread对象时候，此时并不处于执行状态 Runnable状态调用start方法后，那么此时才是真正在JVM进程中创建了一个线程，该状态线程位于可运行线程池中，等待被线程调度选中，获取cpu的使用权 Running状态可运行状态（Runnable）的线程获得CPU时间片，执行程序代码 Blocked状态是指线程因为某种原因放弃了cpu的使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种： 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或运行在当前线程里的其它线程调用了join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。 Dead状态线程run(),main()方法执行结束，或者因为异常退出了run()方法，则该线程结束生命周期 线程基本操作新建线程只需要使用new关键字创建一个线程对象，并且将它start()起来即可 12Thread t1 = new Thread();t1.start(); start()方法就会新建一个线程并让这个线程执行run()方法 如果直接调用run()方法不会新建一个线程，而是只会在当前线程中，串行执行run()中的代码 继承Thread创建线程 实现Runnanle接口创建线程 实现Callable接口通过FutureTask包装器来创建线程 使用ExecutorService、Callable、Future实现有返回结果的线程 终止线程stop()方法，可以立即将线程终止，已被标记为废弃 强行把执行到一半的线程终止，可能会引起一些数据不一致问题 线程中断线程中断不会使线程立即退出，而是给线程发送一个通知告知目标线程希望其退出，至于目标线程接到通知后如何处理则完全由线程自行决定 123public void Thread.interrupt() //中断线程public boolean Thread.isInterrupted() //判断是否被中断public static boolean Thread.interrupted() //判断是否被中断，并清除当前中断状态 Thread.interrupt()是一个实例方法，它通知目标线程中断，也就是设置设置中断标志位。中断标志位表示当前线程已经被中断了。Thread.isInterrupted()方法也是实例方法，它判断当前线程是否被中断（通过检查中断标志位）。Thread.interrupted()是静态方法，也是判断中断状态，但同时会清除当前线程的中断标志位状态。 interrupted()作用于当前线程，interrupt()和isInterrupted()作用于调用此方法的实例所代表的线程 12public static void sleep(long millis) throws InterruptedExceptionpublic static void sleep(long millis, int nanos) throws InterruptedException sleep()方法会让当前线程休眠若干时间，它会抛出一个InterruptedException中断异常。InterruptedException不是运行时异常，也就是程序必须捕获处理，当线程在sleep()休眠时，如果被中断，这个异常就会产生 wait和notify这两个方法输出Object类，任何对象都可以调用 当在一个对象实例上调用了wait方法后，当前线程就会在这个对象上等待，比如一个线程调用了object.wait()，那么它就会进入这个object对象的等待队列。这个等待队列中可能有多个线程在等待，当object.notify()被调用的时候，就会从这个等待队列中随机选择一个线程唤醒，这个选择是不公平的，完全随机的 notifyAll()方法会唤醒在这个等待队列中所有的等待的线程 wait()和notify()方法必须包含哎对应的synchronzied语句中，都需要首先获得目标对象的一个监视器， wait和sleep方法都可以让线程等待若干时间，wait方法会释放目标对象的锁，而sleep方法不会释放任何资源 挂起suspend和继续执行resume线程不推荐使用，suspend方法在导致线程暂停的同时，并不会去释放任何锁资源，直到对应线程上进行了resume方法被挂起的线程才能继续，从而其他所有阻塞在相关锁上的线程也可以继续执行，但是如果resume操作意外的在suspend前执行会导致所占用的锁不会被释放。 等待线程结束join和谦让yield当一个线程的输入可能非常依赖另外一个或者多个线程的输出时候。此时这个线程就需要等待依赖线程执行完毕才能继续执行 12public final void join() throws InterruptExceptionpublic final synchronized void join(long millis) throws InterruptedException 第一个join方法表示无限等待，它会一直阻塞当前线程，直到目标线程执行完毕，第二个方法给出了一个最大等待时间，如果超过给定时间目标线程还在执行，当前线程也会因为等不及了而继续往下执行 join方法本质是让调用线程wait()在当前线程对象实例上，它让调用线程在当前对象上进行等待，当线程执行完成后，被等待的线程会在退出前调用notifyAll通知所有的等待线程继续执行 。因此不要在应用程序中，在Thread对象实例上使用类似wait或者notify等方法 yield方法是一个静态方法，会使当前线程让出CPU，但是让出后该线程还会进行CPU资源的争夺 volatile与Java内存模型（JMM）在计算机中，所有的运算操作都是由CPU的寄存器完成，CPU指令的执行过程需要涉及数据的读取和写入操作，由于CPU的处理速度和内存的访问速度之间的差距越来越大，增加了缓存的设计 由于缓存的出现，极大地提高了CPU的吞吐模型，但是同时也引入了缓存不一致的问题，比如i++操作，在程序的运行过程中，首先需要将主内存中的数据复制一份存放到CPU Cache中，那么CPU寄存器在进行数值计算的时候就直接到Cache中读取和写入，当整个过程运算结束之后再将Cache中的数据刷新到主存当中， i++在单线程中不会出现问题，但是在多线程中就会出现问题，为了解决缓存不一致的问题，通常主流解决办法有：通过总线加锁的方式，通过缓存一致性协议 在缓存一致性协议中最为出名的是Intel的MESI协议，MESI协议保证了每一个缓存中使用的共享变量副本都是一致的，它的大致思想是，当CPU在操作Cache数据的时，如果发现该变量是一个共享变量，也就是说在其他CPU Cache中也存在一个副本，那么： 读取操作，不做任何处理，只是将Cache中的数据读取到寄存器 写入操作，发出信号通知其他CPU将该变量的Cache line置为无效状态，其他CPU在进行该变量读取的时候不得不到主内存中再次获取 Java内存模型 Java内存模型决定了一个线程对共享变量的写入何时对其他线程可见，Java内存模型定义了线程和主内存之间的抽象关系，具体有： 共享内存存储在主内存之中，每个线程都可以访问 每个线程都有私有的工作内存或者称为本地内存 工作内存只存储该线程对共享变量的副本 线程不能直接操作主内存，只有先操作了工作内存之后才能写入主内存 工作内存和Java内存模型一样也是一个抽象的概念，它其实并不存在，它涵盖了缓存、寄存器、编译器优化以及硬件等 JMM与原子性对基本数据类型的变量读取赋值操作是原子性，对引用类型的变量读取和赋值操作也是原子性的 x=10 原子性 y=x 非原子 y++ 非原子 z=z+1 非原子 JMM只保证了基本读取和赋值的原子性操作，如果想要使得某些代码片段具备原子性，需要使用关键字synchronized，或者JUC中的lock。如果想要使得int等类型自增操作具备原子性，可以使用JUC包下的原子封装类型java.util.concurrent.atomic.* volatile关键字不具备原子性的语义 JMM与可见性使用关键字volatile，当一个变量被volatile关键字修饰时，对于共享资源的读操作会直接在主内存中进行（当然也会缓存到工作内存中，当其他线程对该共享资源进行了修改，则会导致当前线程在工作内存中的共享资源失效，所以必须从主内存中再次获取），对于共享资源的写操作要先修改工作内存，但是修改结束后会立刻将其刷新到主内存中 同通过synchronized关键字，能够保证同一个时刻只有一个线程获得锁，然后执行同步方法，并且还会确保在锁释放之前，会将对变量的修改刷新到主内存中 通过JUC提供的显式锁Lock JMM与有序性在Java内存模型中，允许编译器和处理器对指令进行重排列， 使用volatile 使用synchronized 使用Lock happens-before原则 程序次序规则：在一个线程内，代码按照编写时的次序执行，但是虚拟机还是可能会对程序代码的指令进行重排序，只要确保在一个线程内最终的结果和代码顺序执行的结果一致 锁定原则：一个unlock操作要先发生于对同一个锁的lock操作 volatile变量规则：对一个变量的写操作要早与对这个变量之后的读操作 传递规则：如果A操作先于B，B先于C，则A肯定先于C 线程启动规则：Thread对象的start方法要先行发生于对该线程的任何动作 线程中断规则：对线程执行interrupt方法肯定要优先于捕获到中断信号 线程终结规则：线程中所有的操作都要先行发生于线程的终止检测 对象的终结规则：一个对象初始化的完成要先行发生在finalize()方法前 volatile 被volatile修饰的实例变量或者类变量具备如下两层语义： 保证了不同线程之间对共享变量操作的可见性 禁止对指令进行重排序操作 volatile原理 被volatile修饰的变量存在于一个“lock；”的前缀中， “lock；”前缀实际上相当于一个内存屏障，该内存屏障会为指令的执行提供如下几个保证： 确保指令重排序时不会将后面的代码排到内存屏障之前 确保指令重排序时不会将前面的代码排到内存屏障后 确保在执行到内存屏障修饰的指令时在前面的代码全部执行完成 强制将线程工作内存中的值修改刷新到主内存 如果是写操作，则会导致其他线程工作内存总的缓存数据失效 volatile和synchronized使用上的区别 volatile关键字只能用于修饰实例变量或者类变量，不能用于修饰方法以及方法参数和局部变量、常量等 synchronized关键字不能用于对变量的修饰，只能用于修饰方法或者语句块 volatile修饰的变量可以为null，synchronized同步语句块的monitor对象不能为null 对原子性的保证 volatile不能保证原子性 synchronized可以保证代码的原子性 对可见性的保证 都可以保证共享资源在多线程的可见性 synchronized借助JVM指令monitor enter和monitor exit对通过排他的方式使得同步代码串行化，在monitor exit时所有共享资源都将刷新到主内存 volatile使用机器指令（偏硬件）“lock；”的方式迫使其他线程工作内存中的数据失效，不得不在主内存进行再次加载 对有序性保证 volatile禁止JVM编译器以及处理器对其进行重排序，所以保证有序性 synchronized所修饰的同步方法也可以保证顺序性，但是这种顺序性是以程序的串行化执行换来的，在synchronized关键字所修饰的代码块代码指令中也会发生指令重排序情况 其他 volatile不会使线程陷入阻塞 synchronized会使线程进入阻塞 线程组 在Thread的构造函数中，可以显示的指定线程的Group，也就是ThreadGroup，下面看init方法的中间部分: 123456789101112131415if (g == null) &#123; /* Determine if it's an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) &#123; g = security.getThreadGroup(); &#125; /* If the security doesn't have a strong opinion of the matter use the parent thread group. */ if (g == null) &#123; g = parent.getThreadGroup(); &#125;&#125; 如果在构造Thread的时候没有显示的指定一个ThreadGroup，那么子线程将会被加入父线程所在的线程组 守护线程 守护线程是在后台默默完成一些系统性的服务，比如垃圾回收线程、JIT线程；与之对应的是用户线程，用户线程是系统的工作线程，完成这个程序要完成的业务操作。当用户线程全部结束，只有守护线程时候，Java虚拟机自然退出 setDaemon 方法。isDaemon() 方法可以判断该线程是不是守护线程。 另外需要注意的就是，setDaemon() 方法只在线程启动之前才能生效，如果一个线程已经死亡，那么再设置 setDaemon() 则会抛出 IllegalThreadStateException 异常。 synchronized使用指定加锁对象：对给定对象加锁，进入同步代码前要获得给定对象的锁 直接作用于实例方法：相当于对当前实例加锁，进入同步代码前要获得当前实例的锁 直接作用于静态方法：相当于对当前类加锁，进入同步代码前要获得当前类的锁 对象的同步Synchronized的底层是通过monitor来完成每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下： 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。 如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1. 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。 释放锁则是通过monitorexit指令，执行monitorexit的线程必须是objectref所对应的monitor的所有者，指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。 方法的synchronized同步：相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。 JDK并发包ReentranLock重要方法： lock():获得锁，如果锁已经被占用，则等待 lockInterruptibly():获得锁，但是优先响应中断 tryLock()：尝试获得锁，如果成功返回true，失败返回flae。该方法不等待，立即返回 tryLock(long time , TimeUnit nuit)：在给定时间内尝试获得锁 unlock()：释放锁 在重入锁实现中主要包含三个要素： 原子状态。原子状态使用CAS操作来存储当前锁的状态，判断锁是否已经被别的线程持有；以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 等待队列。所有没有请求到锁的线程，会进入等待队列进行等待。待有线程释放锁后，系统就能从等待队列中唤醒一个线程，继续工作 阻塞原语park()和unpark(),用于挂起和恢复线程,没有得到锁的线程将会被挂起 Condition通过Lock接口的Condition newCondition()方法可以生成一个与当前重入锁绑定的Condition实例。利用Condition对象，可以让线程在合适的时间等待，或者在某一个特定的时刻得到通知，继续执行 Condition接口方法有： 123456void await() throws InterruptedException;void awaitUninterruptibly();long awaitNanos(long nanosTimeout) throws InterruptedException;boolean await(long time, TimeUnit unit) throws InterruptedException;boolean awaitUntil(Date deadline) throws InterruptedException;void signal(); 信号量信号量可以指定多个线程，同时访问某一个资源 123456public Semaphore(int permits) &#123; sync = new NonfairSync(permits); &#125;public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; 在构造信号量对象时，必须要指定信号量的准入数，当每个线程每次只申请一个许可时，就相当于指定了同时可以有多少个线程可以访问某个资源 12345678910111213141516 public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public void acquireUninterruptibly() &#123; sync.acquireShared(1); &#125; public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;= 0; &#125;public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; public void release() &#123; sync.releaseShared(1); &#125; 简单实例如下 12345678910111213141516171819202122public class SemapDemo implements Runnable &#123; final Semaphore semp = new Semaphore(5); @Override public void run() &#123; try &#123; semp.acquire(); Thread.sleep(2000); System.out.print(Thread.currentThread().getId()+&quot;:done&quot;); semp.release(); &#125;catch (InterruptedException e )&#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args)&#123; ExecutorService executorService = Executors.newFixedThreadPool(20); final SemapDemo demo = new SemapDemo(); for(int i=0;i&lt;20;i++)&#123; executorService.submit(demo); &#125; &#125;&#125; ReadWriteLock读写锁​ 12345678910111213141516171819202122232425262728* &lt;pre&gt; &#123;@code * class RWDictionary &#123; * private final Map&lt;String, Data&gt; m = new TreeMap&lt;String, Data&gt;(); * private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); * private final Lock r = rwl.readLock(); * private final Lock w = rwl.writeLock(); * * public Data get(String key) &#123; * r.lock(); * try &#123; return m.get(key); &#125; * finally &#123; r.unlock(); &#125; * &#125; * public String[] allKeys() &#123; * r.lock(); * try &#123; return m.keySet().toArray(); &#125; * finally &#123; r.unlock(); &#125; * &#125; * public Data put(String key, Data value) &#123; * w.lock(); * try &#123; return m.put(key, value); &#125; * finally &#123; w.unlock(); &#125; * &#125; * public void clear() &#123; * w.lock(); * try &#123; m.clear(); &#125; * finally &#123; w.unlock(); &#125; * &#125; * &#125;&#125;&lt;/pre&gt; CountDownLatch通常用来控制线程等待， 123456789101112131415161718192021222324252627282930* &lt;pre&gt; &#123;@code * class Driver2 &#123; // ... * void main() throws InterruptedException &#123; * CountDownLatch doneSignal = new CountDownLatch(N); * Executor e = ... * * for (int i = 0; i &lt; N; ++i) // create and start threads * e.execute(new WorkerRunnable(doneSignal, i)); * * doneSignal.await(); // wait for all to finish * &#125; * &#125; * * class WorkerRunnable implements Runnable &#123; * private final CountDownLatch doneSignal; * private final int i; * WorkerRunnable(CountDownLatch doneSignal, int i) &#123; * this.doneSignal = doneSignal; * this.i = i; * &#125; * public void run() &#123; * try &#123; * doWork(i); * doneSignal.countDown(); * &#125; catch (InterruptedException ex) &#123;&#125; // return; * &#125; * * void doWork() &#123; ... &#125; * &#125;&#125;&lt;/pre&gt; * CyclicBarrier也可以实现线程间的计数等待，但是计数器可以循环使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344* &lt;pre&gt; &#123;@code* class Solver &#123;* final int N;* final float[][] data;* final CyclicBarrier barrier;** class Worker implements Runnable &#123;* int myRow;* Worker(int row) &#123; myRow = row; &#125;* public void run() &#123;* while (!done()) &#123;* processRow(myRow);** try &#123;* barrier.await();* &#125; catch (InterruptedException ex) &#123;* return;* &#125; catch (BrokenBarrierException ex) &#123;* return;* &#125;* &#125;* &#125;* &#125;** public Solver(float[][] matrix) &#123;* data = matrix;* N = matrix.length;* Runnable barrierAction =* new Runnable() &#123; public void run() &#123; mergeRows(...); &#125;&#125;;* barrier = new CyclicBarrier(N, barrierAction);** List&lt;Thread&gt; threads = new ArrayList&lt;Thread&gt;(N);* for (int i = 0; i &lt; N; i++) &#123;* Thread thread = new Thread(new Worker(i));* threads.add(thread);* thread.start();* &#125;** // wait until done* for (Thread thread : threads)* thread.join();* &#125;* &#125;&#125;&lt;/pre&gt;* LockSupport可以在线程内任意位置让线程阻塞。和Thread。suspend相比，弥补了由于resume在前发生，导致线程无法继续执行的情况。和Object.wait相比，它不需要先获得某个对象的锁，也不会抛出InterruptedException异常 123456789101112131415161718192021222324252627282930* &lt;pre&gt; &#123;@code * class FIFOMutex &#123; * private final AtomicBoolean locked = new AtomicBoolean(false); * private final Queue&lt;Thread&gt; waiters * = new ConcurrentLinkedQueue&lt;Thread&gt;(); * * public void lock() &#123; * boolean wasInterrupted = false; * Thread current = Thread.currentThread(); * waiters.add(current); * * // Block while not first in queue or cannot acquire lock * while (waiters.peek() != current || * !locked.compareAndSet(false, true)) &#123; * LockSupport.park(this); * if (Thread.interrupted()) // ignore interrupts while waiting * wasInterrupted = true; * &#125; * * waiters.remove(); * if (wasInterrupted) // reassert interrupt status on exit * current.interrupt(); * &#125; * * public void unlock() &#123; * locked.set(false); * LockSupport.unpark(waiters.peek()); * &#125; * &#125;&#125;&lt;/pre&gt; */ 线程池为了避免系统频繁地创建和销毁线程，可以让创建的线程进行复用 Executor 框架是 Java 5 中引入的，其内部使用了线程池机制，它在 java.util.cocurrent 包下，通过该框架来控制线程的启动、执行和关闭，可以简化并发编程的操作。因此，在 Java 5之后，通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题——如果我们在构造器中启动一个线程，因为另一个任务可能会在构造器结束之前开始执行，此时可能会访问到初始化了一半的对象用 Executor 在构造器中。 Executor 框架包括：线程池，Executor，Executors，ExecutorService，CompletionService，Future，Callable 等 线程池类型12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 该方法返回一个固定线程数量的线程池，当有一个新任务提交的时候，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 该方法返回一个只有一个线程的线程池，若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 该方法返回一个可根据实际情况调整线程数量的线程池。当有线程来的时候且现在线程池的线程都在工作的时候，才创建新的线程，否则使用空闲的线程，默认情况下，如果某个线程空闲超过60秒就会自动结束 1234public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); &#125; 该方法返回一个ScheduledExecutorService对象，线程池的大小为1，扩展了在给定时间执行某任务的功能，如在某个固定的延时之后执行，或者周期性执行某个任务 123public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125; 该方法返回一个ScheduledExecutorService对象，但该线程池可以指定线程数量 ForkJoinPoll 核心思想就是分治，Fork分解任务，Join收集数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class CountTask extends RecursiveTask&lt;Long&gt; &#123; private static final int THRESHOLD = 10000; private long start; private long end; public CountTask(long start , long end)&#123; this.start = start; this.end = end; &#125; public Long compute()&#123; long sum = 0; boolean canCompute = (end-start)&lt;THRESHOLD; if(canCompute)&#123; for(long i=start;i&lt;=end;i++)&#123; sum+=i; &#125; &#125;else &#123; //分成100个任务 long step = (start+end)/100; ArrayList&lt;CountTask&gt; subTasks = new ArrayList&lt;&gt;(); long pos = start; for(int i=0;i&lt;100;i++)&#123; long lastOne = pos + step; if(lastOne&gt;end) lastOne=end; CountTask subTask = new CountTask(pos,lastOne); pos+=step+1; subTasks.add(subTask); subTask.fork(); &#125; for(CountTask t : subTasks)&#123; sum+=t.join(); &#125; &#125; return sum; &#125; public static void main(String[] args)&#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); CountTask task = new CountTask(0,200000L); ForkJoinTask&lt;Long&gt; result = forkJoinPool.submit(task); try&#123; long res = result.get(); System.out.println(&quot;sum=&quot; +res); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125;catch (ExecutionException e)&#123; e.printStackTrace(); &#125; &#125;&#125; ThreadPoolExecutor类主要构造方法为 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Creates a new &#123;@code ThreadPoolExecutor&#125; with the given initial * parameters. * * @param corePoolSize the number of threads to keep in the pool, even * if they are idle, unless &#123;@code allowCoreThreadTimeOut&#125; is set * @param maximumPoolSize the maximum number of threads to allow in the * pool * @param keepAliveTime when the number of threads is greater than * the core, this is the maximum time that excess idle threads * will wait for new tasks before terminating. * @param unit the time unit for the &#123;@code keepAliveTime&#125; argument * @param workQueue the queue to use for holding tasks before they are * executed. This queue will hold only the &#123;@code Runnable&#125; * tasks submitted by the &#123;@code execute&#125; method. * @param threadFactory the factory to use when the executor * creates a new thread * @param handler the handler to use when execution is blocked * because the thread bounds and queue capacities are reached * @throws IllegalArgumentException if one of the following holds:&lt;br&gt; * &#123;@code corePoolSize &lt; 0&#125;&lt;br&gt; * &#123;@code keepAliveTime &lt; 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt;= 0&#125;&lt;br&gt; * &#123;@code maximumPoolSize &lt; corePoolSize&#125; * @throws NullPointerException if &#123;@code workQueue&#125; * or &#123;@code threadFactory&#125; or &#123;@code handler&#125; is null */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 参数workQueue指被提交但未执行的任务队列，是一个BlockingQueue接口的对象，仅用于存放Runnable对象。根据队列功能分类，可以使用的BlockingQueue有： 直接提交的队列：SynchronousQueue，是一个特殊的BlockingQueue。没有容量，每一个插入都要等待一个相应的删除操作，反之，每一个删除操作都要等待对应的插入操作。如果使用SynchronousQueue，提交的任务不会被真实的保存，而总是将新任务提交给线程执行，如果没有空闲的线程，则尝试创建新的线程，如果线程数量已经达到最大值则执行拒绝策略 有界的任务队列：ArrayBlockingQueue，当使用有界的任务队列时，若有新的任务需要执行，如何线程池的实际线程小于corePoolSize，则会优先创建新的线程，若大于corePoolSize，则会将新任务加入等待队列。若等待队列已满，无法加入，则在总线程数不大于maximumPoolSize的前提下，创建新的线程执行任务，若大于maximumPoolSize则执行拒绝策略 无界的任务队列：LinkedBlockingQueue，与有界队列相比，除非系统资源耗尽，否则无界的任务队列不存在任务入队失败的情况 优先任务队列：PriorityBlockingQueue， 可以根据任务自身的优先级顺序先后执行，在确保系统性能的同时，也能够很好的质量保证 拒绝策略ThreadPoolExecutor的最后一个参数指定了拒绝策略，也就是当任务数量超过系统实际承载能力时，需要使用拒绝策略，JDK内置了四种拒绝策略 AbortPolicy策略：该策略会直接抛出异常，阻止系统正常工作 CallerRunsPolicy策略：只要线程池未关闭，该策略直接在调用者线程中,运行当前被丢弃的任务， DiscardOledestPolicy策略：该策略将丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务 DiscardPolicy策略：该策略默默地丢弃无法处理的任务，不予任何处理。 锁优化减少锁持有时间，只在必要时进行同步，这样就能明显减少线程持有锁的时间，提高系统的吞吐量 减少锁粒度，就是缩小锁定对象的范围，从而减少锁冲突的可能性，进而提高系统的并发能力 读写分离锁来代替独占锁 锁分离，例如在LinkedBlockingQueue实现中，take和put函数分别实现了从队列中取得数据和往队列中增加数据功能，分别作用于队列的前端和尾端，所以可以通过takeLock和putLock两把锁 锁粗化，虚拟机在遇到一连串连续地对同一锁进行请求和释放的操作时，便会把所有的锁操作整合成对锁的一次请求，从而减少对锁的请求同步次数，这个操作叫做锁粗化 JDK内部”锁“优化策略锁偏向:如果一个线程获得了锁，那么锁就进入偏向模式，当这个线程再次请求锁时，无须再做任何同步操作 轻量级锁：只是简单地将对象头部作为指针，指向持有锁的线程堆栈的内部，来判断一个线程是否持有对象锁。如果线程获得轻量级锁成功，则可以顺利进入临界区。如果轻量级锁加锁失败，则表示其他线程抢先争夺到了锁，那么当前线程的锁请求就会膨胀为重量级锁 自旋锁：锁的等待者会原地忙等，不停的询问，直到获得锁。采用让当前线程不停地的在循环体内执行实现，当循环的条件被其他线程改变时才能进入临界区。 锁消除：Java虚拟机在JIT编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁 ThreadLocal123456789101112131415161718192021/** * Returns the value in the current thread&apos;s copy of this * thread-local variable. If the variable has no value for the * current thread, it is first initialized to the value returned * by an invocation of the &#123;@link #initialValue&#125; method. * * @return the current thread&apos;s value of this thread-local */ public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; 1234567891011121314151617/** * Sets the current thread&apos;s copy of this thread-local variable * to the specified value. Most subclasses will have no need to * override this method, relying solely on the &#123;@link #initialValue&#125; * method to set the values of thread-locals. * * @param value the value to be stored in the current thread&apos;s copy of * this thread-local. */ public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); &#125; 12345678910111213141516/** * Removes the current thread&apos;s value for this thread-local * variable. If this thread-local variable is subsequently * &#123;@linkplain #get read&#125; by the current thread, its value will be * reinitialized by invoking its &#123;@link #initialValue&#125; method, * unless its value is &#123;@linkplain #set set&#125; by the current thread * in the interim. This may result in multiple invocations of the * &#123;@code initialValue&#125; method in the current thread. * * @since 1.5 */ public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this); &#125; AQS（AbstractQueuedSynchronizer）AQS（AbstractQueuedSynchronizer），抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock/Semaphore/CountDownLatch…。 AQS有以下几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 上面是AQS定义的资源独占方式，其实还有资源共享方式，采用以下两种方法： tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 CAS（Compare and swap） CAS（Compare and swap）比较和替换是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量的值。 现在CPU内部已经执行原子的CAS操作，Java5+中内置的CAS特性可以让你利用底层的你的程序所运行机器的CPU的CAS特性，这会使代码运行更快。 Java5以来，你可以使用java.util.concurrent.atomic包中的一些原子类来使用CPU中的这些功能 上面是一个使用AtomicBoolean类实现lock()方法的例子。 locked变量不再是boolean类型而是AtomicBoolean。这个类中有一个compareAndSet()方法，它使用一个期望值和AtomicBoolean实例的值比较，若两者相等，则使用一个新值替换原来的值。在这个例子中，它比较locked的值和false，如果locked的值为false，则把修改为true。 即compareAndSet()返回true，如果值被替换了，返回false。 CAS用于同步（乐观锁的机制就是CAS） 通常将 CAS 用于同步的方式是从地址 V 读取值 A，执行多步计算来获得新 值 B，然后使用 CAS 将 V 的值从 A 改为 B。如果 V 处的值尚未同时更改，则 CAS 操作成功。 类似于 CAS 的指令允许算法执行读-修改-写操作，而无需害怕其他线程同时 修改变量，因为如果其他线程修改变量，那么 CAS 会检测它（并失败），算法 可以对该操作重新计算 CAS存在的问题：有三个，ABA问题，循环时间长开销大和只能保证一个共享变量的原子操作。ABA问题： 因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。 从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 循环时间长开销大： 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 只能保证一个共享变量的原子操作： 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性。 这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作 死锁分析死锁就是两个或者多个线程，相互占用对方需要的资源，而都不进行释放，导致彼此之间相互等待对方释放资源，产生了无限制的等待现象 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class DeadLockDemo extends Thread &#123; protected Object tool; static Object obj1 = new Object(); static Object obj2 = new Object(); public DeadLockDemo(Object obj)&#123; this.tool=obj; if(tool==obj1)&#123; this.setName(&quot;哲学家A&quot;); &#125; if(tool==obj2)&#123; this.setName(&quot;哲学家B&quot;); &#125; &#125; @Override public void run()&#123; if(tool==obj1)&#123; synchronized (obj1)&#123; try &#123; Thread.sleep(500); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; synchronized (obj2)&#123; System.out.println(&quot;A eat&quot;); &#125; &#125; &#125; if(tool==obj2)&#123; synchronized (obj2)&#123; try&#123; Thread.sleep(500); &#125; catch (Exception e)&#123; e.printStackTrace(); &#125; synchronized (obj1)&#123; System.out.println(&quot;B eat&quot;); &#125; &#125; &#125; &#125; public static void main(String[] args)&#123; DeadLockDemo A = new DeadLockDemo(obj1); DeadLockDemo B = new DeadLockDemo(obj2); A.start(); B.start(); &#125;&#125; 产生死锁的四个必要条件： 互斥条件：一个资源每次只能被一个进程使用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系 如何避免死锁？ 从死锁的四个必要条件来看，破坏其中的任意一个条件就可以避免死锁。但互斥条件是由资源本身决定的，不剥夺条件一般无法破坏，要实现的话得自己写更多的逻辑。 避免无限期的等待：用Lock.tryLock(),wait/notify等方法写出请求一定时间后，放弃已经拥有的锁的程序。 注意锁的顺序：以固定的顺序获取锁，可以避免死锁。 开放调用：即只对有请求的进行封锁。你应当只想你要运行的资源获取封锁，比如在上述程序中我在封锁的完全的对象资源。但是如果我们只对它所属领域中的一个感兴趣，那我们应当封锁住那个特殊的领域而并非完全的对象。 最后，如果能避免使用多个锁，甚至写出无锁的线程安全程序是再好不过了 BlockingQueue解决生产者消费者问题12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ProduceAndConsumerDemo &#123; public static void main(String[] argd)&#123; final BlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;&gt;(10); Produce produce = new Produce(blockingQueue); Consume consume = new Consume(blockingQueue); produce.start(); consume.start(); &#125; static class Consume extends Thread&#123; private final BlockingQueue&lt;Integer&gt; blockingQueue; Consume(BlockingQueue&lt;Integer&gt; blockingQueue)&#123; this.blockingQueue=blockingQueue; &#125; @Override public void run() &#123; while (true)&#123; try &#123; Integer take = blockingQueue.take(); System.out.println(&quot;consume:&quot; + take); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125; static class Produce extends Thread&#123; private final BlockingQueue&lt;Integer&gt; blockingQueue; Produce(BlockingQueue&lt;Integer&gt; blockingQueue)&#123; this.blockingQueue=blockingQueue; &#125; @Override public void run() &#123; while (true)&#123; try &#123; int i = new Random().nextInt(100); blockingQueue.add(i); System.out.println(&quot;produce:&quot;+ i); Thread.sleep(1000); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 使用wait和notify实现生产者和消费者123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class ProduceAndConsumerDemo2 &#123; public static void main(String[] args)&#123; Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); int maxSize = 5; Produce produce = new Produce(queue,maxSize); Consume consume = new Consume(queue,maxSize); produce.start(); consume.start(); &#125; static class Produce extends Thread&#123; private Queue&lt;Integer&gt; queue; private int maxSize; Produce(Queue&lt;Integer&gt; queue , int maxSize)&#123; this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run()&#123; while (true)&#123; synchronized (queue)&#123; while (queue.size()==maxSize)&#123; try &#123; System.out.println(&quot;full&quot;); queue.wait(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; int i = new Random().nextInt(100); System.out.println(&quot;produce:&quot;+ i); queue.add(i); queue.notifyAll(); &#125; &#125; &#125; &#125; static class Consume extends Thread&#123; private Queue&lt;Integer&gt; queue; private int maxSize; Consume(Queue&lt;Integer&gt; queue , int maxSize)&#123; this.queue = queue; this.maxSize = maxSize; &#125; @Override public void run()&#123; while (true)&#123; synchronized (queue)&#123; while (queue.isEmpty())&#123; try &#123; System.out.println(&quot;empty&quot;); queue.wait(); &#125;catch (InterruptedException e)&#123; e.printStackTrace(); &#125; &#125; int i = queue.poll(); System.out.println(&quot;consume:&quot;+ i); queue.notifyAll(); &#125; &#125; &#125; &#125;&#125; 参考资料《Java高并发编程详解》 《实战Java高并发程序设计》 《Java多线程编程核心技术》 https://github.com/ZXZxin/ZXBlog/tree/master/%E5%B9%B6%E5%8F%91/%E5%A4%9A%E7%BA%BF%E7%A8%8B https://blog.csdn.net/ll666634/article/details/78615505 https://blog.csdn.net/cmyperson/article/details/79610870","tags":[{"name":"Java","slug":"Java","permalink":"http://www.ylovex.cn/tags/Java/"}]},{"title":"Redis设计与实现笔记七","date":"2019-07-13T03:37:37.000Z","path":"2019/07/13/Redis设计与实现笔记七/","text":"对象Redis构建了一个对象系统，包含字符串、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象 Redis可以在执行命令前，根据对象的类型判断一个对象是否可以执行给定的命令。可以针对不同的使用场景，为对象设置多种不同的数据结构实现，从而优化对象在不同场景下的使用效率。 Redis对象系统实现基于引用计数技术的内存回收机制，还可以通过引用计数技术实现了对象共享机制，通过让多个数据库键共享同一个对象来节约内存 Redis对象带有访问时间记录信息，该信息可以用于计算数据库键的空转时长，在服务器启用了maxmemory功能情况下，空转时长较长的那些键可能会优先被服务器删除 对象的类型与编码Redis使用对象来表示数据库中的键和值，新创建一个键值对的时候，会创建两个对象，一个用于键一个用于值。 每个对象都由一个redisObject结构表示， 12345678910111213141516171819202122232425/* The actual Redis Object *//* * Redis 对象 */#define REDIS_LRU_BITS 24#define REDIS_LRU_CLOCK_MAX ((1&lt;&lt;REDIS_LRU_BITS)-1) /* Max value of obj-&gt;lru */#define REDIS_LRU_CLOCK_RESOLUTION 1000 /* LRU clock resolution in ms */typedef struct redisObject &#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 对象最后一次被访问的时间 unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */ // 引用计数 int refcount; // 指向实际值的指针 void *ptr;&#125; robj; type属性记录了对象的类型，键总是一个字符串对象；值可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象，当对一个数据库键执行TYPE命令时候，返回的是值对象类型 对象的ptr指针指向对象的底层实现数据结构，而这个数据结构又对象的enconding属性决定 enconding属性记录了对象所使用的编码： 每种类型对象都至少使用了两种不同的编码： 根据不同的使用场景为一个对象设置不同的编码，从而优化对象在某一场景下的效率 字符串对象字符串对象编码可以是int、raw、embstr 如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保持在字符串对象结构的ptr属性里面（将void*转换为long），并将字符串对象编码设置为int 如果字符串对象保存的是一个字符串值，并且这个字符串值的长度大于32字节，那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值，并将对象的编码设置为raw 如果保存的字符串长度小于等于32字节。用embstr编码保存，专门用于保存短字符串，这种编码和raw编码一样，都使用redisObject结构和sdshdr结构来表示字符串对象，但是raw编码会调用两次内存分配函数分别创建redisObject结构和sdshdr结构，而embstr编码则通过调用一次内存分配函数分配一块连续空间，空间中依次包含redisObject和sdshdr两个结构 可以用long double类型表示的浮点数在Redis中也是作为字符串值保存 int编码的字符串对象和embstr编码的字符串对象在条件满足的情况下，会被转换为raw编码 列表对象编码可以是ziplist或者linkedlist 编码转换：当列表对象同时满足以下两个条件，使用ziplist编码 保存的所有字符串元素的长度都小于64字节 列表对象保存的元素数量小于512个 可以在配置文件中list-max-ziplist-value和list-max-ziplist-entries配置 哈希对象编码可以是ziplist或者hashtable ziplist编码的哈希对象使用压缩列表作为底层实现，每当有新的键值对要加入到哈希对象时候，程序会将保存了键的压缩列表节点推入到压缩列表表尾，然后将保存了值的压缩列表节点推入到压缩列表表尾，因此： 保存了同一个键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后 先添加到哈希对象中的键值对会被放在压缩列表的表头方向，后来添加的放在表尾方向 hashtable编码的哈希对象使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值对保存 编码转换，当哈希对象同时满足： 保存的所以键值对的键和值的字符串长度都小于64字节 保存的键值对数量小于512个 使用ziplist编码，否则编码转化为hashtable 集合对象编码可以是intset或者hashtable hashtablw编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，每个字符串对象包含了一个集合元素，而字典的值则全部被设置为NULL 编码转换，当满足： 集合对象保存的所有元素都是整数值 保存元素数量不超过512 使用intset编码，否则使用hashtable 有序集合对象编码可以是ziplist或者skiplist ziplist编码的压缩列表对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，而第二个元素保存元素的分值，压缩列表内的集合元素按分值从小到大进行排序，分值较小的元素被放置在靠近表头的方向，而分值较大的元素则被放置在靠近表尾方法 skiplist编码的有序集合对象使用zset结构作为底层实现，一个zset结构同时包含一个字典和一个跳跃表，zset结构中的zsl跳跃表按分值从小到大保存了所有集合元素，通过跳跃表可以进行范围型操作比如ZRANK、ZRANGE等，dict字典为有序集合创建了一个从成员到分值的映射，可以用O（1）查找给定成员的分值 类型检查与命名多态命令可以分为两种类型，一种命令可以对任何类型的键执行，比如DEL、EXPIRE、RENAME、TYPE、OBJECT等 另一种只能对特定类型的键执行，比如SET只能对字符串键执行，HSET只能对哈希键执行 类型检查的实现为了确保只有指定类型的键可以执行某些特定的命令，在执行一个类型特定的命令之前，Redis会先检查输入键的类型是否正确，然后再决定是否执行给定的命令 多态命令实现根据值对象的编码方式，选择正确的命令实现代码执行命令 内存回收跟踪对象的引用计数信息，在适当的时候自动释放对象并进行内存回收 对象共享 Redis会在初始化服务器时，创建一万个字符串对象，这些对象包含了从0到9999的所以整数值，当服务器需要用到值为0到999的字符串对象时，服务器就会使用这些共享对象，而不是新创建对象 Redis只对包含整数值的字符串对象进行共享 对象的空转时长redisObject结构包含的lru属性，记录了对象最后一次被命令程序访问的时间","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"Redis设计与实现笔记六","date":"2019-07-10T03:37:28.000Z","path":"2019/07/10/Redis设计与实现笔记六/","text":"压缩列表压缩列表是列表键和哈希键的底层实现之一。 使用压缩列表作为列表键底层实现：列表键只包含少量列表项，并且每个列表项要么是小整数值要么是长度比较短的字符串 使用压缩列表作为哈希键底层实现：哈希键只包含少量键值对，并且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串 压缩列表构成ziplist是Redis为了节约内存而开发的，各部分如下 节点构成1234567891011121314151617181920212223* 保存 ziplist 节点信息的结构 */typedef struct zlentry &#123; // prevrawlen ：前置节点的长度 // prevrawlensize ：编码 prevrawlen 所需的字节大小 unsigned int prevrawlensize, prevrawlen; // len ：当前节点值的长度 // lensize ：编码 len 所需的字节大小 unsigned int lensize, len; // 当前节点 header 的大小 // 等于 prevrawlensize + lensize unsigned int headersize; // 当前节点值所使用的编码类型 unsigned char encoding; // 指向当前节点的指针 unsigned char *p;&#125; zlentry; 每个压缩列表节点可以保存一个字节数组或者一个整数值， 添加新节点或者删除节点，可能会引发连锁更新操作，导致需要对压缩列表执行N次空间重分配操作，最坏复杂度O（N^2）。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"jvm虚拟机执行子系统","date":"2019-07-09T12:26:37.000Z","path":"2019/07/09/jvm虚拟机执行子系统/","text":"虚拟机执行子系统类文件结构任何一个Class文件都对应着唯一一个类或者接口的定义信息，但反过来说，类或接口并不一定都得定义在文件里（譬如类或者接口也可以通过类加载器直接生成）。 Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地 排列在Class文件之中，中间没有添加任何分隔符，这使得整个Class文件中存储的内容几乎 全部是程序运行的必要数据，没有空隙存在。当遇到需要占用8位字节以上空间的数据项时，则会按照高位在前的方式分割成若干个8位字节进行存储。 Class文件格式采用一种类似于C语言结构体的伪结构来存 储数据，这种伪结构中只有两种数据类型：无符号数和表： 无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个 字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8 编码构成字符串值。 表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表都习惯性以“_info”结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表。 Class类文件结构详解： 魔数：每个Class文件的头4个字节称为魔数，唯一的作用是确定这个文件是否为一个能被虚拟机接受的Class文件。值为：0xCAFEBABE。 版本号：紧接着魔数的4个字节存储的是Class文件的版本号，第5和第6个字节是次版本号，第7和第8个字节是主版本号。java版本号从45开始。 常量池：紧接着版本号之后的是常量池入口，常量池可以理解为Class文件之中的资源仓库，常量池入口需要放置一项u2类型的数据，代表常量池容量计数器，该容量计数从1开始而不是0；常量池主要存在两大类常量：字面量和符号引用，字面量比较接近于java语言层面的常量概念，如文本字符串、声明为final的常量值等。符号引用则属于编译原理方面的概念，包含：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。 访问标志：常量池结束后，紧接着的两个字符代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口、是否定义为public类型、是否定义为abstract类型、如果是类的话，是否被声明为final等 类索引、父类索引、接口索引：类索引和父类索引都是一个u2类型的数据，而接口索引集合是一组u2类型的数据集合 字符表集合：用于描述接口或者类中声明的变量，字段包括类级变量以及实例级变量，但不包括在方法内部声明的局部变量。 方法表集合：结构如同字段表一样，依次包括了访问标志、名称索引、描述符索引、属性表集合几项 属性表集合：常用属性如下 Code属性；使用位置：方法表；含义：Java代码编译成的字节码指令 ConstantValue属性；字段表；final关键字定义的常量值 Deprecated属性；类、方法表、字段表；被声明为deprecated的方法和字段 Exceptions属性、方法表、方法抛出的异常 EnclosingMethod属性、方法表、仅当一个类为局部类或者匿名类时才能拥有这个属性，这个属性用于标识这个类所在的外围方法 虚拟机类加载机制虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是JVM的类加载机制。 类加载的时机类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载 （Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化 （Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个 部分统称为连接（Linking） 其中，加载、验证、准备、初始化和卸载这5个阶段是确认的， 解析阶段不一定：在某些情况在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定） 虚拟机严格规定了有且只有5种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化， 则需要先触发其初始化 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化 当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个 类），虚拟机会先初始化这个主类 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄 所对应的类没有进行过初始化，则需要先触发其初始化。 对于这5种会触发类进行初始化的场景，虚拟机规范中使用了一个很强烈的限定语：“有 且只有”，这5种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都 不会触发初始化，称为被动引用： 对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化 通过数组定义来引用类，不会触发此类的初始化 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 接口也用初始化过程，当一个类在初始化时，要求其父类全部都已经初始 化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使 用到父接口的时候（如引用接口中定义的常量）才会初始化。 类加载过程加载 通过一个类的全限定名来获取定义此类的二进制字节流。JVM把这个阶段的动作放在了虚拟机外部的“类加载器”中实现。未指明从哪里获取，因此有各种花样，比如从JAR包、WAR包，或者网络，或者运行时计算生成比如动态代理、由其他文件生成、从数据库读取等等。 将这个字节流所代表的的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。即对象类型数据（非对象实例数据）存在方法区。 验证验证的目的是确保Class文件的字节流中包含的信号符合当前虚拟机的要求，不会危害虚拟机自身的安全。 分为四个阶段： 文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理 元数据验证：是对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求 字节码验证：主要是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的 符号引用验证：发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在连接的第三阶段–解析阶段中发生。符号引用验证可以看做是对类自身以外的信息进行匹配性校验。 对于虚拟机的类加载机制来说，验证阶段是一个非常重要的、但不是一定必要（因为对 程序运行期没有影响）的阶段。如果所运行的全部代码（包括自己编写的及第三方包中的代 码）都已经被反复使用和验证过，那么在实施阶段就可以考虑使用-Xverify：none参数来关 闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。 这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值。 比如public static int value=123：在准备阶段过后value=0，只有在初始化阶段后，value才等于123； 但是如何类字段的字段属性表中存在ConstantValue属性，那么在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，比如 public static final int value=123，编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123. 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。 直接引用（Direct References）：直接引用可以是直接指向目标的指针、相对偏移量或是 一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引 用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在 虚拟机规范之中并未规定解析阶段发生的具体时间，只要求了在执行anewarray、 checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invokespecial、 invokestatic、invokevirtual、ldc、ldc_w、multianewarray、new、putfield和putstatic这16个用于 操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析 对同一个符号引用进行多次解析请求是很常见的事情，除invokedynamic指令以外，虚拟 机实现可以对第一次解析的结果进行缓存（在运行时常量池中记录直接引用，并把常量标识 为已解析状态）从而避免解析动作重复进行。 对于invokedynamic指令，上面规则则不成立。当碰到某个前面已经由invokedynamic指令 触发过解析的符号引用时，并不意味着这个解析结果对于其他invokedynamic指令也同样生 效。因为invokedynamic指令的目的本来就是用于动态语言支持（目前仅使用Java语言不会生 成这条字节码指令），它所对应的引用称为“动态调用点限定符”（Dynamic Call Site Specifier），这里“动态”的含义就是必须等到程序实际运行到这条指令的时候，解析动作才能进行。相对的，其余可触发解析的指令都是“静态”的，可以在刚刚完成加载阶段，还没有 开始执行代码时就进行解析。 解析动作主要针对类或者接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行 初始化是类加载过程的最后一步，类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制，到了初始化阶段，才开始真正执行类中定义的Java程序代码。 在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通 过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始 化阶段是执行类构造器＜clinit＞（）方法的过程。 类加载器虚拟机把类加载阶段中的通过一个类的全限定名来获取定义此类的二进制字节流这个动作放在了虚拟机外部的“类加载器”中实现。 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性 比较两个类是否“相等”，只有在这个两个类是由同一个类加载器加载的前提下才有意义。 双亲委派模型绝大部分Java程序都会使用到3种系统提供的类加载器： 启动类加载器：这个类将器负责将存放在＜ JAVA_HOME＞\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机 识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载） 类库加载到虚拟机内存中 扩展类加载器：它负责加载＜JAVA_HOME＞\\lib\\ext目录中的，或者被java.ext.dirs系 统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器：它负责加载用户类路径（ClassPath）上所指定的类 库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一 般情况下这个就是程序中默认的类加载器。 上图就是类加载器的双亲委派模型，双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当 有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系 来实现，而是都使用组合（Composition）关系来复用父加载器的代码 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 12345678910111213141516171819202122protected synchronized Class＜?＞loadClass（String name,boolean resolve）throws ClassNotFoundException &#123; //首先，检查请求的类是否已经被加载过了 Class c=findLoadedClass（name）； if（c==null）&#123; try&#123; if（parent！=null）&#123; c=parent.loadClass（name,false）；&#125;else&#123;c=findBootstrapClassOrNull（name）；&#125; &#125;catch（ClassNotFoundException e）&#123; //如果父类加载器抛出ClassNotFoundException //说明父类加载器无法完成加载请求&#125; if（c==null）&#123; //在父类加载器无法加载的时候 //再调用本身的findClass方法来进行类加载c=findClass（name）；&#125; &#125; if（resolve）&#123; resolveClass（c）； &#125; return c；&#125; 好处：Java类随着它的类加载器一起具备了一种带有优先级的层次关系。 为什么需要双亲委派模型： 例如类java.lang.Object，它存在在rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的Bootstrap ClassLoader进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有双亲委派模型而是由各个类加载器自行加载的话，如果用户编写了一个java.lang.Object的同名类并放在ClassPath中，那系统中将会出现多个不同的Object类，程序将混乱。 如果不采用双亲委派模型，那么由各个类加载器自己去加载的话，那么系统中会存在多种不同的Object类。 虚拟机字节码执行引擎执行引擎是Java虚拟机最核心的组成部分之一。 运行时栈帧结构栈帧（Stack Frame）是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区中的虚拟机栈（Virtual Machine Stack）的栈元素。 栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息。每一个方法从调用开始至执行完成的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程。 每一个栈帧都包括了局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。在编译程序代码的时候，栈帧中需要多大的局部变量表，多深的操作数栈都已经完全确定了，并且写入到方法表的Code属性之中，因此一个栈帧需要分配多少内存，不会受 到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。 一个线程中的方法调用链可能会很长，很多方法都同时处于执行状态。对于执行引擎来 说，在活动线程中，只有位于栈顶的栈帧才是有效的，称为当前栈帧（Current Stack Frame），与这个栈帧相关联的方法称为当前方法（Current Method）。执行引擎运行的所有 字节码指令都只针对当前栈帧进行操作。 局部变量表是一组变量值存储空间，用于存放方法参数和方法 内部定义的局部变量。在Java程序编译为Class文件时，就在方法的Code属性的max_locals数 据项中确定了该方法所需要分配的局部变量表的最大容量 以变量槽（Slot）为最小单位，到每个Slot都应该能存放一 个boolean、byte、char、short、int、float、reference或returnAddress类型的数据。 操作数栈也常称为操作栈，它是一个后入先出（Last In First Out,LIFO）栈。同局部变量表一样，操作数栈的最大深度也在编译的时候写入到Code属性的 max_stacks数据项中。操作数栈的每一个元素可以是任意的Java数据类型，包括long和 double。32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。在方法执行的任 何时候，操作数栈的深度都不会超过在max_stacks数据项中设定的最大值 动态连接每个栈帧都包含一个指向运行时常量池[1]中该栈帧所属方法的引用，持有这个引用是为 了支持方法调用过程中的动态连接（Dynamic Linking）。Class 文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符 号引用作为参数。这些符号引用一部分会在类加载阶段或者第一次使用的时候就转化为直接引用，这种转化称为静态解析。另外一部分将在每一次运行期间转化为直接引用，这部分称为动态连接 方法返回地址当一个方法开始执行后，只有两种方法可以退出： 执行引擎遇到任意一个方法返回的字节码指令 遇到异常，并且该异常没有在方法体内得到处理 方法调用方法调用阶段唯一的任务就是确认被调用方法的版本（即调用哪一个方法），一切方法调用在Class文件里面存储的都只是符号引用，而不是方法在实践运行时内存布局中的入口地址。 解析所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载的解析阶段会将其中一部分符号引用转化为直接引用 这类解析成立前提：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期不可变。 符合“编译期可知，运行期不可变”：主要包括静态方法和私有方法。 Java虚拟机里面提供了5条方法调用字节指令： invokestatic：调用静态方法 invokespecial：调用实例构造器方法，私有方法和父类方法 invokevirtual;调用所有的虚方法 invokeinterface:调用接口方法，会在运行时再确认一个实现此接口的对象 invokedynamic:先在运行时动态解析出调用点限定符所引用的方法，然后再执行该方 法，在此之前的4条调用指令，分派逻辑是固化在Java虚拟机内部的，而invokedynamic指令 的分派逻辑是由用户所设定的引导方法决定 只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段中确定唯一的 调用版本，符合这个条件的有静态方法、私有方法、实例构造器、父类方法4类，它们在类 加载的时候就会把符号引用解析为该方法的直接引用。这些方法可以称为非虚方法，与之相 反，其他方法称为虚方法（除去final方法） 分派静态分派：所有依赖静态类型来定位方法执行版本的分派动作称为静态分派。典型应用是方法重载。 动态分派：在运行期根据实际类型确定方法执行的颁布的分派过程，重要体现是方法重写 Java代码编译过程 代码编译是由Javac编译器来完成，流程如上图所示。Javac的任务就是将Java源代码编译成Java字节码，也就是JVM能够识别的二进制代码，从表面看是将.java文件转化为.class文件。而实际上是将Java源代码转化成一连串二进制数字，这些二进制数字是有格式的，只有JVM能够真确的识别他们到底代表什么意思。 具体流程： 词法分析：读取源代码，一个字节一个字节的读进来，找出这些词法中我们定义的语言关键词如：if、else、while等，识别哪些if是合法的哪些是不合法的。这个步骤就是词法分析过程 语法分析：就是对词法分析中得到的token流进行语法分析，这一步就是检查这些关键词组合在一起是不是符合Java语言规范。如if的后面是不是紧跟着一个布尔型判断表达式。 语义分析：语法分析完成之后也就不存在语法问题了，语义分析的主要工作就是把一些难懂的，复杂的语法转化成更简单的语法。比如将foreach转化为for循环。 字节码生成：将会根据经过注释的抽象语法树生成字节码，也就是将一个数据结构转化为另外一个数据结构，结果就是生成符合java虚拟机规范的字节码。","tags":[{"name":"java","slug":"java","permalink":"http://www.ylovex.cn/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://www.ylovex.cn/tags/jvm/"}]},{"title":"Redis设计与实现笔记五","date":"2019-07-08T03:37:21.000Z","path":"2019/07/08/Redis设计与实现笔记五/","text":"整数集合整数集合是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis就会使用整数集合作为集合键的底层实现 整数集合实现用于保存整数值的集合抽象数据结构，可以保存类型为int16_t、int32_t、int64_t的整数值，并且保证不会出现重复元素 123456789101112typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset; contents数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项，各个项在数组中按值的大小从小到大有序排列，并且数组不包含任何重复项 升级当新元素类型比整数集合现有所有元素的类型都要长时候，整数集合需要先升级再把新元素添加 分为三步： 根据新元素，扩展整数集合底层数组的空间大小，并为新元素分配空间 将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素放在正确位上，维持有序性质不变 将新元素添加到底层数组里面 升级的好处 提升灵活性 节约内存 降级整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态 整数集合API","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"nowcoder-病毒传播","date":"2019-07-06T23:37:20.000Z","path":"2019/07/07/nowcoder-病毒传播/","text":"题目来源：https://www.nowcoder.com/practice/3b6060942397444cb0fe5846e230f6d9?tpId=90&amp;tqId=30850&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：给出一个图G(V,E)，图上有n个点，m条边，所有的边都是无向边。 最开始，也就是第0天的时候，这n个点中有一个点v感染了病毒，之后的每一天，凡是感染病毒的点都会向它的邻居点传播病毒。经过了t天之后，得到了感染病毒的点集S。要求找出第0天感染病毒的点v。如果v有很多不同的答案，把它们都找出来。 思路：bfs算法，显然感染源一定是感染的点，先用ArrayLIst生成图，以每个感染的点为起点在t时间内进行广度遍历，将结果与给定的感染集合进行比较，如果一样则该点可以是感染源。 参考代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class Now_74 &#123; static boolean[] infected; static ArrayList&lt;Integer&gt;[] graph; static int n, m, k, t; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); infected = new boolean[n+1]; graph = new ArrayList[n+1]; for(int i=1;i&lt;=n;i++)&#123; graph[i]=new ArrayList&lt;&gt;(); &#125; for(int i=0 ; i&lt;m;i++)&#123; int u = sc.nextInt(); int v = sc.nextInt(); graph[u].add(v); graph[v].add(u); &#125; k = sc.nextInt(); t = sc.nextInt(); for(int i = 0;i&lt;k;i++)&#123; infected[sc.nextInt()]=true; &#125; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for(int i=1;i&lt;=n;i++)&#123; if(infected[i] &amp;&amp; bfs(i))&#123; res.add(i); &#125; &#125; if(res.size()==0)&#123; System.out.println(-1); &#125; else &#123; for(int i=0;i&lt;res.size();i++)&#123; if(i==res.size()-1)&#123; System.out.print(res.get(i)); &#125; else &#123; System.out.print(res.get(i)+\" \"); &#125; &#125; &#125; &#125; //以x为起点传播t天的结果和实际结果比较是否相同 private static boolean bfs(int x) &#123; //每个点被传染需要的时间, 为0表明没有被传染 int[] temp = new int[n+1]; LinkedList&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); temp[x]=1; queue.offer(x); while (! queue.isEmpty())&#123; int cur = queue.poll(); if(temp[cur]&gt;t) break; for(Integer e : graph[cur])&#123; if(temp[e]==0)&#123; temp[e]=temp[cur]+1; queue.offer(e); &#125; &#125; &#125; for(int i=1;i&lt;=n;i++)&#123; if(!infected[i] &amp;&amp; temp[i]!=0) return false; if(infected[i] &amp;&amp; temp[i]==0) return false; &#125; return true; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"},{"name":"bfs","slug":"bfs","permalink":"http://www.ylovex.cn/tags/bfs/"}]},{"title":"Redis设计与实现笔记四","date":"2019-07-06T03:37:07.000Z","path":"2019/07/06/Redis设计与实现笔记四/","text":"跳跃表跳跃表是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳跃表支持平均O（logN），最坏O（N）复杂度的节点查找，还可以通过顺序性操作来批量处理节点 Redis使用跳跃表作为有序集合键的底层实现之一，如果一个有序集合包含的元素数量比较多，或者有序集合中的元素的成员是比较长的字符串时候，Redis就会使用跳跃表来作为有序集合键的底层实现 Redis只在两个地方用到了跳跃表，一个是实现有序集合键，另一个是在集群节点中用作内部数据结构 跳跃表的实现跳跃表由redis.h/zskiplistNode和redis.h/zskiplist两个结构定义，其中zskiplistNode结构用于表示跳跃表节点，zskiplist结构则用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针等。 header：指向跳跃表的表头节点 tail：指向跳跃表的表尾节点 level：记录目前跳跃表内，层数最大的那个节点层数（表头节点除外） length：记录跳跃表长度（表头节点不计算在内） 跳跃表节点12345678910111213141516171819202122232425* 跳跃表节点 */typedef struct zskiplistNode &#123; // 成员对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel &#123; // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; &#125; level[];&#125; zskiplistNode; 层：level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针，一般层数越多访问其他节点的速度就越快。每次创建一个新跳跃表节点的时候，程序都根据幂次定律（越大的数出现的概率越小）随机生成一个介于1和32之间的值作为level数组的大小。 前进指针：每个层都有一个指向表尾方向的前进指针，用于从表头向表尾方向访问节点 跨度：用于记录两个节点之间的距离 后退指针：用于从表尾向表头方向访问节点，因为每个节点只有一个后退指针，所以每次只能后退至前一个节点。 分值和成员：分值是一个double类型的浮点数，跳跃表中的所有节点都按分值从小到大来排序；成员对象是一个指针，它指向一个字符串对象，而字符串对象保存一个SDS值 在同一个跳跃表中，各个节点保存的成员对象必须是唯一的，但是多个节点保存的分值却可以是相同的：分值相同的节点将按照成员对象的字典序中的大小来进行排序，成员对象较小的节点会排在前面（靠近表头的方向），而成员对象较大的节点则会排在后面（靠近表尾的反向） 跳跃表通过使用zskiplist结构来持有多个跳跃表节点，程序可以更方便地对整个跳跃表进行处理，如何快速访问跳跃表的表头节点和表尾节点，或者快速地获取跳跃表节点的数量等信息 1234567891011121314* 跳跃表 */typedef struct zskiplist &#123; // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;&#125; zskiplist;","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"Redis设计与实现笔记三","date":"2019-07-04T22:55:12.000Z","path":"2019/07/05/Redis设计与实现笔记三/","text":"字典：又称符号表、关联数组、映射，是一种保存键值对的抽象数据结构。 Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，一个哈希表节点就保存了字典中的一个键值对。 哈希表：由dict.h/dictht结构定义： 1234567891011typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //该哈希表已有节点数量 unsigned long user;&#125; table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存一个键值对。size属性记录了哈希表的大小，也即是table数组的大小，而used属性则记录了哈希表目前已有节点的数量，sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放在table数组的哪个索引上面。 哈希表节点：使用dictEntry结构，每个dictEntry结构都保存一个键值对。 123456789101112typedef struct dictEntry&#123; //键 void *key; //值 union&#123; void *val; uint64_t u64; unt64_t s64; &#125;v; //指向下个哈希表节点，形成链表 strcut dictEntry *next;&#125;dictEntry; key属性保存键，v属性保存值，可以是指针、uint64_t、uint64_t。 next属性指向另一个哈希表节点指针，解决哈希冲突。 字典：由dict.h/dict结构表示： 1234567891011typedef struct dict&#123; //类型特定函数 sictType *type; //私有数据 void *privtata; //哈希表 dictht ht[2]; //rehash索引 //当rehash不在进行时，值为-1 int trehashidx;/*rehashing not in progress if rehashidx==-1 */&#125;dict; type属性和privdata属性是针对不同的类型的键值对，为创建多态字典而设置的： type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同的类型特定函数。 privdata属性则保存了需要传给那些类型特定函数的可选参数。 1234567891011121314typedef struct dictType&#123; //计算哈希值的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(*keyDup)(void *privdata,const void *key); //复制值的函数 void *(*valDup)(void *privdata,const void *obj); //对比键的函数 int (*keyCompare)(void *privdata,const void *key1.const void *key2); //销毁键的函数 void (*keyDestructor)(void *prevdata,void *key); //销毁值的函数 void (*valDestructor)(void *prevdata,void *obj);&#125;dictType； ht属性是一个包含两项的数组，数组的每一项都是一个dictht哈希表，一般，字典只使用ht[0]，ht[1]用于对ht[0]rehash。 哈希算法：Redis计算哈希值和索引值方法： 12345//使用字典设置的哈希函数，计算键key的哈希值hash = dict-&gt;type-&gt;hashFunction(key);//使用哈希值的sizemask属性和哈希值，计算索引//根据情况不同，ht[x]可以是hx[0]或者ht[1]index = hash &amp; dict-&gt;ht[x].sizemask; 解决键冲突：当有两个或者以上数量的键被分配到哈希表数组的同一个索引上面的时候，产生了冲突。 使用链地址法来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，从而解决键冲突。 新节点总是添加到链表的表头位置（复杂度为O(1)） rehash:扩展和收缩哈希表通过rehash（重新散列）完成 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量（也即是ht[0].used属性值） 如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2^n值 如果执行的收缩，那么ht[1]的大小是第一个大于等于ht[0].used的2^n值 将保存在ht[0]中的所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放在ht[1]哈希表指定位置 当ht[0]包含所有键值对都迁移到ht[1]后，释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新建一个空白哈希表，为下一次rehash做准备。 哈希表的扩展与收缩：哈希表的负载因子=哈希表已保存节点数量/哈希表大小 渐进式rehash为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1],二十分多次、渐进式地将ht[0]里面的键值对慢慢rehash。 在渐进式rehash进行期间，字典的删除、查找、更新等操作会在两个哈希表进行 渐进式rehash期间，新添加到字典的键值对一律会保存到ht[1]中","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"Redis设计与实现笔记二","date":"2019-07-03T04:52:07.000Z","path":"2019/07/03/Redis设计与实现笔记二/","text":"链表：链表和链表节点的实现：链表节点使用一个adlist.h/listNode结构表示： 12345678typedef struct listNode&#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value;&#125;listNode; 多个listNode可以通过prev和next指针组成双端链表。 使用adlist.h/list来持有链表。 1234567891011121314typedef struct list&#123; //表头节点 listNode *head; //表尾节点 listNode *tail; //链表所包含的节点数量 unsigned long len; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void *(*free)(void *ptr); //节点值对比函数 int (*match)(void *pre , void *key);&#125;list; 上图是一个由list结构和三个listNode结构组成的链表。 Redis链表实现特性: 双端：链表节点带有prev和next指针，获取某个节点的前置和后置复杂度都是O(1) 无环：表头节点的prev和表尾的next都指向NULL，对链表访问都以NULL为终点 带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点都是O(1) 带链表长度计数器：获取链表中节点数量的复杂度为O(1) 多态：链表节点使用void* 指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"nowcoder-骰子游戏","date":"2019-07-01T23:37:01.000Z","path":"2019/07/02/nowcoder-骰子游戏/","text":"题目来源：https://www.nowcoder.com/practice/0e83797c34e54cca91179fe9ad681bc4?tpId=90&amp;tqId=30849&amp;tPage=4&amp;rp=4&amp;ru=%2Fta%2F2018test&amp;qru=%2Fta%2F2018test%2Fquestion-ranking 题目描述：小易参加了一个骰子游戏,这个游戏需要同时投掷n个骰子,每个骰子都是一个印有数字1~6的均匀正方体。小易同时投掷出这n个骰子,如果这n个骰子向上面的数字之和大于等于x,小易就会获得游戏奖励。小易想让你帮他算算他获得奖励的概率有多大。 思路：12345动态规划，用dp[i][j]表示i个骰子产生数字和j的结果数，初始值dp[1][j]=1(j=1~6),dp[i] [i]=1,dp[i][6*i]=1,由于第i个骰子的点数可以为1~6，要使i个骰子的数字和为j的话，则前i-1个骰子的数字和可以为j-1~j-6，所以得到公式dp[i][j] +=dp[i-1][j-k] (k=1~6)。 参考代码：1234567891011121314151617181920212223242526272829public class Now_73 &#123; public static void main(String[] args) &#123; Scanner sc=new Scanner(System.in); int n=sc.nextInt(); int x=sc.nextInt(); if(n&gt;=x) System.out.print(1); else if(6*n&lt;x) System.out.print(0); else &#123; long[][] dp=new long[n+1][6*n+1]; for(int i=1;i&lt;=6;i++) dp[1][i]=1; for(int i=2;i&lt;=n;i++) &#123; for(int j=i;j&lt;=6*n;j++) &#123; for(int k=1;k&lt;j&amp;&amp;k&lt;=6;k++) &#123; dp[i][j]+=dp[i-1][j-k]; &#125; &#125; &#125; long total=(long)Math.pow(6,n); long sum=0; for(int i=1;i&lt;x;i++) sum+=dp[n][i]; long num=gcd(total-sum,total); System.out.print((total-sum)/num+\"/\"+total/num); &#125; &#125; private static long gcd(long a,long b) &#123; return (a%b==0)?b:gcd(b,a%b);//求最大公约数 &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"},{"name":"dp","slug":"dp","permalink":"http://www.ylovex.cn/tags/dp/"}]},{"title":"Redis设计与实现笔记一","date":"2019-07-01T13:33:42.000Z","path":"2019/07/01/Redis设计与实现笔记一/","text":"简单动态字符串：Redis并没有直接使用C语音传统的字符串（以空字符串结尾的字符数组），而是构建了一种名为简单动态字符串（simple dynamic string ， SDS）的抽象类型。 每个sds.h/sdshdr结构表示一个SDS值： 1234567891011struct sdshdr&#123; //记录buf数组中已使用字节的数量 //等于SDS所保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组，用于保存字符串 char buf[];&#125;; 下图展示了一个SDS示例： 其中： free属性的值为0，表示这个SDS没有分配任何未使用的空间 len属性的值为5，表示这个SDS保存一个5字节长的字符串 buf属性是一个char类型的数组，最后以空字符‘\\0’。 SDS遵循C字符串以空字符结尾的惯例，保存的空字符的1字节不计算在SDS的len属性中，并且为空字符分配额外的1字节空间，以及添加空字符到字符末尾等操作都是SDS自动完成，对使用者完成透明，遵循空字符结尾可以重用一部分C字符串函数库里面的函数。 SDS优点：常数复杂度获取字符串的长度：通过使用SDS而不是C字符串，Redis将获取字符串长度所需要的复杂度从O(n)降低到了O(1)。 杜绝缓冲区溢出：当SDS API需要对SDS进行修改时候，API会先检查SDS空间是否满足修改所需的要求，如果不满足的话，API会自动将SDS空间扩展至执行修改所需的大小，然后才执行实际的修改操作。 减少修改字符串时候带来的内存重分配次数：对于一个包含N个字符的C字符串，这个C字符串的底层实现总是一个N+1个字符长的数组（额外的一个字符空间用于保存空字符），因为C字符串的长度和底层数组的长度之间存在这种关联，所以每次增长或者缩短一个C字符串，程序都总要对保存这个C字符串的数组进行一个内存重分配操作： 如果程序执行的是增长字符串操作，比如拼接（append），那么在执行这个操作之前，程序需要先通过内存重分配来扩展底层数组的空间大小—如果忘了这一步就会产生缓冲区溢出。 如果程序执行的就是缩短字符串操作，比如截断（trim），那么在执行这个操作之后，程序需要通过内存重分配来释放字符串不再使用的那部分空间—如果忘了这步就会产生内存泄漏。 为了避免C字符串这种缺陷，SDS通过未使用空间解除了字符串长度和底层数组长度的关联，在SDS中，buf数组的长度不一定是字符数量加一，数组里面可以包含未使用的字节，而这个未使用的字节由SDS的free属性记录。 通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略。 空间预分配：空间预分配用于优化SDS字符串增长操作：当SDS的API对一个SDS进行修改，并且需要对SDS进行空间扩展的时候，程序不仅会为SDS分配修改所必须的空间的时候，还会为SDS分配额外的未使用空间。 其中，额外分配的未使用空间数量由以下公式决定： 如果对SDS进行修改之后，SDS的的长度将小于1MB，那么程序分配和len属性同样大小的未使用空间。 如何对SDS进行修改后，SDS的长度将大于等于1MB，那么程序会分配1MB的未使用空间。 通过空间预分配策略，Redis可以减少连续执行字符串增长操作所需要的内存重分配次数。 惰性空间释放：惰性空间释放用于优化SDS字符串缩短操作：当SDS的API需要缩短的SDS保存的字符串时候，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节数量记录起来，并等到将来使用。 二进制安全：C字符中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使C字符只能保存文本数据，不能保存像图像、音频、视频、压缩文件这样的二进制数据。 SDS的API都是二进制安全的，所有SDS API都会处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入是什么样，被读取就是什么样。 兼容部分C字符串函数：通过遵循C字符串以空字符结尾的惯例，SDS可以在有需要时重用&lt;string.h&gt;函数库，从而避免了不必要的代码重复。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.ylovex.cn/tags/Redis/"}]},{"title":"jvm自动内存管理机制","date":"2019-06-28T00:11:47.000Z","path":"2019/06/28/jvm自动内存管理机制/","text":"JVM组成：JVM 由类加载器子系统、运行时数据区、执行引擎以及本地方法接口组成。 运行时数据区域：Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。 程序计数器：是当前线程所执行的字节码的行号指示器。字节码解释器工作时候通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复都依赖该计数器。 线程私有，此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况区域。 Java虚拟机栈：存储局部变量表、操作数栈、动态链接、方法出口等信息。 线程私有。 局部变量表存放编译期可知的各种基本数据类型、对象引用和returnAddress类型（指向一条字节码指令地址）。 其中64位长度的long和double类型数据占用2个局部变量空间（slot），其余数据类型只占1个字节。 本地方法栈：虚拟机栈为虚拟机执行Java方法（字节码）服务，本地方法栈为虚拟机使用Native方法服务。 Java堆：存放对象实例，是垃圾收集器管理的主要区域。 线程共享。 方法区：存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 线程共享。 运行时常量池：是方法区的一部分。具有动态性，不仅预置入Class文件中常量池的内容可以进入方法区运行时常量池，运行期间也可以将新的常量放入池中。 对象的创建： 虚拟机遇到一条new指令时，会先去常量池检测能否找到new对应的类的符号引用，并检测这个类是否加载、初始化。 如果加载检查通过，则分配内存。分配内存有两种方式：⑴指针碰撞，针对连续内存区域；⑵空闲列表，针对不连续内存区域 内存分配完之后，会对内存初始化零值，保证实例字段能在java代码不赋初值也能使用。 接下来对对象信息进行设置，把类的元数据信息、对象的哈希吗、对象的GC分代年龄等信息存放在对象头之中 最后执行用户的Init方法 对象的内存布局： 分为三部分，对象头、实例数据、对齐填充 对象头：⑴对象自身运行时数据，如哈希吗、GC分代年龄、锁状态标志、线程持有的锁等。⑵类型指针，虚拟机通过这个来确定这个对象是哪个类的实例。⑶如果对象是一个Java数组，那么对象头中还必须有一块用于记录数组长度的数据。 实例数据：对象真正存储的有效信息，也是在程序代码中定义的各种类型的字段内容。 对齐填充：JVM要求对象的起始地址必须是8字节的整数倍，因此当对象实例数据没有对齐时，这部分来补全。 对象的访问定位：使用句柄访问：Java堆中会划分一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接指针访问：那么Java堆对象的布局中就必须考虑如何放置访问类型数据的 相关信息，而reference中存储的直接就是对象地址 Java垃圾回收区域： Java垃圾回收只针对堆和方法区的内存。 程序计数器、虚拟机栈、本地方法栈随线程而生，随线程而灭，因此不用管。 如何确认垃圾：引用计数算法：给对象中添加一个引用计数器，每当有 一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0 的对象就是不可能再被使用的。 可达性分析算法：这个算法的基本思 路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连 （用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。如图所示，对象object 5、object 6、object 7虽然互相有关联，但是它们到GC Roots是不可达 的，所以它们将会被判定为是可回收的对象。 可作为GC Roots对象有： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。 垃圾回收算法：标记-清除算法：首先标记出所有需要回收的对象，在标记完成后统一回收所有 被标记的对象。 不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法：它将可用内存按容 量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着 的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是 对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指 针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。 标记-整理算法：标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存 活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集：一般是把Java堆 分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代 中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付 出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间 对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。 JVM GC：枚举根节点要GC就得枚举根节点，如果逐一去检查引用，效率很低。因此JVM使用一组称为OopMap的数据结构，直接知道哪些地方存放着对象引用。 安全点可能导致引用关系、或者说OopMap内容变化的指令非常多，不可能为每一条指令都生成对应的OopMap，因此有了安全点，在安全点才记录OopMap，在安全点才能进行GC，例如方法调用、循环跳转、异常跳转等，具有这些功能的指令才会产生安全点 如何让GC发生时线程都跑到安全点采用主动式中断思想，GC时，不直接对线程操作，而是设置一个中断标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起，轮询标志的地方和安全点是重合的 安全区域如果程序不执行时，比如sleep了，岂不是就进不了安全点？因此有了安全区域，安全区域指在一段代码中，引用关系不会发生变化，在这个区域内GC都是安全的。线程进入安全区域后，会标志自己进入了。JVM要GC时就不会管这些线程。线程要离开安全区域时，必须检查GC是否完成，如果GC完成了线程就继续执行，否则一直等待直到GC完成。 垃圾收集器： Serial收集器：单线程，GC时候需要暂停其他所有的工作线程，直到它收集结束。 JVM运行在Client模式下的默认新生代收集器：简单而高效。 ParNew收集器：Serial收集器的多线程版本。 许多运行在Server模式下虚拟机的首选新生代收集器。 在单CPU环境次啊ParNew不会有比Serial收集器效果更好，Serial和ParNew都是与CMS配合工作。 Parallel Scavenge收集器：新生代收集器，使用复制算法。 关注吞吐量，吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）。 Serial Old收集器：是Seraial收集器的老年代版本，单线程，采用“标记-整理”算法。 Parallel Old收集器：是Parallel Scavenge收集器的老年代版本，“标记-整理”。 CMS收集器：是一种以获取最短回收停顿时间为目标的收集器。 基于“标记-清除”。 初始标记，并发标记，重新标记，并发清除。其中，初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是 标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC RootsTracing 的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变 动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远 比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起 工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 缺点：对CPU资源非常敏感、无法处理浮动垃圾、基于“标记-清除”，产生大量空间碎片。 G1收集器：是一款面向服务端应用的垃圾收集器，、并行与并发、分代收集、空间整合、可预测停顿 将整个Java堆划分多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的。 内存分配与回收策略： 对象优先在Eden分配。 老年代GC（Full GC/Major GC）一般比新生代GC（Minor GC）慢10倍以上。 大对象直接进入老年代，大对象指需要大量连续内存空间的Java对象，比如很长的字符串和数组。可通过参数设置。 长期存活的对象将进入老年代。默认15岁。 动态对象年龄判定。如果Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 空间分配担保。当出现大量对象Minor GC后仍然存活的情况，需要老年代进行分配担保，让Survivor无法容纳的对象直接进入老年代。","tags":[{"name":"java","slug":"java","permalink":"http://www.ylovex.cn/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://www.ylovex.cn/tags/jvm/"}]},{"title":"计算机网络基础","date":"2019-06-25T11:42:18.000Z","path":"2019/06/25/计算机网络基础/","text":"计算机网络基础OSI七层模型介绍：开放式系统互联，一般都叫OSI参考模型。 七层模型划分：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），每一层实现各自的功能和协议，并完成与相邻层的接口通信。 TCP/IP五层协议 在每一层都工作者不同的设备，如：交换机就工作在数据链路层的，一般的路由器是工作在网络层的。如下图： 各层协议： TCP/UDP协议的区别 TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接 TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付 TCP实时性比UDP差，UDP更适用于对高速传输和实时性有较高的通信（比如LOL这种实时对战网络游戏）或广播通信。 每一条TCP连接只能是点到点的，即TCP不支持组播或者广播传输模式。UDP支持一对一，一对多，多对一和多对多的交互通信。 TCP对系统资源要求较多，UDP对系统资源要求较少。 UDP在越来越多的场景下取代了TCP： UDP以其简单、传输快的优势，在越来越多场景下取代了TCP，不能容忍延迟比如LOL、Dota用UDP，可以容忍延迟的游戏如RPG还是用TCP。 网速的提升给UDP的稳定性提供可靠网络保障，丢包率很低，如果使用应用层重传，能够确保传输的可靠性。 网络游戏如果采用TCP，一旦发生丢包，TCP会将后续的包缓存起来，等前面的包重传并接收到后再继续发送，延时会越来越大，基于UDP对实时性要求较为严格的情况下，采用自定义重传机制，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成影响。 设计UDP丢包检查来保证可靠性： 可以采用一个近似TCP的ack机制，可以给每个数据包都添加一个sequence ID，然后服务端就依次发送数据包，客户端收到数据包后就可以根据sequence ID来判断是否有丢包了。 接下来是重点，客户端需要发该sequenceID的ack给服务端，服务端才会知道这个包是否已经送达。但这是一笔不小的开销，而且，ack本身也有可能丢包。 可以这样，客户端发送一个sequence ID的ack时，附加一个32bit的位序列，表示当前sequence ID之前的32个连续顺位的数据包是否已经送达，其实就是冗余的发送连续32个包的送达状态，如果bit为0说明这个包还没到，如果为1，说明已经收到了。这样一来，除非连续丢包30多次，ack是一定会送到的，这种几率已经非常小了。 相应的，在服务端设置一个超时机制，这个时间差不多比连续发30个ack的时间长一点，如果发送一个包后开始计时，达到超时还没有收到ack，这个包就丢失了。 但即使丢包了也不一定需要重发！是否需要重发，如何重发可以和游戏的逻辑结合起来，没有必要实现类似TCP那样的完全可靠的机制，毕竟战斗中的同步速率很高，丢一个一般也没啥事情。 TCP如何保证可靠性TCP通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制 数据被分割成TCP认为最合适的数据块 包是按序收到的，即发送顺序和接受顺序一致。 TCP发送一个段之后会启动一个定时器，等待目标端的确认信息，如果没有收到确认信息，会重发 防止序号回绕机制。即在连接期间，时间戳被用来辅助扩展32位序号，而且采用了伪随机的初始序号，防止重复数据包。 TCP保证收到的包不出错，即保持首部和数据的校验和，如果收到的校验和出错，TCP将丢弃这个数据报也不会确认这个数据报 TCP会对收到的数据进行重新排序，保证数据以正确的顺序交给应用层 TCP还有流量控制和拥塞控制 滑动窗口协议也是来保证可靠的 TCP三次握手、四次挥手TCP是面向连接的，在传输报文段之前先要建立连接。发起连接请求的一方叫客户端，想要连接请求的一方叫服务端。 第一次握手： 客户端向服务端发送请求连接报文(SYN)；其中报头控制位SYN=1，初始序列号seq=x。并进入SYN_SENT(SYN-sent)状态，等待服务器确认； 第二次握手： 服务端收到请求连接报文(SYN)后，向客户端发送确认报文(SYN+ACK包)。确认报文段的首部中，ACK=1、SYN=1。确认序号：ack=x+1，同时为自己选择一个初始序列号seq=y。此时，服务器进入SYN_RCVD（SYN-received）状态； 第三次握手： 客户端收到服务器的确认报文(SYN＋ACK包)后，还要再向服务端发送一个确认报文(ACK)。该确认报文段首部中，ACK=1，确认号是ack=y+1，自己的序列号是seq=x+1。此包发送完毕，客户端进入ESTABLISHED(established)状态，服务端收到确认报文后，也进入ESTABLISHED(established)状态。 至此TCP连接建立。 三次握手过程中传送的包里不携带数据。三次握手完毕后，客户端与服务端才正式开始传输数据。理想状态下，TCP连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。 断开一个TCP连接需要“四次挥手”，此处，客户端为主动关闭方： 第一次挥手： 此时两端还都处于ESTABLISHED状态，客户端停止发送数据，并发送一个请求断开连接报文(FIN)。（此时客户端处于半连接状态）该报文首部中，FIN=1，序列号seq=u。 服务端接收到请求报文后，进入CLOSE_WAIT(关闭等待)状态。 也就是告诉服务端，我的数据发送完了，不会再给你发数据了。(另，在FIN包发送之前发送出去的数据，如果没有收到服务端对应的ACK确认报文，主动关闭方依然会重发这些数据)；此时，客户端还可以接受数据。 第二次挥手： 服务端收到请求断开连接报文(FIN)后，回复确认报文(ACK)，确认号：ack=u+1，序列号seq=v。 客户端收到确认报文(ACK)后，进入FIN-WAIT-1(终止等待-1)状态。 现在TCP连接处于半开半闭状态，服务端如果继续发送数据，客户端依然接收。 第三次挥手： 服务端发送一个请求断开连接报文(FIN)，用来服务端到客户端的数据传送。 该报文段首部中，FIN=1，ACK=1，确认序列号ack=u+1，序列号seq=w。 客户端接收到确认断开连接报文(ACK、FIN)后，进入FIN-WAIT-2(终止等待-2)状态。也就是告诉客户端，我的数据也发送完了，不会再给你发数据了。 第四次挥手： 客户端收到确认断开连接报文(ACK、FIN)后，回复确认报文(ACK)给服务端。 确认序号ack=w+1。序列号=u+1。 然后进入TIME_WAIT(时间等待)状态。 注意：此时，TCP连接还没有被释放，需要时间等待状态结束后(2MSL)，两端才会进入CLOSED状态。设置时间等待是因为——最后一个确认报文可能会丢失，而需要重传。 seq、ack、ACK、SYN、FIN序列号seq：占4个字节，用来标记数据段的顺序，TCP把连接中发送的所有数据字节都编上一个序号，第一个字节的编号由本地随机产生；给字节编上序号后，就给每一个报文段指派一个序号；序列号seq就是这个报文段中的第一个字节的数据编号。 确认号ack：占4个字节，期待收到对方下一个报文段的第一个数据字节的序号；序列号表示报文段携带数据的第一个字节的编号；而确认号指的是期望接收到的下一个字节的编号；因此当前报文段最后一个字节的编号+1即为确认号。 确认ACK：占1位，仅当ACK=1时，确认号字段才有效。ACK=0时，确认号无效 同步SYN：连接建立时用于同步序号。当SYN=1，ACK=0时表示：这是一个连接请求报文段。若同意连接，则在响应报文段中使得SYN=1，ACK=1。因此，SYN=1表示这是一个连接请求，或连接接受报文。SYN这个标志位只有在TCP建立连接时才会被置1，握手完成后SYN标志位被置0。 终止FIN：用来释放一个连接。FIN=1表示：此报文段的发送方的数据已经发送完毕，并要求释放传输连接ACK、SYN和FIN这些大写的单词表示标志位，其值要么是1，要么是0；ack、seq小写的单词表示序号。 TCP状态中TIME_WAIT作用客户端接收到服务端的FIN报文后进入状态，此时并不是直接进入CLOSED状态，还需要等待一个时间计时器设置的时间，理由如下： 确保最后一个确认报文段能够到达，如果B没有收到A发送来的确认报文段，那么就会重新发送连接释放请求报文段，A等待一段时间就是为了处理这种情况发生。 可能存在’已失效的连接请求报文段，为了防止这种报文段出现在本次连接之外，需要等待一段时间。 服务器出现异常？如果服务器出现异常，百分之八九十都是下面两种情况： 服务器保持了大量TIME_WAIT状态 服务器保持了大量CLOSE_WAIT状态 因为linux分配给一个用户的文件句柄是有限的，而TIME_WAIT和CLOSE_WAIT两种状态如果一直被保持，那么意味着对应数目的通道就一直被占着，而且是“占着茅坑不使劲”，一旦达到句柄数上限，新的请求就无法被处理了，接着就是大量Too Many Open Files异常，tomcat崩溃。。。 服务器大量CLOSE_WAIT状态的原因？？ CLOSE_WAIT产生的原因在于：TCP Server 已经ACK了过来的FIN数据包，但是上层应用程序迟迟没有发命令关闭Server到client 端的连接。所以TCP一直在那等啊等….. 所以说如果发现自己的服务器保持了大量的CLOSE_WAIT，问题的根源十有八九是自己的server端程序代码的问题。 服务器大量TIME_WAIT状态原因？ 服务器处理大量连接并主动关闭连接时，将导致服务器端存在大量的处于TIME_WAIT状态的socket。 因为主动关闭方会进入TIME_WAIT的状态，然后在保持这个状态2MSL（max segment lifetime）时间（1到4分钟）之后，彻底关闭回收资源（被占用的是一个五元组：（协议，本地IP，本地端口，远程IP，远程端口）。对于 Web 服务器，协议是 TCP，本地 IP 通常也只有一个，本地端口默认的 80 或者 443。只剩下远程 IP 和远程端口可以变了。如果远程 IP 是相同的话，就只有远程端口可以变了。这个只有几万个）。 所以如果大量关闭，资源还没来得及回收，会导致大量TIME_WAIT。 解决方案是修改linux内核，允许将TIME-WAIT sockets重新用于新的TCP连接，并开启TCP连接中TIME-WAIT sockets的快速回收，这些默认都是关闭的。 TCP连接为什么不是两次连接防止失效的连接请求报文段被服务端接受，从而产生错误。 失效的连接请求：若客户端向服务端发送的连接请求丢失，客户端等待应答超时后就会再次发送连接请求，此时，上一个连接请求就是『失效的』。 若建立连接只需两次握手，客户端并没有太大的变化，仍然需要获得服务端的应答后才进入ESTABLISHED状态，而服务端在收到连接请求后就进入ESTABLISHED状态。此时如果网络拥塞，客户端发送的连接请求迟迟到不了服务端，客户端便超时重发请求，如果服务端正确接收并确认应答，双方便开始通信，通信结束后释放连接。此时，如果那个失效的连接请求抵达了服务端，由于只有两次握手，服务端收到请求就会进入ESTABLISHED状态，等待发送数据或主动发送数据。但此时的客户端早已进入CLOSED状态，服务端将会一直等待下去，这样浪费服务端连接资源。 TCP第三次握手失败会出现什么当失败时，服务器并不会重传ack报文，而是直接发送RTS（注意区分RST）报文段，进入CLOSED状态，防止SYN洪泛攻击。 syn洪泛攻击，通俗的理解是：当第三次握手没有发送确认信息时，等待一段时间后，主机就会断开之前的半开连接并回收资源，这为dos（deny of service）攻击埋下隐患，当主动方主动发送大量的syn数据包，但并不做出第三次握手响应，server就会为这些syn包分配资源（但并未使用），就会使server占用大量内存，使server连接环境耗尽，这就是syn洪泛攻击 RSTRST标志位RST表示复位，用来异常的关闭连接，在TCP的设计中它是不可或缺的。就像上面说的一样，发送RST包关闭连接时，不必等缓冲区的包都发出去（不像上面的FIN包），直接就丢弃缓存区的包发送RST包。而接收端收到RST包后，也不必发送ACK包来确认。 TCP处理程序会在自己认为的异常时刻发送RST包。例如，A向B发起连接，但B之上并未监听相应的端口，这时B操作系统上的TCP处理程序会发RST包。 又比如，AB正常建立连接了，正在通讯时，A向B发送了FIN包要求关连接，B发送ACK后，网断了，A通过若干原因放弃了这个连接（例如进程重启）。网通了后，B又开始发数据包，A收到后表示压力很大，不知道这野连接哪来的，就发了个RST包强制把连接关了，B收到后会出现connect reset by peer错误。 RST攻击A和服务器B之间建立了TCP连接，此时C伪造了一个TCP包发给B，使B异常的断开了与A之间的TCP连接，就是RST攻击了。实际上从上面RST标志位的功能已经可以看出这种攻击如何达到效果了。 那么伪造什么样的TCP包可以达成目的呢？我们至顶向下的看。 假定C伪装成A发过去的包，这个包如果是RST包的话，毫无疑问，B将会丢弃与A的缓冲区上所有数据，强制关掉连接。 如果发过去的包是SYN包，那么，B会表示A已经发疯了（与OS的实现有关），正常连接时又来建新连接，B主动向A发个RST包，并在自己这端强制关掉连接。 这两种方式都能够达到复位攻击的效果。似乎挺恐怖，然而关键是，如何能伪造成A发给B的包呢？这里有两个关键因素，源端口和序列号。 一个TCP连接都是四元组，由源IP、源端口、目标IP、目标端口唯一确定一个连接。所以，如果C要伪造A发给B的包，要在上面提到的IP头和TCP头，把源IP、源端口、目标IP、目标端口都填对。这里B作为服务器，IP和端口是公开的，A是我们要下手的目标，IP当然知道，但A的源端口就不清楚了，因为这可能是A随机生成的。当然，如果能够对常见的OS如windows和linux找出生成source port规律的话，还是可以搞定的。 序列号问题是与滑动窗口对应的，伪造的TCP包里需要填序列号，如果序列号的值不在A之前向B发送时B的滑动窗口内，B是会主动丢弃的。所以我们要找到能落到当时的AB间滑动窗口的序列号。这个可以暴力解决，因为一个sequence长度是32位，取值范围0-4294967296，如果窗口大小像上图中我抓到的windows下的65535的话，只需要相除，就知道最多只需要发65537（4294967296/65535=65537）个包就能有一个序列号落到滑动窗口内。RST包是很小的，IP头＋TCP头也才40字节，算算我们的带宽就知道这实在只需要几秒钟就能搞定。 发送RST的情况：在某些特殊情况下，TCP连接的一端会向另一端发送复位报文段，以通知对方关闭或重新建立连接。 访问不存在的端口。若端口不存，则直接返回RST，同时RST报文接收通告窗口大小为0。其实客户端向服务器的某个端口发起连接，如果端口被处于TIME_WAIT 状态的连接占用时，客户端也会收到RST。 异常终止连接。一方直接发送RST报文，表示异常终止连接。一旦发送方发送复位报文段，发送端所有排队等待发送的数据都被丢弃。应用程序可以通过socket选项SO_LINGER来发送RST复位报文。3.处理半打开连接。一方关闭了连接，另一方却没有收到结束报文（如网络故障），此时另一方还维持着原来的连接。而一方即使重启，也没有该连接的任何信息。这种状态就叫做半打开连接。而此时另一方往处于半打开状态的连接写数据，则对方回应RST复位报文。 TCP长连接和短连接在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 TCP流量控制流量控制：一般来说，我们希望数据传输得更快一些，但如果发送方把数据发送的过快，接收方可能来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。有两种控制方式： 基于速率流量控制，它是给发送方指定某个速率，同时确保数据永远不能超过这个速率发送。这种类型的流量控制最适合流应用程序，可被用于广播和组播发现。 基于窗口流量控制，是使用滑动窗口时最流行的方法。在这种方法里，窗口大小不是固定的，而是允许随时间而变动的。为了使用这种技术，必须有种方法让接收方可以通知发送方使用多大的窗口。这一般称为窗口通告或者窗口更新。窗口更新和ACK是由同一个分组携带的，意味着发送方往往在它的窗口滑动到右边的同时调整它的大小。 在TCP的实现中广泛使用的Nagle算法:若发送方应用进程把要发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个字节先发送出去，把后面到达的数据字节都缓存起来。当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率缓慢时，用这种方法可明显减少所用的网络带宽。Nagle算法还规定，当到达的数据已达到发送窗口大小的一半或者报文段的最大长度时，就立即发送一个报文段。这样做，可以有效提高网络的吞吐量。 TCP拥塞控制发生拥塞控制的原因：资源(带宽、交换节点的缓存、处理机)的需求&gt;可用资源。 拥塞控制就是为了防止过多的数据注入到网络中，这样可以使网络中的路由器或者链路不至于过载。拥塞控制要做的都有一个前提：就是网络能够承受现有的网络负荷。 包括：慢启动、拥塞避免、快重传、快启动。 对比流量控制：拥塞控制是一个全局的过程，涉及到所有的主机、路由器、以及降低网络相关的所有因素。流量控制往往指点对点通信量的控制。是端对端的问题。 拥塞窗口：发送方为一个动态变化的窗口叫做拥塞窗口，拥塞窗口的大小取决于网络的拥塞程度。发送方让自己的发送窗口=拥塞窗口，但是发送窗口不是一直等于拥塞窗口的，在网络情况好的时候，拥塞窗口不断的增加，发送方的窗口自然也随着增加，但是接受方的接受能力有限，在发送方的窗口达到某个大小时就不在发生变化了。发送方如果知道网络拥塞了呢？发送方发送一些报文段时，如果发送方没有在时间间隔内收到接收方的确认报文段，则就可以认为网络出现了拥塞。 慢启动：主机开发发送数据报时，如果立即将大量的数据注入到网络中，可能会出现网络的拥塞。慢启动算法就是在主机刚开始发送数据报的时候先探测一下网络的状况，如果网络状况良好，发送方每发送一次报文段都能正确的接受确认报文段。那么就从小到大的增加拥塞窗口的大小，即增加发送窗口的大小。例子：开始发送方先设置cwnd（拥塞窗口）=1,发送第一个报文段M1，接收方接收到M1后，发送方接收到接收方的确认后，把cwnd增加到2，接着发送方发送M2、M3，发送方接收到接收方发送的确认后cwnd增加到4，慢启动算法每经过一个传输轮次（认为发送方都成功接收接收方的确认），拥塞窗口cwnd就加倍。 拥塞控制：为了防止cwnd增加过快而导致网络拥塞，所以需要设置一个慢启动开始门限ssthresh状态变量（我也不知道这个到底是什么，就认为他是一个拥塞控制的标识）,它的用法： 当cwnd &lt; ssthresh,使用慢启动算法， 当cwnd &gt; ssthresh,使用拥塞控制算法，停用慢启动算法。 当cwnd = ssthresh，这两个算法都可以。 拥塞避免的思路：是让cwnd缓慢的增加而不是加倍的增长，每经历过一次往返时间就使cwnd增加1，而不是加倍，这样使cwnd缓慢的增长，比慢启动要慢的多。 无论是慢启动算法还是拥塞避免算法，只要判断网络出现拥塞，就要把慢启动开始门限(ssthresh)设置为设置为发送窗口的一半（&gt;=2），cwnd(拥塞窗口)设置为1，然后在使用慢启动算法，这样做的目的能迅速的减少主机向网络中传输数据，使发生拥塞的路由器能够把队列中堆积的分组处理完毕。拥塞窗口是按照线性的规律增长，比慢启动算法拥塞窗口增长块的多。 实例： TCP连接进行初始化的时候，cwnd=1,ssthresh=16。 在慢启动算法开始时，cwnd的初始值是1，每次发送方收到一个ACK拥塞窗口就增加1，当ssthresh =cwnd时，就启动拥塞控制算法，拥塞窗口按照规律增长， 当cwnd=24时，网络出现超时，发送方收不到确认ACK，此时设置ssthresh=12,(二分之一cwnd),设置cwnd=1,然后开始慢启动算法，当cwnd=ssthresh=12,慢启动算法变为拥塞控制算法，cwnd按照线性的速度进行增长。 AIMD(加法增大乘法减小) 乘法减小：无论在慢启动阶段还是在拥塞控制阶段，只要网络出现超时，就是将cwnd置为1，ssthresh置为cwnd的一半，然后开始执行慢启动算法（cwnd&lt;ssthresh）。 加法增大：当网络频发出现超时情况时，ssthresh就下降的很快，为了减少注入到网络中的分组数，而加法增大是指执行拥塞避免算法后，是拥塞窗口缓慢的增大，以防止网络过早出现拥塞。 这两个结合起来就是AIMD算法，是使用最广泛的算法。拥塞避免算法不能够完全的避免网络拥塞，通过控制拥塞窗口的大小只能使网络不易出现拥塞。 快重传：快重传算法要求首先接收方收到一个失序的报文段后就立刻发出重复确认，而不要等待自己发送数据时才进行捎带确认。接收方成功的接受了发送方发送来的M1、M2并且分别给发送了ACK，现在接收方没有收到M3，而接收到了M4，显然接收方不能确认M4，因为M4是失序的报文段。如果根据可靠性传输原理接收方什么都不做，但是按照快速重传算法，在收到M4、M5等报文段的时候，不断重复的向发送方发送M2的ACK,如果接收方一连收到三个重复的ACK,那么发送方不必等待重传计时器到期，由发送方尽早重传未被确认的报文段。 快恢复: 当发送发连续接收到三个确认时，就执行乘法减小算法，把慢启动开始门限（ssthresh）减半，但是接下来并不执行慢开始算法。 此时不执行慢启动算法，而是把cwnd设置为ssthresh的一半， 然后执行拥塞避免算法，使拥塞窗口缓慢增大。 TCP如何解决粘包、拆包问题我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。 粘包、拆包表现形式 现在假设客户端向服务端连续发送了两个数据包，用packet1和packet2来表示，那么服务端收到的数据可以分为三种，现列举如下： 第一种情况，接收端正常收到两个数据包，即没有发生拆包和粘包的现象： 第二种情况，接收端只收到一个数据包，由于TCP是不会出现丢包的，所以这一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。这种情况由于接收端不知道这两个数据包的界限，所以对于接收端来说很难处理 第三种情况，这种情况有两种表现形式，如下图。接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。这两种情况如果不加特殊处理，对于接收端同样是不好处理的。 发生TCP粘包或拆包有很多原因，现列出常见的几点： 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。等等。 粘包、拆包解决办法：通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个： 发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。 发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。 可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。等等。。。 IP知识点总结IP（Internet Protocol）即网络之间互连的协议。网络层的功能是基于IP地址进行不同网络系统间的路径选择。 IP作用：对不同数据链路的相异特性进行抽象化，在复杂的网络环境中将数据包发给最终的目标地址。 IP的两大功能 路由控制 含义：指分组数据发送到最终目标地址的功能。 作用：即使网络非常复杂，通过路由控制就可以确定到达目标地址的通路。 例子：坐火车，每到一站再向车站工作人员打听接下来该坐什么车。“各跳之间无计划传输”。火车-数据链路，旅客-IP数据包，车站工作人员-路由器。 路由控制表：所有主机都维护着一张路由控制表（Routing Table），记录了IP数据在下一步应该发给哪个路由器。IP包根据这个路由表在各个数据链路上传输。 数据链路的抽象化 IP对不同数据链路进行了抽象。那么不同数据链路之间最大的区别是：他们各自的最大传输单位（MTU，Maximum Transmission Unit）不同。IP会进行分片处理（IP Fragmentation），将较大的IP包分成多个较小的IP包。 从网络层上看，可以忽略数据包在各个数据链路上的MTU，只需要按照原地址发送的长度接收数据包。 IP属于面向无连接型 无连接型含义：发包之前，不需要建立与对端目标地址之间的连接。上次如果有需要发送给IP的数据，该数据会立即被压缩成IP包发出去。 缺点：产生冗余的通信。 为什么IP要采用面向无连接？简化：面向连接相对复杂，管理每个连接本身就是一个很繁琐的事情。提速：每次通信之前都要事先建立连接，会降低处理速度。需要有连接时，可以委托上一层提供此项服务。 IP地址的分类: A类地址:定义：首位0开头，后24位是主机标识；网络地址范围：0.0.0.0~127.0.0.0；一个网段内可以容纳的主机上限是2^24-2个 B类地址：定义：前两位是10的地址，后16位是主机标识；网络地址范围：128.0.0.1~191.255.0.0；一个网段可以容纳的主机上限是2^16-2个 C类地址：定义：前三位是110的地址，前24位是网络标识，后8位是主机标识。网络地址范围：192.0.0.0~239.255.255.0；一个网段内可容纳的主机地址上限是2^8-2个(254个) D类地址：定义：前四位是1110的地址，前32位是网络标识；网络地址范围：224.0.0.0~239.255.255.255；D类地址没有主机标识，常被用于多播 关于分配IP主机地址的注意事项： 主机地址不可以全部为0或全部为1。 全部为0标识对应的网络地址或IP地址不可获知。 全部为1的主机地址通常作为广播地址。 所以以上每个网段的主机数量上限是2^n-2个。 广播地址： 广播地址定义：IP地址的主机标识全部设置为1。 广播定义：向某个网段的广播地址发送IP包，这个网段的所有主机都能收到这个包，由主机IP之上的一层去判断是否接收数据。 缺点：给毫无关系的网络或主机带来影响，造成不必要的流量。 子网掩码 作用：理论上B类网络一个链路允许65000多台计算机连接。然而实际网络架构中，一般不会有在同一连路上连接65000多台计算机的情况。因此，直接使用A\\B\\C类地址，有点浪费资源，人们开始采用一种新的组合方式减少地址空间的浪费。子网掩码可以通过子网网络地址细分出比A\\B\\C类更小粒度的网络。 定义子网掩码用二进制方式表示，也是32位二进制数字， 规则1表示IP地址的网络地址对应位。0表示IP地址的主机地址对应位。 特点子网掩码可以灵活指定网络标识的长度，从而网络粒度更细。 路由控制 作用：仅仅有IP地址不足以将数据发向目标地址，在数据发送过程中需要“指明路由器或主机”的信息，以便真正发往目标地址。保存这种信息的就是路由控制表（Routing Table）。该表是由一个“路由协议”（有别于IP协议）制作而成的。 路由控制与IP地址默认路由主机路由环回地址同一台计算机的程序之间进行网络通信，使用一个特殊IP地址 127.0.0.1作为环回地址，与该地址等价的是localhost主机名。使用这个IP或主机名，数据包不会发向网络。 路由控制表的聚合，又称路由汇总（Aggregation）。作用：路由表越大，管理它需要的内存和CPU也就越大，而且查找路由表的时间就越长，导致转发IP数据包的性能下降。如果要构建大规模、高性能网络，需要尽可能削减路由表的大小。利用网络地址的比特分步进行分层配置。对内即使有多个子网掩码，对外呈现出的也是同一个网络地址。 IP对数据的处理背景&amp;作用每种数据链路的MTU之所以不同，是因为每个不同类型的数据链路的使用目的不同，可承载的MTU也就不同。IP数据传递到下一层数据链路层时，可能需要进行分片处理（IP Fragmentation)。规则按照路径中存在的所有数据链路中 最小的MTU发送，可以避免中途的路由器进行分片处理。 IPv6 定义：8个16位，共128比特，是IPv4长度的4倍。 作用：从根本上解决IPv4地址耗尽的问题。 特点：依旧适应互联网分层构造，路由控制上也尽可能避免路由表膨大，性能提升，简化首部，路由器不再分片，通过路径MTU只由发送端主机进行分片处理；即插即用；采用认证与加密功能；多播、Moblie IP比IPv4更顺利使用 规则每16位比特为一组，用”:”隔开。出现连续的0时可以省略，用”::”表示。一个IP地址只允许出现一次“::”。 IP包的具体内容 IPv4首部IP首部包含着 用IP协议进行发包控制时 所有的必要信息。首部以每32比特（8字节）为一个单位： 版本号：4比特，IPv4即值为4 首部长度（IHL：Internet Header Length）：IP首部大小。4比特，单位是4字节。值为5时，IP首部长度为4*5=20字节。 区分服务（TOS：Type Of Service）：表明服务质量。8比特，现已划分为DSCP和ECN两个字段。 总长度（Total Length）：表示IP首部与数据部分的总字节数。该字段长16比特。因此IP包最大长度是65535字节。 标识（ID：Identification）:用于分片重组，该字段长16比特。同一分片的标识值相同，不同分片的标识值不同。 标志（Flags）:表示包被分片的相关信息，该字段长3比特。可以表示 是否使用分片、是否分片的最后一个包。 片偏移（FO：Fragment Offset）:标识被分片的每一个分段相对于原始数据的位置。该字段长13比特。单位是8字节，因此最大可以表示8* 2^13 =65536字节的位置。 生存时间（TTL：Time To Live）：指可以中转多少个路由器，没经过一个路由器，TTL会减1，该字段长度为8比特。因此一个包的中转路由次数不会超过2^8=256次。由此可以避免IP包在网络内无限传递的问题。 协议（Protocol）：表示IP首部的下一个首部属于哪个协议（其实就是上层协议）。该字段长度8比特。 首部校验和（Header Checksum）：按照一定算法校验数据报的首部，不校验数据部分，主要来确保IP数据报不被破坏。该字段长度16比特。 源地址（Source Address）：32比特，表示发送端IP地址。 目标地址（Destination Address）：32比特，表示接收端IP地址。 可选项（Options）:长度可变，通常只用于实验或诊断时使用。包含如下几点信息：安全级别源路径路径记录时间戳填充（Padding）：再有可选项的情况下，首部长度可能不是32比特的整数倍。为此，通过向该字段填充0，调整为32比特的整数倍。 IP包数据部分OSI模型网络层之下 数据链路层的数据帧 就是IP包的数据部分。IP首部是对数据进行包装，增加了网络层的控制信息。* ICMP协议架构IP网络时需要注意：确认网络是否正常工作，以及遇到异常时进行问题诊断 作用 确定IP包是否成功送达目标地址 通知发在发送过程中IP包被废弃的原因 改善网络设置 根据以上，就可以获得网路是否正常、设置是否有误以及设备有何异常等信息，从而便于进行网络上的问题诊断。网络的设置可以包括很多内容：网线、IP地址和子网掩码的设置、路由表的和值、DNS服务器的设置、邮件服务器的设置以及代理服务器的设置等。而ICMP只负责与IP相关的设置。 ICMP的包以明文的形式像TCP、UDP一样通过IP进行传输。然而，ICMP所承担的功能并非传输层的补充，而应该把它视为IP的一部分。 ICMP的消息分为两类：通知出错原因的错误消息;用于诊断的查询消息 ICMP超时消息IP包首部有一个字段TTL，每经过一个路由器就会减1，直到减到0时IP报就会被丢弃。此时，IP路由器将会发送一个ICMP超时的消息给发送端，通知该包已被丢弃。 ICMP回送消息用于进行通信的主机或路由器之间，判断所发送的数据包是否已经成功到达对端的一种消息。向对端主机发送 回送请求消息（ICMP Echo Request Message）,接收对端主机发回来的 回送应答消息（ICMP Echo Reply Message）。ping命令（Packet InterNetwork Groper） 就是利用这个消息实现的。还有ICMP路由器探索消息用于发现与自己相连网络中的路由器、ICMP地址掩码消息获取子网掩码的信息。 ARP解析过程ARP是一种能够实现IP地址到物理地址的转化协议，以目标地址为线索用来定义下一位应该接收数据分包的网络设备对应的MAC地址，如果目标主机不在同一个数据链路层的话，可以通过ARP查找下一跳路由器的MAC地址，ARP只识用于IPV4，IPV6可以使用ICMPV6替代。 ARP工作过程：ARP借助ARP请求包和响应包来确定MAC地址。 例如：处在同一链路上的主机A 向B发送一个IP请求包，且互不知MAC地址：主机为了获取主机B的 MAC地址，起初通过广播发送一个ARP请求包，此包包含想要获取MAC地址主机的IP地址，因此ARP的请求包中会被同一链路上的所有主机或路由解析，如果ARP请求包中的目标IP与自己的IP地址相同，那么此节点就将自己MAC地址塞入ARP响应包，返回给主机A。 ARP缓存表：如果每发送一次IP数据包就进行一次ARP请求获取MAC地址，会造成不必要的网络流量。通常做法就是把获取的MAC地址缓存一端时间，即把第一次通过ARP获取的MAC地址作为IP对MAC的映射关系记忆，下一次如果若向该IP发送数据的时候，直接使用缓存表中的多应的MAC地址进行通信即可。当然每执行一次ARP请求去，其对应的ARP都会被清除。 DNS原理网络通讯大部分是基于TCP/IP的，而TCP/IP是基于IP地址的，所以计算机在网络上进行通讯时只能识别如“202.96.134.133”之类的IP地址，而不能认识域名。我们无法记住10个以上IP地址的网站，所以我们访问网站时，更多的是在浏览器地址栏中输入域名，就能看到所需要的页面，这是因为有一个叫“DNS服务器”的计算机自动把我们的域名“翻译”成了相应的IP地址，然后调出IP地址所对应的网页。 DNS( Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是用来将主机名和域名转换为IP地址的工作 DNS 的过程 首先是查找浏览器缓存，浏览器会保存一段时间你之前访问过的一些网址的DNS信息，不同浏览器保存的时常不等。 如果没有找到对应的记录，这个时候浏览器会尝试调用系统缓存来继续查找这个网址的对应DNS信息。 如果还是没找到对应的IP，那么接着会发送一个请求到路由器上，然后路由器在自己的路由器缓存上查找记录，路由器一般也存有DNS信息。 如果还是没有，这个请求就会被发送到ISP（注：Internet Service Provider，互联网服务提供商，就是那些拉网线到你家里的运营商，中国电信中国移动什么的），ISP也会有相应的ISP DNS服务器，一听中国电信就知道这个DNS服务器的规模肯定不会小，所以基本上都能在这里找得到。题外话：会跑到这里进行查询是因为你没有改动过”网络中心”的”ipv4”的DNS地址，万恶的电信联通可以改动了这个DNS服务器，换句话说他们可以让你的浏览器跳转到他们设定的页面上，这也就是人尽皆知的DNS和HTTP劫持，ISP们还美名曰“免费推送服务”。强烈鄙视这种霸王行为。我们也可以自行修改DNS服务器来防止DNS被ISP污染。 如果还是没有的话， 你的ISP的DNS服务器会将请求发向根域名服务器进行搜索。根域名服务器就是面向全球的顶级DNS服务器，共有13台逻辑上的服务器，从A到M命名，真正的实体服务器则有几百台，分布于全球各大洲。所以这些服务器有真正完整的DNS数据库。如果到了这里还是找不到域名的对应信息，那只能说明一个问题：这个域名本来就不存在，它没有在网上正式注册过。或者卖域名的把它回收掉了（通常是因为欠费）。 这也就是为什么打开一个新页面会有点慢，因为本地没什么缓存，要这样递归地查询下去 DHCP动态主机配置协议即自动给主机配置IP地址、网络掩码等信息。 DHCP如何实现分配IP？ 首先每个网络必须有一个DHCP服务器 计算机启动时，在自己的网络上广播一个报文，请求IP地址 这个请求就是DHCP DISCOVER包，这个包必须到达DHCP服务器 DHCP收到请求了就给主机分配一个IP地址，并通过DHCP OFFER包返回给主机 为了在主机没有IP地址的情况下完成此项工作，服务器用主机的以太网地址来标识这台主机 防止IP地址过期为了避免主机离开网络，并没有把IP地址返回给DHCP服务器，因此DHCP服务器在分配IP地址的时候都会指定一个有效期。在有效期满之前，主机必须请求续订。 DHCP数据包格式及其原理DHCP可为主机配置除了IP地址以外的其他各种参数，比如网络掩码、默认网关的IP地址，DNS服务器和时间服务器的IP地址。 HTTP简介HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写，是用于从万维网（WWW：World Wide Web）服务器传输超文本到本地浏览器的传送协议。HTTP基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。工作于客户端-服务端架构上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。Web服务器根据接收到的请求，向客户端发送响应信息。（明文传输） HTTP之请求消息Request：请求行、请求头部（header）、空行和请求数据四部分组成。 HTTP响应消息Response：HTTP响应由四个部分组成：状态行、消息报头、空行和响应正文 HTTPS和HTTP区别 http是HTTP协议运行在TCP之上。所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。 https是HTTP运行在SSL/TLS之上，SSL/TLS运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。此外客户端可以验证服务器端的身份，如果配置了客户端验证，服务器方也可以验证客户端的身份。 https协议需要到ca申请证书，一般免费证书很少，需要交费。 http是超文本传输协议，信息是明文传输，https 则是具有安全性的ssl加密传输协议 http和https使用的是完全不同的连接方式用的端口也不一样,前者是80,后者是443。 http的连接很简单,是无状态的 HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议 要比http协议安全 HTTPS不足之处： HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电； HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响； SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。 SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。 HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。 HTTPS建立连接过程建立HTTPS连接前需要建立SSL加密 过程： 客户端发送请求到服务器端 服务器端返回证书和公开密钥，公开密钥作为证书的一部分而存在 客户端验证证书和公开密钥的有效性，如果有效，则生成共享密钥并使用公开密钥加密发送到服务器端 服务器端使用私有密钥解密数据，并使用收到的共享密钥加密数据，发送到客户端 客户端使用共享密钥解密数据 一次完整HTTP请求 网址进行DNS域名解析，得到对应的IP地址 根据这个IP，找到对应的服务器，发起TCP的三次握手 建立TCP连接后发起HTTP请求 服务器响应HTTP请求，浏览器得到html代码 浏览器解析html代码，并请求html代码中的资源（如js、css图片等）（先得到html代码，才能去找这些资源） 浏览器对页面进行渲染呈现给用户 注： DNS域名解析采用的是递归查询的方式，过程是，先去找DNS缓存-&gt;缓存找不到就去找根域名服务器-&gt;根域名又会去找下一级，这样递归查找之后，找到了，给我们的web浏览器。 为什么HTTP协议要基于TCP来实现？ TCP是一个端到端的可靠的面相连接的协议，HTTP基于传输层TCP协议不用担心数据传输的各种问题（当发生错误时，会重传） 最后一步浏览器是如何对页面进行渲染的？ a）解析html文件构成 DOM树，b）解析CSS文件构成渲染树， c）边解析，边渲染 ， d）JS 单线程运行，JS有可能修改DOM结构，意味着JS执行完成前，后续所有资源的下载是没有必要的，所以JS是单线程，会阻塞后续资源下载 HTTP1.0 HTTP1.1 HTTP2.0HTTP1.0、HTTP 1.1主要区别长链接：HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。HTTP是基于TCP/IP协议的，创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。 节约带宽：HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。另外HTTP还支持传送内容的一部分。这样当客户端已经有一部分的资源后，只需要跟服务器请求另外的部分资源即可。这是支持文件断点续传的基础 HOST域：现在可以web server例如tomat，设置虚拟站点是非常常见的，也即是说，web serve上的多个虚拟站点可以共享同一个ip和端口。HTTP1.0是没有host域的，HTTP1.1才支持这个参数。 HTTP 1.1、HTTP2.0主要区别多路复用：HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。当然HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。TCP连接有一个预热和保护的过程，先检查数据是否传送成功，一旦成功过，则慢慢加大传输速度。因此对应瞬时并发的连接，服务器的响应就会变慢。所以最好能使用一个建立好的连接，并且这个连接可以支持瞬时并发的请求。 数据压缩：HTTP1.1不支持header数据的压缩，HTTP2.0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。 服务器推送：当我们对支持HTTP2.0的web server请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源。服务器端推送的这些资源其实存在客户端的某处地方，客户端直接从本地加载这些资源就可以了，不用走网络，速度自然是快很多的。 服务端推送过来的资源，会统一放在一个网络与http缓存之间的一个地方，在这里可以理解为“本地”。当客户端把index.html解析完以后，会向本地请求这个资源。由于资源已经本地化，所以这个请求的速度非常快，这也是服务端推送性能优势的体现之一 session和cookie会话（Session）跟踪是Web程序中常用的技术，用来跟踪用户的整个会话。常用的会话跟踪技术是Cookie与Session。Cookie通过在客户端记录信息确定用户身份，Session通过在服务器端记录信息确定用户身份。 理论上，一个用户的所有请求操作都应该属于同一个会话，而另一个用户的所有请求操作则应该属于另一个会话，二者不能混淆HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话。即用户A购买了一件商品放入购物车内，当再次购买商品时服务器已经无法判断该购买行为是属于用户A的会话还是用户B的会话了。要跟踪该会话，必须引入一种机制。 Cookie ：由于HTTP是一种无状态的协议，服务器单从网络连接上无从知道客户身份。怎么办呢？就给客户端们颁发一个通行证吧，每人一个，无论谁访问都必须携带自己通行证。这样服务器就能从通行证上确认客户身份了。这就是Cookie的工作原理。Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客 户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。 Session：Session是另一种记录客户状态的机制，不同的是Cookie保存在客户端浏览器中，而Session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。如果说Cookie机制是通过检查客户身上的“通行证”来确定客户身份的话，那么Session机制就是通过检查服务器上的“客户明细表”来确认客户身份。Session相当于程序在服务器上建立的一份客户档案，客户来访的时候只需要查询客户档案表就可以了。 区别： 存放的位置：cookie保存在客户端，session一般保存在服务器端的文件系统或数据库或mamcache 安全性：由于session存放在服务器端，而客户端可以集中采用软、硬件技术保证安全性，所以cookie的安全性较session弱； 网络传输量：cookie需通过网络实现客户端与服务器端之间的传输，而session保存在服务器端，无需传输； 生存时间（以设置24分钟为例）（1）cookie的生命周期是累计的。从创建的时候就开始计时，24分钟后cookie生命周期结束，cookie自动失效；（2）session的生命周期是间隔的，从创建时开始计时，比如在24分钟内（php.ini默认session的失效时间就是1440s，即24m）没有访问过session(指没有执行含session的文件)，那么session信息就自动无效，但如果在24分钟之内，比如第23分钟访问过session，那么它的生命周期将重新开始计算。 GET和POST在客户机和服务器之间进行请求-响应时，两种最常被用到的方法是：GET 和 POST。GET - 从指定的资源请求数据。POST - 向指定的资源提交要被处理的数据 GET交互 GET交互方式是从服务器上获取数据，而并非修改数据，所以GET交互方式是安全的。就像数据库查询一样，从数据库查询数据，并不会影响数据库的数据信息，对数据库来说，也就是安全的。 GET交互方式是幂等的，幂等是一个数学概念，幂等函数就是可以使用相同参数重复执行，并且能获得相同结果的函数。在GET交互这里就是，对同一个URL的多个请求，得到的结果是相同的。就像数据库查询，不同的数据库连接对同一个数据库表用相同条件查询时，得到的结果也是一样的。 POST交互 POST交互是可以修改服务器数据的一种方式，涉及到信息的修改，就会有安全问题。就像数据库的更新，Update一个数据库表时，如果条件没有写对，就可能把不需要修改的数据给修改了，得到的数据就是错误的了。 一般的POST交互是必须要用到表单的，但是表单提交的默认方法是GET，如果改为POST方式，就需要修改表单提交时的Method。 区别： get参数通过url传递，post放在request body中。 get请求在url中传递的参数是有长度限制的，而post没有。 get比post更不安全，因为参数直接暴露在url中，所以不能用来传递敏感信息。 1：get请求只能进行url编码，而post支持多种编码方式；2：get请求会浏览器主动cache，而post支持多种编码方式。3：get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留。 GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 GET产生一个TCP数据包；POST产生两个TCP数据包。 对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。 状态码 2开头 （请求成功）表示成功处理了请求的状态代码。 3开头 （请求被重定向）表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。 4开头 （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。 5开头（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。 2XX 200 OK 204 No Content：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。 206 Partial Content ：表示客户端进行了范围请求。响应报文包含由 Content-Range 指定范围的实体内容。 3XX 301：表示永久重定向（301 moved permanently），表示请求的资源分配了新url，以后应使用新url。 302：表示临时性重定向（302 found），请求的资源临时分配了新url，本次请求暂且使用新url。302与301的区别是，302表示临时性重定向，重定向的url还有可能还会改变。 303：表示请求的资源路径发生改变，使用GET方法请求新url。她与302的功能一样，但是明确指出使用GET方法请求新url。新url指的是，第一次请求返回的location。 304 not modified：客户端发送附带条件的请求时（if-matched,if-modified-since,if-none-match,if-range,if-unmodified-since任一个）服务器端允许请求访问资源，但因发生请求未满足条件的情况后，直接返回304Modified（服务器端资源未改变，可直接使用客户端未过期的缓存）。304状态码返回时，不包含任何响应的主体部分。304虽然被划分在3xx类别中，但是和重定向没有关系。 4XX 400 Bad Request：请求报文中存在语法错误。 401 Unauthorized：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。 403 Forbidden ：请求被拒绝，服务器端没有必要给出拒绝的详细理由。 404 Not Found 5XX 500 Internal Server Error：服务器正在执行请求时发生错误。 503 Service Unavailable ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。 HTTP方法客户端发送的 请求报文 第一行为请求行，包含了方法字段。 GET 获取资源，当前网络请求中，绝大部分使用的是 GET 方法。 HEAD 获取报文首部，和 GET 方法一样，但是不返回报文实体主体部分。主要用于确认 URL 的有效性以及资源更新的日期时间等。 POST 传输实体主体，POST 主要用来传输数据，而 GET 主要用来获取资源。 PUT 上传文件，由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法。 123456PUT /new.html HTTP/1.1Host: example.comContent-type: text/htmlContent-length: 16&lt;p&gt;New File&lt;/p&gt; PATCH 对资源进行部分修改，PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改。 1234567PATCH /file.txt HTTP/1.1Host: www.example.comContent-Type: application/exampleIf-Match: &quot;e0023aa4e&quot;Content-Length: 100[description of changes] DELETE 删除文件，与 PUT 功能相反，并且同样不带验证机制。 1DELETE /file.html HTTP/1.1 OPTIONS 查询支持的方法，、查询指定的 URL 能够支持的方法。会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容。 CONNECT 要求在与代理服务器通信时建立隧道，使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加密后经网络隧道传输。 HTTP请求格式主要有四部分组成，分别是：请求行、请求头、空行、消息体，每部分内容占一行 请求行：由三部分组成，GET/POST请求方法、请求资源URL、HTTP版本号 请求头：和缓存相关的头（Cache-Control，If-Modified-Since），客户端身份信息（User-Agent）等等 消息体：客户端发给服务端的请求数据，这部分数据并不是每个请求必须的 HTTP响应格式包括：状态行、响应头、空行、消息体。每部分内容占一行 状态行：HTTP协议版本号，状态码和状态说明三部分构成 响应头：响应头是服务器传递给客户端用于说明服务器的一些信息（Content-Type，charset等），以及将来继续访问该资源时的策略。 响应体：返回给客户端的HTML文本内容，或者其他格式的数据，比如：视频流、图片或者音频数据。 TCP\\UDP常用端口端口号的范围是从1～65535。其中1～1024是被RFC 3232规定好了的，被称作“众所周知的端口”(Well Known Ports)；从1025～65535的端口被称为动态端口（Dynamic Ports），可用来建立与其它主机的会话，也可由用户自定义用途。 TCP 21端口：FTP 文件传输服务 TCP 23端口：TELNET 终端仿真服务，远程登录 TCP 25端口：SMTP 简单邮件传输服务，发送邮件 UDP 53端口：DNS 域名解析服务 TCP 80端口：HTTP 超文本传输服务 TCP 110端口：POP3 “邮局协议版本3”使用的端口，接收邮件 TCP 443端口：HTTPS 加密的超文本传输服务 参考https://github.com/ZXZxin/ZXBlog https://www.zhihu.com/question/24853633 https://blog.csdn.net/jankin6/article/details/79192095 https://www.jianshu.com/p/1183208dd5e3 https://www.cnblogs.com/zhangyinhua/p/7611420.html https://baijiahao.baidu.com/s?id=1593714120815701015&amp;wfr=spider&amp;for=pc https://coding.imooc.com/lesson/132.html#mid=8907 https://blog.csdn.net/wenqian1991/article/details/40110703 https://www.cnblogs.com/huenchao/p/6266352.html","tags":[{"name":"网络","slug":"网络","permalink":"http://www.ylovex.cn/tags/网络/"}]},{"title":"nowcoder-数位重排","date":"2019-06-18T12:32:06.000Z","path":"2019/06/18/nowcoder-数位重排/","text":"题目来源：https://www.nowcoder.com/practice/f970201e9f7e4040ab25a40918e27d15?tpId=90&amp;tqId=30847&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：牛牛有一个正整数x,牛牛需要把数字x中的数位进行重排得到一个新数(不同于x的数),牛牛想知道这个新数是否可能是原x的倍数。请你来帮他解决这个问题。 思路：题目要求将x中的数位重排得到的新数是否可能是原x的倍数；只需判断x的2到9的倍数中是否存在由x重排后得到的数。 参考代码：123456789101112131415161718192021222324252627282930313233343536public class Now_71&#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); boolean[] booleans = new boolean[n]; for(int i=0;i&lt;n;i++)&#123; booleans[i] = isCheck(sc.nextInt()); &#125; for(int i=0;i&lt;n;i++)&#123; if(booleans[i])&#123; System.out.println(&quot;Possible&quot;); &#125; else &#123; System.out.println(&quot;Impossible&quot;); &#125; &#125; &#125; private static boolean isCheck(int num) &#123; for(int i=2;i&lt;=9;i++)&#123; String s1 = String.valueOf(num*i); String s2 = String.valueOf(num); char[] c1 = s1.toCharArray(); char[] c2 = s2.toCharArray(); if(c1.length != c2.length) continue; Arrays.sort(c1); Arrays.sort(c2); String s3 = String.valueOf(c1); String s4 = String.valueOf(c2); if(s3.equals(s4))&#123; return true; &#125; &#125; return false; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"}]},{"title":"数据库基础","date":"2019-06-15T01:30:43.000Z","path":"2019/06/15/数据库基础/","text":"数据库类别关系型数据库关系型数据库模型是把复杂的数据结构归结为简单的二元关系（即二维表格形式）。在关系型数据库中，对数据的操作几乎全部建立在一个或多个关系表格上，通过对这些关联的表格分类、合并、连接或选取等运算来实现数据库的管理。包括：Mysql、Oracle、DB2、Sqlserver 非关系型数据库NoSQL是非关系型数据库的广义定义，如下小结：NOSQL不是否定关系数据库，而是作为关系数据库的一个重要补充。NOSQL为了高性能、高并发而生，忽略影响高性能、高并发的功能。NOSQL典型产品memcached（纯内存），redis（持久化缓存），mongodb（面向文档） 键值存储数据库（key-value） 键值数据库就类似传统语言中使用的哈希表。可以通过key来添加、查询或者删除数据库，因为使用key主键访问，所以会获得很高的性能及扩展性。键值数据库主要使用一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说的优势在于简单、易部署、高并发。典型产品：Memcached、Redis、MemcacheDB: 列存储（Column-oriented）数据库:列存储数据库将数据存储在列族中，一个列族存储经常被一起查询的相关数据，比如人类，我们经常会查询某个人的姓名和年龄，而不是薪资。这种情况下姓名和年龄会被放到一个列族中，薪资会被放到另一个列族中。这种数据库通常用来应对分布式存储海量数据。典型产品：Cassandra、HBase 面向文档（Document-Oriented）数据库:文档型数据库的灵感是来自于Lotus Notes办公软件，而且它同第一种键值数据库类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可以 看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。面向文档数据库会将数据以文档形式存储。每个文档都是自包含的数据单元，是一系列数据项的集合。每个数据项都有一个名词与对应值，值既可以是简单的数据类型，如字符串、数字和日期等；也可以是复杂的类型，如有序列表和关联对象。数据存储的最小单位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用XML、JSON或JSONB等多种形式存储。典型产品：MongoDB、CouchDB 图形数据库图形数据库允许我们将数据以图的方式存储。实体会被作为顶点，而实体之间的关系则会被作为边。比如我们有三个实体，Steve Jobs、Apple和Next，则会有两个“Founded by”的边将Apple和Next连接到Steve Jobs。典型产品：Neo4J、InforGrid 关系型和非关系型数据库区别关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织。优点： 易于维护：都是使用表结构，格式一致； 使用方便：SQL语言通用，可用于复杂查询； 复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。 缺点： 读写性能比较差，尤其是海量数据的高效率读写； 固定的表结构，灵活度稍欠； 不能满足高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。 非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方式的集合，可以是文档或者键值对等。 优点： 格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。 速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘； 高扩展性； 成本低：nosql数据库部署简单，基本都是开源软件。 缺点： 不提供sql支持，学习和使用成本较高； 无事务处理； 数据结构相对复杂，复杂查询方面稍欠。 Innodb和MyIASM：区别： MyIASM是非事务安全的，而InnoDB是事务安全的 MyIASM锁的粒度是表级的，而InnoDB支持行级锁 MyIASM不支持外键，InnoDB支持外键 MyIASM支持全文类型（FullText）索引，而InnoDB不支持全文类型索引 MyIASM保存了表的行数，InnDB没有保存表的行数 MyIASM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyIASM 应用场景： InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB MyIASM管理非事务表，提供高速存储和检索以及全文搜索能力，如果再应用中执行大量select操作，应该选择MyIASM 对于一般的Web应用来说，应该选择MyIASM，效率更高，特定场景再用InnoDB 数据库三大范式：第一范式（1NF）即表中的列的具有原子性，不可再分解，即列的信息，不能分解, 只要数据库是关系型数据库(MySQL/oracle/db2 /SQL server)，就自动的满足1NF。数据库表的每一列都是不可分割的原子数据项，而不能是集合，数组，记录等非原子数据项。如果实体中的某个属性有多个值时，必须拆分为不同的属性。通俗理解即一个字段只存储一项信息。 第二范式（2NF）第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被唯一地区分。为实现区分通常需要我们设计一个主键来实现。 第三范式（3NF）满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中定义的非主键字段 事务满足ACID条件：原子性、一致性、隔离性、持久性 原子性：一个事务中的所有操作，要么全部完成，要么全部不完成 一致性：在事务开始之前和结束后，数据库的完整性没有被破坏 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。 持久性：事务结束之后，事务的结果是持久性的，即使断电结果也能保存下来 事务处理主要方法： 用BEGIN、ROLLBACK、COMMIT实现，BEGIN开始一个事务、ROLLBACK事务回滚、COMMIT事务确认 直接用SET来改变MySQL的自动提交模式，SET AUTHCOMMIT=0禁止自动提交、SET AUTHCOMMIT=1开启自动提交 隔离级别Read Uncommitted读未提交就是其他事务做到一半还未提交的数值可以被读出来 脏读：事务可以读取未提交的数据 Read Committed读已提交就是读取其他事务提交后的数值，比如B事务修改了某数据后还没有提交的话，A事务看到的值仍然是修改之前的数值。 可避免脏读的发生 Repeatable Read可重复读就是在开始读取数据（A事务开启）时候，即使其他事务修改了数据，但A事务读到的数据不管读几次都是不变的 可避免脏读、不可重复读的发生：不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了 幻读：可重复读可能产生幻读，A事务开始准备插入一条记录id=6，B事务同时开始并成功插入一条记录id=6，此时A执行插入id=6操作，结果插入失败，因为id=6记录已经存在，这就是幻读。Innodb通过多版本并发控制(MVCC)解决了幻读问题。 Serializable读加共享锁，写加排他锁 以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式（类似于Java多线程中的锁）使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read（可重复读）。 事务回滚机制事务是用户定义的一个数据库操作序列，这些操作要么全做要么全不做，是一个不可分割的工作单位，事务回滚是指将该事务已经完成的对数据库的更新操作撤销。 要同时修改数据库中两个不同表时，如果它们不是一个事务的话，当第一个表修改完，可能第二个表修改过程中出现了异常而没能修改，此时就只有第二个表依旧是未修改之前的状态，而第一个表已经被修改完毕。而当你把它们设定为一个事务的时候，当第一个表修改完，第二表修改出现异常而没能修改，第一个表和第二个表都要回到未修改的状态，这就是所谓的事务回滚 锁数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。 加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。 锁分类： 按操作划分：DML锁，DDL锁 按锁的粒度划分：表级锁、行级锁、页级锁 按锁级别划分：共享锁、排他锁 按加锁方式划分：自动锁、显示锁 按使用方式划分：乐观锁、悲观锁 悲观锁：顾名思义，就是很悲观，每次去拿（取）数据的时候都认为别人会修改，所以每次在拿（取）数据的时候都会上锁，这样别人想拿这个数据就会block（阻塞）直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 悲观锁优缺点：悲观并发控制(悲观锁)采用”先取锁再分”的保守策略，为数据处理提供了安全的保证。但在效率方面，加锁机制会产生额外的开销，增加产生死锁的机会。 乐观锁：乐观锁的机制就是CAS，版本保护就是CAS中的期望值 CAS顾名思义，就是很乐观，每次去拿（取）数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，并发量不是很高的时候可以用，并发量高时，比如抢票，数据就存在Redis这类内存中了，就不存mysql了，mysql太慢了。 乐观锁优缺点：乐观锁认为事务直接竞争的概率是很小的，在提交的时候才锁定，所以不会产生死锁。但是如果两个事务同时写入数据库的某一行，这时，就会发现乐观锁的弊端。 行级锁：行级锁分为共享锁和排它锁。行级锁是Mysql中锁定粒度最细的锁。InnoDB引擎支持行级锁和表级锁，只有在通过索引条件检索数据的时候，才使用行级锁，否就使用表级锁。行级锁开销大，加锁慢，锁定粒度最小，发生锁冲突概率最低，并发度最高 表级锁：表级锁分为表共享锁和表独占锁。表级锁开销小，加锁快，锁定粒度大、发生锁冲突最高，并发度最低 页级锁：页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁。开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 排它锁(exclusive locck)：排它锁又叫写锁，如果事务T对A加上排它锁，则其它事务都不能对A加任何类型的锁。获准排它锁的事务既能读数据，又能写数据。 共享锁(share lock)：共享锁又叫读锁，如果事务T对A加上共享锁，则其它事务只能对A再加共享锁，不能加其它锁。获准共享锁的事务只能读数据，不能写数据。 InnoDB：支持行级锁和表级锁，默认是行级锁 MyISAM &amp;Memory：这两个存储引擎都是采用表级锁 锁优化： 读写分离 分段加锁 减少锁持有的时间 多个线程尽量以相同的顺序去获取资源 Innodb多版本并发控制（MVCC）可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制所有不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。 InnoDB的MVCC，是通过在每行纪录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存了行的过期时间，（存储的并不是实际的时间值，而是系统版本号）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行纪录的版本号进行比较。 MYSQL索引类型MySQL目前主要有以下几种索引类型：普通索引、唯一索引、主键索引、组合索引、全文索引。 普通索引：仅加速查询 唯一索引：加速查询 + 列值唯一（可以有null） 主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 全文索引：对文本的内容进行分词，进行搜索 普通索引-是最基本的索引，它没有任何限制。它有以下几种创建方式： 123456789101112131415直接创建索引CREATE INDEX index_name ON table(column(length))修改表结构的方式添加索引ALTER TABLE table_name ADD INDEX index_name ON (column(length))创建表的时候同时创建索引CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`), INDEX index_name (title(length)))删除索引 DROP INDEX index_name ON table 唯一索引-与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式： 123456789101112创建唯一索引 CREATE UNIQUE INDEX indexName ON table(column(length))修改表结构 ALTER TABLE table_name ADD UNIQUE indexName ON (column(length))创建表的时候直接指定CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , UNIQUE indexName (title(length))); 主键索引-是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引： 12345CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) NOT NULL , PRIMARY KEY (`id`)); 组合索引-指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合。 1ALTER TABLE `table` ADD INDEX name_city_age (name,city,age); 全文索引-主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。 12345678910111213创建表的适合添加全文索引CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`), FULLTEXT (content));修改表结构添加全文索引ALTER TABLE article ADD FULLTEXT index_content(content)直接创建索引CREATE FULLTEXT INDEX index_content ON article(content) 索引的作用和优缺点索引就一种特殊的查询表，数据库的搜索引擎可以利用它加速对数据的检索。它很类似与现实生活中书的目录，不需要查询整本书内容就可以找到想要的数据。索引可以是唯一的，创建索引允许指定单个列或者是多个列。缺点是它减慢了数据录入（插入、删除、更新表）的速度，同时也增加了数据库的尺寸大小。 优点： 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以大大加快数据的检索速度。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺点： 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 索引需要占物理空间，除了数据表占物理空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存索引文件。 如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。 不建议使用索引情况： 数据唯一性差的字段不要使用索引：比如性别，只有两种可能数据。意味着索引的二叉树级别少，多是平级。这样的二叉树查找无异于全表扫描。 频繁更新的字段不要使用索引：比如logincount登录次数，频繁变化导致索引也频繁变化，增大数据库工作量，降低效率。 字段不在where语句出现时不要添加索引：只有在where语句出现，mysql才会去使用索引 数据量少的表不要使用索引：使用了改善也不大 另外，如果mysql估计使用全表扫描要比使用索引快，则不会使用索引。 索引、主键索引、唯一索引、组合索引索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。 普通索引(由关键字KEY或INDEX定义的索引)的唯一任务是加快对数据的访问速度。 普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。 主键，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，不允许有空值，使用关键字 PRIMARY KEY 来创建。 索引可以覆盖多个数据列，如像INDEX(columnA, columnB)索引，这就是组合索引。 索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度，因为在执行这些写操作时，还要操作索引文件。 主键、外键、唯一索引定义： 主键–唯一标识一条记录，不能有重复的，不允许为空 外键–表的外键是另一表的主键, 外键可以有重复的, 可以是空值 唯一索引–该字段没有重复值，但可以有一个空值 作用： 主键–用来保证数据完整性 外键–用来和其他表建立联系用的 唯一索引–是提高查询排序的速度 个数： 主键–主键只能有一个 外键–一个表可以有多个外键 唯一索引–一个表可以有多个唯一索引 MySQL索引原理MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，因此MySQL数据库支持多种索引类型，如BTree索引，B+Tree索引，哈希索引，全文索引等等 哈希索引只有memory（内存）存储引擎支持哈希索引，哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能。 全文索引FULLTEXT（全文）索引，仅可用于MyISAM和InnoDB，针对较大的数据，生成全文索引非常的消耗时间和空间。对于文本的大对象，或者较大的CHAR类型的数据，如果使用普通索引，那么匹配文本前几个字符还是可行的，但是想要匹配文本中间的几个单词，那么就要使用LIKE %word%来匹配，这样需要很长的时间来处理，响应时间会大大增加，这种情况，就可使用时FULLTEXT索引了，在生成FULLTEXT索引时，会为文本生成一份单词的清单，在索引时及根据这个单词的清单来索引。FULLTEXT可以在创建表的时候创建，也可以在需要的时候用ALTER或者CREATE INDEX来添加： 123456789//创建表的时候添加FULLTEXT索引CTREATE TABLE my_table(id INT(10) PRIMARY KEY,name VARCHAR(10) NOT NULL,my_text text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,FULLTEXT(my_text));//创建表以后，在需要的时候添加FULLTEXT索引ALTER my_table ADD FULLTEXT ft_index(my_text);CREATE INDEX ft_index ON my_table(my_text); 对于较大的数据集，把数据添加到一个没有FULLTEXT索引的表，然后添加FULLTEXT索引的速度比把数据添加到一个已经有FULLTEXT索引的表快。 MySQL自带的全文索引只能用于MyISAM存储引擎，如果是其它数据引擎，那么全文索引不会生效。 在MySQL中，全文索引支队英文有用，目前对中文还不支持。 在MySQL中，如果检索的字符串太短则无法检索得到预期的结果，检索的字符串长度至少为4字节，此外，如果检索的字符包括停止词，那么停止词会被忽略。 BTree索引和B+Tree索引BTree索引BTree是平衡搜索多叉树，设树的度为d（d&gt;1），高度为h，那么BTree要满足以一下条件： 每个叶子结点的高度一样，等于h； 每个非叶子结点由n-1个key和n个指针point组成，其中d&lt;=n&lt;=2d,key和point相互间隔，结点两端一定是key； 叶子结点指针都为null； 非叶子结点的key都是[key,data]二元组，其中key表示作为索引的键，data为键值所在行的数据； 在BTree的机构下，就可以使用二分查找的查找方式，查找复杂度为h*log(n)，一般来说树的高度是很小的，一般为3左右，因此BTree是一个非常高效的查找结构。 B+Tree索引B+Tree是BTree的一个变种，设d为树的度数，h为树的高度，B+Tree和BTree的不同主要在于： B+Tree中的非叶子结点不存储数据，只存储键值； B+Tree的叶子结点没有指针，所有键值都会出现在叶子结点上，且key存储的键值对应的数据的物理地址； 一般来说B+Tree比BTree更适合实现外存的索引结构，因为存储引擎的设计专家巧妙的利用了外存（磁盘）的存储结构，即磁盘的一个扇区是整数倍的page（页），页是存储中的一个单位，通常默认为4K，因此索引结构的节点被设计为一个页的大小，然后利用外存的“预读取”原则，每次读取的时候，把整个节点的数据读取到内存中，然后在内存中查找，已知内存的读取速度是外存读取I/O速度的几百倍，那么提升查找速度的关键就在于尽可能少的磁盘I/O，那么可以知道，每个节点中的key个数越多，那么树的高度越小，需要I/O的次数越少，因此一般来说B+Tree比BTree更快，因为B+Tree的非叶节点中不存储data域，就可以存储更多的key。带顺序索引的B+TREE。很多存储引擎在B+Tree的基础上进行了优化，添加了指向相邻叶节点的指针，形成了带有顺序访问指针的B+Tree，这样做是为了提高区间查找的效率，只要找到第一个值那么就可以顺序的查找后面的值。 SQL常见语句数据库 12345678# 查看所有的数据库SHOW DATABASES ;# 创建一个数据库CREATE DATABASE name;# 删除一个数据库DROP DATABASE name;# 使用这个数据库USE name; 表 12345678910111213141516171819202122232425262728# 查看所有的表SHOW TABLES ;# 创建一个表CREATE TABLE n(id INT, name VARCHAR(10));CREATE TABLE m(id INT, name VARCHAR(10), PRIMARY KEY (id), FOREIGN KEY (id) REFERENCES n(id), UNIQUE (name));CREATE TABLE m(id INT, name VARCHAR(10));# 直接将查询结果导入或复制到新创建的表CREATE TABLE n SELECT * FROM m;# 新创建的表与一个存在的表的数据结构类似CREATE TABLE m LIKE n;# 创建一个临时表# 临时表将在你连接MySQL期间存在。当断开连接时，MySQL将自动删除表并释放所用的空间。也可手动删除。CREATE TEMPORARY TABLE l(id INT, name VARCHAR(10));# 直接将查询结果导入或复制到新创建的临时表CREATE TEMPORARY TABLE tt SELECT * FROM n;# 删除一个存在表DROP TABLE IF EXISTS m;# 更改存在表的名称ALTER TABLE n RENAME m;RENAME TABLE n TO m;# 查看表的结构(以下五条语句效果相同）DESC n; # 因为简单，所以建议使用（DESC表示descend降序，ASC表示ascend升序）DESCRIBE n; #（discribe）SHOW COLUMNS IN n;SHOW COLUMNS FROM n;EXPLAIN n;# 查看表的创建语句SHOW CREATE TABLE n; 表的结构 12345678# 添加字段ALTER TABLE n ADD age VARCHAR(2) ;# 删除字段ALTER TABLE n DROP age;# 更改字段属性和属性ALTER TABLE n CHANGE age a INT;# 只更改字段属性ALTER TABLE n MODIFY age VARCHAR(7) ; 表的数据 1234567891011# 增加数据INSERT INTO n VALUES (1, &apos;tom&apos;, &apos;23&apos;), (2, &apos;john&apos;, &apos;22&apos;);INSERT INTO n SELECT * FROM n; # 把数据复制一遍重新插入# 删除数据DELETE FROM n WHERE id = 2;# 更改数据UPDATE n SET name = &apos;tom&apos; WHERE id = 2;# 数据查找SELECT * FROM n WHERE name LIKE &apos;%h%&apos;;# 数据排序(反序)SELECT * FROM n ORDER BY name, id DESC ; 键 12345678910111213141516171819202122232425# 添加主键ALTER TABLE n ADD PRIMARY KEY (id);ALTER TABLE n ADD CONSTRAINT pk_n PRIMARY KEY (id); # 主键只有一个，所以定义键名似乎也没有什么用# 删除主键ALTER TABLE n DROP PRIMARY KEY ;# 添加外键ALTER TABLE m ADD FOREIGN KEY (id) REFERENCES n(id); # 自动生成键名m_ibfk_1ALTER TABLE m ADD CONSTRAINT fk_id FOREIGN KEY (id) REFERENCES n(id); # 使用定义的键名fk_id# 删除外键ALTER TABLE m DROP FOREIGN KEY `fk_id`;# 修改外键ALTER TABLE m DROP FOREIGN KEY `fk_id`, ADD CONSTRAINT fk_id2 FOREIGN KEY (id) REFERENCES n(id); # 删除之后从新建# 添加唯一键ALTER TABLE n ADD UNIQUE (name);ALTER TABLE n ADD UNIQUE u_name (name);ALTER TABLE n ADD UNIQUE INDEX u_name (name);ALTER TABLE n ADD CONSTRAINT u_name UNIQUE (name);CREATE UNIQUE INDEX u_name ON n(name);# 添加索引ALTER TABLE n ADD INDEX (age);ALTER TABLE n ADD INDEX i_age (age);CREATE INDEX i_age ON n(age);# 删除索引或唯一键DROP INDEX u_name ON n;DROP INDEX i_age ON n; 视图 12345678910111213# 创建视图CREATE VIEW v AS SELECT id, name FROM n;CREATE VIEW v(id, name) AS SELECT id, name FROM n;# 查看视图(与表操作类似)SELECT * FROM v;DESC v;# 查看创建视图语句SHOW CREATE VIEW v;# 更改视图CREATE OR REPLACE VIEW v AS SELECT name, age FROM n;ALTER VIEW v AS SELECT name FROM n ;# 删除视图DROP VIEW IF EXISTS v; 链接 12345678910111213# 内联接SELECT * FROM m INNER JOIN n ON m.id = n.id;# 左外联接SELECT * FROM m LEFT JOIN n ON m.id = n.id;# 右外联接SELECT * FROM m RIGHT JOIN n ON m.id = n.id;# 交叉联接SELECT * FROM m CROSS JOIN n; # 标准写法SELECT * FROM m, n;# 类似全连接full join的联接用法SELECT id,name FROM mUNIONSELECT id,name FROM n; 函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# 聚合函数SELECT count(id) AS total FROM n; # 总数SELECT sum(age) AS all_age FROM n; # 总和SELECT avg(age) AS all_age FROM n; # 平均值SELECT max(age) AS all_age FROM n; # 最大值SELECT min(age) AS all_age FROM n; # 最小值# 数学函数SELECT abs(-5); # 绝对值SELECT bin(15), oct(15), hex(15); # 二进制，八进制，十六进制SELECT pi(); # 圆周率3.141593SELECT ceil(5.5); # 大于x的最小整数值6SELECT floor(5.5); # 小于x的最大整数值5SELECT greatest(3,1,4,1,5,9,2,6); # 返回集合中最大的值9SELECT least(3,1,4,1,5,9,2,6); # 返回集合中最小的值1SELECT mod(5,3); # 余数2SELECT rand(); # 返回０到１内的随机值，每次不一样SELECT rand(5); # 提供一个参数(种子)使RAND()随机数生成器生成一个指定的值。SELECT round(1415.1415); # 四舍五入1415SELECT round(1415.1415, 3); # 四舍五入三位数1415.142SELECT round(1415.1415, -1); # 四舍五入整数位数1420SELECT truncate(1415.1415, 3); # 截短为3位小数1415.141SELECT truncate(1415.1415, -1); # 截短为-1位小数1410SELECT sign(-5); # 符号的值负数-1SELECT sign(5); # 符号的值正数1SELECT sqrt(9); # 平方根3SELECT sqrt(9); # 平方根3# 字符串函数SELECT concat(&apos;a&apos;, &apos;p&apos;, &apos;p&apos;, &apos;le&apos;); # 连接字符串-appleSELECT concat_ws(&apos;,&apos;, &apos;a&apos;, &apos;p&apos;, &apos;p&apos;, &apos;le&apos;); # 连接用&apos;,&apos;分割字符串-a,p,p,leSELECT insert(&apos;chinese&apos;, 3, 2, &apos;IN&apos;); # 将字符串&apos;chinese&apos;从3位置开始的2个字符替换为&apos;IN&apos;-chINeseSELECT left(&apos;chinese&apos;, 4); # 返回字符串&apos;chinese&apos;左边的4个字符-chinSELECT right(&apos;chinese&apos;, 3); # 返回字符串&apos;chinese&apos;右边的3个字符-eseSELECT substring(&apos;chinese&apos;, 3); # 返回字符串&apos;chinese&apos;第三个字符之后的子字符串-ineseSELECT substring(&apos;chinese&apos;, -3); # 返回字符串&apos;chinese&apos;倒数第三个字符之后的子字符串-eseSELECT substring(&apos;chinese&apos;, 3, 2); # 返回字符串&apos;chinese&apos;第三个字符之后的两个字符-inSELECT trim(&apos; chinese &apos;); # 切割字符串&apos; chinese &apos;两边的空字符-&apos;chinese&apos;SELECT ltrim(&apos; chinese &apos;); # 切割字符串&apos; chinese &apos;两边的空字符-&apos;chinese &apos;SELECT rtrim(&apos; chinese &apos;); # 切割字符串&apos; chinese &apos;两边的空字符-&apos; chinese&apos;SELECT repeat(&apos;boy&apos;, 3); # 重复字符&apos;boy&apos;三次-&apos;boyboyboy&apos;SELECT reverse(&apos;chinese&apos;); # 反向排序-&apos;esenihc&apos;SELECT length(&apos;chinese&apos;); # 返回字符串的长度-7SELECT upper(&apos;chINese&apos;), lower(&apos;chINese&apos;); # 大写小写 CHINESE chineseSELECT ucase(&apos;chINese&apos;), lcase(&apos;chINese&apos;); # 大写小写 CHINESE chineseSELECT position(&apos;i&apos; IN &apos;chinese&apos;); # 返回&apos;i&apos;在&apos;chinese&apos;的第一个位置-3SELECT position(&apos;e&apos; IN &apos;chinese&apos;); # 返回&apos;i&apos;在&apos;chinese&apos;的第一个位置-5SELECT strcmp(&apos;abc&apos;, &apos;abd&apos;); # 比较字符串，第一个参数小于第二个返回负数- -1SELECT strcmp(&apos;abc&apos;, &apos;abb&apos;); # 比较字符串，第一个参数大于第二个返回正数- 1# 时间函数SELECT current_date, current_time, now(); # 2018-01-13 12:33:43 2018-01-13 12:33:43SELECT hour(current_time), minute(current_time), second(current_time); # 12 31 34SELECT year(current_date), month(current_date), week(current_date); # 2018 1 1SELECT quarter(current_date); # 1SELECT monthname(current_date), dayname(current_date); # January SaturdaySELECT dayofweek(current_date), dayofmonth(current_date), dayofyear(current_date); # 7 13 13# 控制流函数SELECT if(3&gt;2, &apos;t&apos;, &apos;f&apos;), if(3&lt;2, &apos;t&apos;, &apos;f&apos;); # t fSELECT ifnull(NULL, &apos;t&apos;), ifnull(2, &apos;t&apos;); # t 2SELECT isnull(1), isnull(1/0); # 0 1 是null返回1，不是null返回0SELECT nullif(&apos;a&apos;, &apos;a&apos;), nullif(&apos;a&apos;, &apos;b&apos;); # null a 参数相同或成立返回null，不同或不成立则返回第一个参数SELECT CASE 2 WHEN 1 THEN &apos;first&apos; WHEN 2 THEN &apos;second&apos; WHEN 3 THEN &apos;third&apos; ELSE &apos;other&apos; END ; # second# 系统信息函数SELECT database(); # 当前数据库名-testSELECT connection_id(); # 当前用户id-306SELECT user(); # 当前用户-root@localhostSELECT version(); # 当前mysql版本SELECT found_rows(); # 返回上次查询的检索行数 用户 1234567891011121314151617# 增加用户CREATE USER &apos;test&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;test&apos;;INSERT INTO mysql.user(Host, User, Password) VALUES (&apos;localhost&apos;, &apos;test&apos;, Password(&apos;test&apos;)); # 在用户表中插入用户信息，直接操作User表不推荐# 删除用户DROP USER &apos;test&apos;@&apos;localhost&apos;;DELETE FROM mysql.user WHERE User=&apos;test&apos; AND Host=&apos;localhost&apos;;FLUSH PRIVILEGES ;# 更改用户密码SET PASSWORD FOR &apos;test&apos;@&apos;localhost&apos; = PASSWORD(&apos;test&apos;);UPDATE mysql.user SET Password=Password(&apos;t&apos;) WHERE User=&apos;test&apos; AND Host=&apos;localhost&apos;;FLUSH PRIVILEGES ;# 用户授权GRANT ALL PRIVILEGES ON *.* TO test@localhost IDENTIFIED BY &apos;test&apos;;# 授予用&apos;test&apos;密码登陆成功的test@localhost用户操作所有数据库的所有表的所有的权限FLUSH PRIVILEGES ; # 刷新系统权限表,使授予权限生效# 撤销用户授权REVOKE DELETE ON *.* FROM &apos;test&apos;@&apos;localhost&apos;; # 取消该用户的删除权限 存储过程 1234567891011121314151617181920212223242526272829303132333435# 创建存储过程DELIMITER // # 无参数CREATE PROCEDURE getDates() BEGIN SELECT * FROM test ; END //CREATE PROCEDURE getDates_2(IN id INT) # in参数 BEGIN SELECT * FROM test WHERE a = id; END //CREATE PROCEDURE getDates_3(OUT sum INT) # out参数 BEGIN SET sum = (SELECT count(*) FROM test); END //CREATE PROCEDURE getDates_4(INOUT i INT) # inout参数 BEGIN SET i = i + 1; END //DELIMITER ;# 删除存储过程DROP PROCEDURE IF EXISTS getDates;# 修改存储过程的特性ALTER PROCEDURE getDates MODIFIES SQL DATA ;# 修改存储过程语句（删除再重建）略# 查看存储过程SHOW PROCEDURE STATUS LIKE &apos;getDates&apos;; # 状态SHOW CREATE PROCEDURE getDates_3; # 语句# 调用存储过程CALL getDates();CALL getDates_2(1);CALL getDates_3(@s);SELECT @s;SET @i = 1;CALL getDates_4(@i);SELECT @i; # @i = 2 SQL语句关键字SQL语言包括数据定义(DDL)、数据操纵(DML),数据控制(DCL)和数据查询（DQL）四个部分。 数据定义：Create Table,Alter Table,Drop Table, Craete/Drop Index 数据操纵：select ,insert,update,delete 数据控制：revoke 数据查询：select DROP、TRUNCATE、DELETE DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。 TRUNCATE TABLE一次性地从表中删除所有的数据，不能通过ROLLBACK回滚。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。 DROP是DDL，会隐式提交，所以不能回滚，不会触发触发器。 表和索引所占空间。当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小，DELETE操作不会减少表或索引所占用的空间。DROP语句将表所占用的空间全释放掉。 应用范围：TRUNCATE只能对TABLE使用；DELETE可以是TABLE和VIEW；DROP可以删除表和数据库。 TRUNCATE和DELETE只删除数据，DROP则删除整个表（结构和数据）。TRUNCATE与不带WHERE的DELETE：只删除数据，而不删除表的结构（定义）；DROP语句将删除表的结构，被依赖的约束（constrain)，触发器（trigger)，索引（index）也会被删除；而依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。 对于外键（FOREIGN KEY）约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带where 子句的 DELETE 语句。TRUNCATE TABLE不能用于参与了索引视图的表。 MySQL连接方式内链接：（相交部分)关键字：inner join on 语句：select * from a_table a inner join b_table b on a.a_id = b.b_id; 左链接：（左边部分）关键字：left join on / left outer join on 语句：select * from a_table a left join b_table b on a.a_id = b.b_id; 右链接：（右边部分）关键字：right join on/right outer join on 语句：select * from a_table a right outer join b_table b on a.a_id = b.b_id; 全链接：目前MySQL不支持MySQL查询过程 客户端先发送一条查询给服务器； 服务器先检查查询缓存，如果命中了缓存，则立刻返回给存储在缓存中的结果，否则进入下一个阶段； 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划； MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询； 将结果返回客户端。 数据库高并发解决方法总结一个项目刚开始的时候是为了实现基本功能，随着版本和功能的迭代，大数据和高并发成了软件设计必须考虑的问题！本质很简单，一个是慢，一个是等。两者是相互关联的，因为慢，所以要等，因为等，所以慢，解决了慢，也就解决了等，解决了等，也就解决了慢。关键是如何解决慢和等，核心一个是短，一个是少，一个是分流，最后一种是集群/横向扩张/读写分离/建立主从。 短是指路径要短：典型的mvc结构是请求-&gt;controller-&gt;model-&gt;dao-&gt;view，然后把页面返回给用户。要想短的话， 页面静态化-用户可以直接获取页面，不用走那么多流程，比较适用于页面不频繁更新。 使用缓存-第一次获取数据从数据库准提取，然后保存在缓存中，以后就可以直接从缓存提取数据。不过需要有机制维持缓存和数据库的一致性。 使用储存过程-那些处理一次请求需要多次访问数据库的操作，可以把操作整合到储存过程，这样只要一次数据库访问就可以了。 批量读取-高并发情况下，可以把多个请求的查询合并到一次进行，以减少数据库的访问次数 延迟修改-高并发情况下，可以把多次修改请求，先保存在缓存中，然后定时将缓存中的数据保存到数据库中，风险是可能会断电丢失缓存中的数据， 使用索引-索引可以看作是特殊的缓存，尽量使用索引就要求where字句中精确的给出索引列的值。 少是指查询的数据要少 分表-把本来同一张表的内容，可以按照地区，类别等分成多张表，很简单的一个思路，但是要尽量避免分出来的多表关联查询。 分离活跃数据-例如登录用户业务，注册用户很多，但是活跃的登录用户很少，可以把活跃用户专门保存一张表，查询是先查询活跃表，没有的话再查总表，这也类似与缓存啦。 分块-数据库层面的优化，对程序是透明的，查询大数据只用找到相应块就行。 分流三种: 集群-将并发请求分配到不同的服务器上，可以是业务服务器，也可以是数据库服务器。 分布式-分布式是把单次请求的多项业务逻辑分配到多个服务器上，这样可以同步处理很多逻辑，一般使用与特别复杂的业务请求。 CDN -在域名解析层面的分流，例如将华南地区的用户请求分配到华南的服务器，华中地区的用户请求分配到华中的服务器。 高并发数据库系统 数据库的优化，包括合理的事务隔离级别、SQL语句优化、索引的优化 使用缓存，尽量减少据库 IO 分布式数据库、分布式缓存 服务器的负载均衡 SQL优化选择正确的存储引擎以 MySQL为例，包括有两个存储引擎 MyISAM 和 InnoDB，每个引擎都有利有弊。 MyISAM 适合于一些需要大量查询的应用，但其对于有大量写操作并不是很好。甚至你只是需要update一个字段，整个表都会被锁起来，而别的进程，就算是读进程都无法操作直到读操作完成。另外，MyISAM 对于 SELECT COUNT(*) 这类的计算是超快无比的。 InnoDB 的趋势会是一个非常复杂的存储引擎，对于一些小的应用，它会比 MyISAM 还慢。但是它支持“行锁” ，于是在写操作比较多的时候，会更优秀。并且，他还支持更多的高级应用，比如：事务。 优化字段的数据类型记住一个原则，越小的列会越快。如果一个表只会有几列罢了（比如说字典表，配置表），那么，我们就没有理由使用 INT 来做主键，使用 MEDIUMINT, SMALLINT 或是更小的 TINYINT 会更经济一些。如果你不需要记录时间，使用 DATE 要比 DATETIME 好得多。当然，你也需要留够足够的扩展空间。 为常用的搜索字段添加索引索引并不一定就是给主键或是唯一的字段。如果在你的表中，有某个字段你总要会经常用来做搜索，那么最好是为其建立索引，除非你要搜索的字段是大的文本字段，那应该建立全文索引。 避免使用Select *从数据库里读出越多的数据，那么查询就会变得越慢。并且，如果你的数据库服务器和WEB服务器是两台独立的服务器的话，这还会增加网络传输的负载。即使你要查询数据表的所有字段，也尽量不要用*通配符，善用内置提供的字段排除定义也许能给带来更多的便利。 使用 ENUM 而不是 VARCHARENUM 类型是非常快和紧凑的。在实际上，其保存的是 TINYINT，但其外表上显示为字符串。这样一来，用这个字段来做一些选项列表变得相当的完美。例如，性别、民族、部门和状态之类的这些字段的取值是有限而且固定的，那么，你应该使用 ENUM 而不是 VARCHAR。 尽可能的使用 NOT NULL除非你有一个很特别的原因去使用 NULL 值，你应该总是让你的字段保持 NOT NULL。 NULL其实需要额外的空间，并且，在你进行比较的时候，你的程序会更复杂。 当然，这里并不是说你就不能使用NULL了，现实情况是很复杂的，依然会有些情况下，你需要使用NULL值。+ 固定长度的表会更快如果表中的所有字段都是“固定长度”的，整个表会被认为是 “static” 或 “fixed-length”。 例如，表中没有如下类型的字段： VARCHAR，TEXT，BLOB。只要你包括了其中一个这些字段，那么这个表就不是“固定长度静态表”了，这样，MySQL 引擎会用另一种方法来处理。 固定长度的表会提高性能，因为MySQL搜寻得会更快一些，因为这些固定的长度是很容易计算下一个数据的偏移量的，所以读取的自然也会很快。而如果字段不是定长的，那么，每一次要找下一条的话，需要程序找到主键。 并且，固定长度的表也更容易被缓存和重建。不过，唯一的副作用是，固定长度的字段会浪费一些空间，因为定长的字段无论你用不用，他都是要分配那么多的空间。 SQL语句优化方法 where子句中：where表之间的连接必须写在其他Where条件之前，那些可以过滤掉最大数量记录的条件必须写在where子句的末尾.HAVING最后。 用EXISTS替代IN、用NOT EXISTS替代NOT IN。 避免在索引列上使用计算 避免在索引列上使用IS NULL和IS NOT NULL 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描 实践中优化MySQL从效果上第一条影响最大，后面越来越小。 SQL语句及索引的优化 数据库表结构的优化 系统配置的优化 硬件的优化 优化数据库方法 选取最适用的字段属性，尽可能减少定义字段宽度，尽量把字段设置NOTNULL，例如’省份’、’性别’最好适用ENUM 使用连接(JOIN)来代替子查询 适用联合(UNION)来代替手动创建的临时表 事务处理 锁定表、优化事务处理 适用外键，优化锁定表 建立索引 优化查询语句 NULL含义NULL这个值表示UNKNOWN(未知)，它不表示“”(空字符串)。对NULL这个值的任何比较都会生产一个NULL值。您不能把任何值与一个 NULL值进行比较，并在逻辑上希望获得一个答案。 使用IS NULL来进行NULL判断 char和varcharchar是一种固定长度的类型，varchar则是一种可变长度的类型，它们的区别是： char(M)类型的数据列里，每个值都占用M个字节，如果某个长度小于M，MySQL就会在它的右边用空格字符补足。（在检索操作中那些填补出来的空格字符将被去掉）在varchar(M)类型的数据列里，每个值只占用刚好够用的字节再加上一个用来记录其长度的字节（即总长度为L+1字节）． varchar的适用场景: 字符串列得最大长度比平均长度大很多。 字符串很少被更新，容易产生存储碎片 使用多字节字符集存储字符串 char的适用场景: 存储具有近似得长度（md5值,身份证，手机号）,长度比较短小得字符串（因为varchar需要额外空间记录字符串长度），更适合经常更新得字符串，更新时不会出现页分裂得情况，避免出现存储碎片，获得更好的io性能。 SQL约束not null：非空约束，强制列不接受空值。例：创建表时，name varchar(6) not null unique：唯一性约束约束唯一标识数据库表中的每条记录 unique和primary key都为数据提供了唯一性约束 primary key 拥有自动定义的unique约束 注意：每个表中只能有一个primary key约束，但是可以有多个Unique约束 语法： 123451.name int unique2.unique(column_name)3.CONSTRAINT uc_PersonID UNIQUE (Id_P, LastName)：添加多个约束 4.alter table table_name add unique(column_name)：增加表中的约束 5.ALTER TABLE table_name DROP CONSTRAINT 主键名：删除约束 Primary Key约束约束唯一标识数据库表中的每条记录 主键必须包含唯一的值，主键列不能为空 每个表都应该有个主键，但只能有一个主键 语法： 123456① StudentID int not null primary key 创建学生编号为主键② primary key(StudentID) 创建学生编号为主键③ primary key(StudentID, Email) 创建学生ID和Email为联合主键④ alter table table_name add primary key(column_name) 为已存在的列创建主键⑤ alter table table_name drop primary key 删除主键约束⑥ alter table table_name drop constraint 主键约束名 删除主键约束 foreign key约束一个表中的foreign key指向另一个表的primary key foreign key约束用于预防破坏表之间连接的动作 foreign key约束也能防止非法数据插入外键列，因为它必须是指向的表中的主键值 语法： 1234foreign key (column_name) references 主表名（主键列名）创建column_name为主表名的外键 column_name int foreign key references 主表名（主键列名）创建column_name为主表名的外键 alter table table_name add foreign key (列名) references 主表名（主键列名）为已存在的列创建外键 alter table table_name drop foreign key 外键约束名 删除外键约束 check 约束check约束用于限制列中的值的范围 如果对个单个列做check约束，那么该列只可以输入特定数值 如果一个表定义check约束，那么此约束会在特定的列对值进行限制 语法： 123StudentID int not null check (StudentID&gt;0) 限制StudentID输入的值要大于0sex varchar(2) not null check(sex=&apos;男&apos; or sex=&apos;女&apos;) 限制sex的性别只能是男或者女 alter table table_name add check(列名&gt;0) 向已有的列加入check约束 default约束：用于向列中插入默认值，若没有规定其他值，那么会将默认值添加到所有的新记录中 语法：name varchar(10) default ‘张三’ name默认插入张三的名字 完整性约束数据完整性(Data Integrity)是指数据的精确(Accuracy)和可靠性(Reliability)。 分为以下四类： 实体完整性：规定表的每一行在表中是惟一的实体。 域完整性：是指表中的列必须满足某种特定的数据类型约束，其中约束又包括取值范围、精度等规定。 参照完整性：是指两个表的主关键字和外关键字的数据应一致，保证了表之间的数据的一致性，防止了数据丢失或无意义的数据在数据库中扩散。 用户定义的完整性：不同的关系数据库系统根据其应用环境的不同，往往还需要一些特殊的约束条件。用户定义的完整性即是针对某个特定关系数据库的约束条件，它反映某一具体应用必须满足的语义要求。 与表有关的约束：包括列约束(NOT NULL（非空约束）)和表约束(PRIMARY KEY、foreign key、check、UNIQUE) 。 基本表和视图基本表是本身独立存在的表，在 SQL 中一个关系就对应一个表。 视图是从一个或几个基本表导出的表。视图本身不独立存储在数据库中，是一个虚表。 视图的优点 视图能够简化用户的操作 视图使用户能以多种角度看待同一数据； 视图为数据库提供了一定程度的逻辑独立性； 视图能够对机密数据提供安全保护。 MySQL运维优化 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。 选择合适的表字段数据类型和存储引擎，适当的添加索引。 mysql库主从读写分离。 找规律分表，减少单表中的数据量提高查询速度。 添加缓存机制，比如memcached，apc等。 不经常改动的页面，生成静态页面。 书写高效率的SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE. 大流量网站，解决各页面访问量统计问题 确认服务器是否能支撑当前访问量。 优化数据库访问。 禁止外部访问链接（盗链）, 比如图片盗链。 控制文件下载。 使用不同主机分流。 使用浏览统计软件，了解访问量，有针对性的进行优化 数据库连接池不用连接池的话，就要根据每个请求或者每个用户来建立连接。这样的缺点是显而易见的。 这样需要建立很多连接，建立连接是要花很多时间的。 有的用户建立了连接，却没有使用，造成了资源浪费。 因此需要用连接池，如下先建好5个连接（Tomcat默认的连接是10到100个，可修改），每次请求来了直接用，用完了还回去，如果请求太多，来不及处理，超时会报错（线程池请求太多会排队，不会超时报错） JDBC和ODBCJDBC使用起来更方便，ODBC因为是C编写，性能更快一些。 JDBC：（Java Data Base Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，它是Java十三个规范之一。可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。 JDBC的最大特点是它独立于详细的关系数据库。 ODBC：是微软公司开放服务结构(WOSA，Windows Open Services Architecture)中有关数据库的一个组成部分。一个基于ODBC的应用程序对数据库的操作不依赖数据库类型，能以统一的方式处理全部的数据库。 MySQL主从同步原理 一句话解释：Slaver读取Master的binlog并顺序执行 概述： MySQL的主从复制是一个异步的复制过程（虽然一般情况下感觉是实时的），在Master与Slave之间实现整个主从复制的过程是由三个线程参与完成的。其中有两个线程（SQL线程和IO线程）在Slave端，另一个线程（I/O线程）在Master端。 要实现MySQL的主从复制，首先必须打开Master端的binlog记录功能，否则就无法实现。因为整个复制过程实际上就是Slave从Master端获取binlog日志，然后再在Slave上以相同顺序执行获取的binlog日志中的记录的各种SQL操作 详细过程 在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制。 此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容 Master服务器接收到来自Slave服务器的IO线程的请求后，其上负责复制的IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在Master服务器端记录的IO线程。返回的信息中除了binlog中的下一个指定更新位置。 当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（Mysql-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容 Slave服务器端的SQL线程会实时检测本地Relay Log 中新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点 知识点 3个线程，主库IO，从库IO和SQL及作用 master.info（从库）作用 relay-log 作用 异步复制 binlog作用（如果需要级联需要开启Binlog） 小结 主从复制是异步的逻辑的SQL语句级的复制 复制时，主库有一个I/O线程，从库有两个线程，I/O和SQL线程 实现主从复制的必要条件是主库要开启记录binlog功能 作为复制的所有Mysql节点的server-id都不能相同 binlog文件只记录对数据库有更改的SQL语句（来自主库内容的变更），不记录任何查询（select，show）语句 工作中常用主从模式 数据库事务断电本地事务数据库断电的这种情况，它是怎么保证数据一致性的呢？ 我们使用SQL Server来举例，我们知道我们在使用 SQL Server 数据库是由两个文件组成的，一个数据库文件和一个日志文件，通常情况下，日志文件都要比数据库文件大很多。数据库进行任何写入操作的时候都是要先写日志的，同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时候，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。 两段锁协议数据库的两段锁协议是指所有事务必须分两个阶段对数据项进行加锁和解锁1.扩展阶段在对任何数据项的读、写之前，要申请并获得该数据项的封锁。 2.收缩阶段每个事务中，所有的封锁请求必须先于解锁请求。例如：事务T遵循两段锁协议，其封锁协议为：BEGIN TRANSACTION;LOCK（A）；READ A; A := A + 100; WRITE A; LOCK(B); UNLOCK(A); READ(B), UNLOCK(B),;COMMIT; 可以证明：若并发执行的所有事务均遵守两段锁协议，则对这些并行事务的任何并行调度策略都是可串行化 需要说明的是，并发执行的所有事务若均遵守两段锁协议，只是这些事务的并行调度策略能可串行化的充分条件，不是必要条件。 两段锁协议与防止死锁的一次封锁法的区别：一次封锁法要求事务必须一次对所有要使用到的数据项进行加锁，否则不能继续运行。 显然，一次封锁法符合两段锁协议，但是两段锁协议并不要求一次就要对所有需要用到的数据项进行加锁，因此遵守两段锁协议的事务有可能死锁 参考链接&lt;https://blog.csdn.net/aaronthon/article/details/81714528&gt; &lt;https://blog.csdn.net/c361604199/article/details/79479398&gt; &lt;https://blog.csdn.net/plg17/article/details/78758593&gt; &lt;https://www.cnblogs.com/luyucheng/p/6289714.html&gt; &lt;https://blog.csdn.net/tongdanping/article/details/79878302&gt; &lt;https://blog.csdn.net/yifansj/article/details/79233726&gt; &lt;https://www.cnblogs.com/zxz1987/p/6538462.html&gt; &lt;https://coding.imooc.com/lesson/132.html#mid=6561&gt; &lt;https://coding.imooc.com/lesson/132.html#mid=6562&gt; &lt;https://blog.csdn.net/qq_23923485/article/details/73456784&gt;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.ylovex.cn/tags/MySQL/"}]},{"title":"nowcoder-最小众倍数","date":"2019-06-11T04:52:39.000Z","path":"2019/06/11/nowcoder-最小众倍数/","text":"题目来源：https://www.nowcoder.com/practice/3e9d7d22b7dd4daab695b795d243315b?tpId=90&amp;tqId=30844&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：定5个正整数, 它们的最小的众倍数是指的能够被其中至少三个数整除的最小正整数。给定5个不同的正整数, 请计算输出它们的最小众倍数。 思路：先遍历n从1开始，再遍历nums[i]，使用map记录n*nums[i]出现的次数，当该数的次数出现三次的时候即为最小众倍数。 参考代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Now_68 &#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); int[] nums = new int[5]; for(int i=0;i&lt;5;i++)&#123; nums[i]=sc.nextInt(); &#125; Arrays.sort(nums); int res = getRes(nums); System.out.println(res); &#125; private static int getRes(int[] nums) &#123; Map&lt;Integer , Integer&gt; map = new HashMap&lt;&gt;(); for(int n=1;n&lt;Integer.MAX_VALUE; n++)&#123; for(int i=0;i&lt;5;i++)&#123; if(map.containsKey(n*nums[i]))&#123; map.put(n*nums[i] , map.get(n*nums[i])+1); if(map.get(n*nums[i])==3)&#123; return n*nums[i]; &#125; &#125; else &#123; map.put(n*nums[i] , 1); &#125; &#125; &#125; return -1; &#125; public static int getRes2(int[] nums)&#123; for(int n=1;n&lt;Integer.MAX_VALUE;n++)&#123; int count=0; for(int i=0;i&lt;5;i++)&#123; if(n%nums[i]==0)&#123; count++; &#125; if(count&gt;2)&#123; return n; &#125; &#125; &#125; return -1; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"},{"name":"遍历","slug":"遍历","permalink":"http://www.ylovex.cn/tags/遍历/"}]},{"title":"nowcoder-括号匹配问题","date":"2019-06-06T23:44:08.000Z","path":"2019/06/07/nowcoder-括号匹配问题/","text":"题目来源：https://www.nowcoder.com/practice/380380e6c6b444888ae145593ccbbbca?tpId=90&amp;tqId=30840&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：合法的括号匹配序列被定义为: 空串””是合法的括号序列 如果”X”和”Y”是合法的序列,那么”XY”也是一个合法的括号序列 如果”X”是一个合法的序列,那么”(X)”也是一个合法的括号序列 每个合法的括号序列都可以由上面的规则生成例如””, “()”, “()()()”, “(()())”, “(((())))”都是合法的。 东东现在有一个合法的括号序列s,一次移除 操作分为两步: 移除序列s中第一个左括号 移除序列s中任意一个右括号.保证操作之后s还是一个合法的括号序列东东现在想知道使用上述的移除操作有多少种方案可以把序列s变为空如果两个方案中有一次移除操作移除的是不同的右括号就认为是不同的方案。例如: s = “()()()()()”,输出1, 因为每次都只能选择被移除的左括号所相邻的右括号.s = “(((())))”,输出24, 第一次有4种情况, 第二次有3种情况, … ,依次类推, 4 * 3 * 2 * 1 = 24 思路：反向遍历，用count记录”)“数量，用res记录结果，每次遍历到”)“则count加一，遍历到”(“则结果乘以count，表示该”(“可以匹配的”)”选择为count数，之后count减一继续遍历，遍历完序列后的res即为方案数量。 参考代码：12345678910111213141516171819public class Now_64 &#123; public static void main(String[] args) throws IOException&#123; BufferedReader bf = new BufferedReader(new InputStreamReader(System.in)); String input = bf.readLine(); int len=input.length(); int res=1; int count=0; for(int i=len-1;i&gt;=0;i--)&#123; if(input.charAt(i)==')')&#123; count++; &#125; else &#123; res*=count; count--; &#125; &#125; System.out.println(res); &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"},{"name":"Stack","slug":"Stack","permalink":"http://www.ylovex.cn/tags/Stack/"}]},{"title":"nowcoder-神奇数","date":"2019-06-02T23:40:06.000Z","path":"2019/06/03/nowcoder-神奇数/","text":"题目来源：https://www.nowcoder.com/practice/56d818ae68134c12b26e81f41ecafb9e?tpId=90&amp;tqId=30841&amp;tPage=4&amp;rp=4&amp;ru=%2Fta%2F2018test&amp;qru=%2Fta%2F2018test%2Fquestion-ranking 题目描述：/** 东东在一本古籍上看到有一种神奇数,如果能够将一个数的数字分成两组, 其中一组数字的和等于另一组数字的和,我们就将这个数称为神奇数。 例如242就是一个神奇数,我们能够将这个数的数字分成两组, 分别是{2,2}以及{4},而且这两组数的和都是4.东东现在需要统计给定区间中有多少个神奇数, 即给定区间[l, r],统计这个区间中有多少个神奇数,请你来帮助他。*/ 思路：设数字X，先求出X的每位数字存在List中，再求出X每位数字和，若为奇数则舍弃，若为偶数则判断是否是神奇数，通过动态规划，dp[i] [j]表示链表前i个数字能否求和得到j，则有dp[i] [j]=dp[i-1] [j] || dp[i-1] [j-list.get(i)];通过逆序循环将dp数组简化为一维数组。 参考代码：123456789101112131415161718192021222324252627282930313233343536public class Now_65 &#123; public static void main(String[] args)throws IOException&#123; BufferedReader bf = new BufferedReader(new InputStreamReader(System.in)); String[] strings = bf.readLine().split(&quot; &quot;); int left = Integer.parseInt(strings[0]); int right = Integer.parseInt(strings[1]); int res = 0; for(int num = left ; num&lt;=right ; num++)&#123; if(isMagic(num))&#123; res++; &#125; &#125; System.out.println(res); &#125; private static boolean isMagic(int num) &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); int sum = 0; while (num&gt;0)&#123; list.add(num%10); sum+=num%10; num/=10; &#125; if(sum%2 != 0) return false; int mid = sum/2; int len = list.size(); boolean[] dp = new boolean[mid+1]; dp[0]=true; for(int i=0;i&lt;len;i++)&#123; for(int j=mid;j&gt;=list.get(i);j--)&#123; dp[j]=dp[j-list.get(i)] || dp[j]; &#125; &#125; return dp[mid]; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://www.ylovex.cn/tags/code/"},{"name":"动态规划","slug":"动态规划","permalink":"http://www.ylovex.cn/tags/动态规划/"}]},{"title":"web工作方式","date":"2019-05-28T13:30:45.000Z","path":"2019/05/28/web工作方式/","text":"Web工作方式：from:《Go Web 编程》 打开浏览器，输入网址后按下回车，然后显示出浏览内容，这个看似简单的用户行为背后，隐藏的流程一般是：浏览器本身是一个客户端，当你输入 URL 的 时候，首先浏览器会去请求 DNS 服务器，通过 DNS 获取相应的域名对应的 IP，然后通过IP 地址找到 IP 对应的服务器后，要求建立 TCP 连接，等浏览器发送完 HTTP Request（请求）包后，服务器接收到请求包之后才开始处理请求包，服务器调用自身服务，返回HTTP Response（响应）包；客户端收到来自服务器的响应后开始渲染这个 Response 包里的主体（body），等收到全部的内容随后断开与该服务器之间的 TCP 连接。 一个Web服务器也被称为HTTP服务器，它通过HTTP协议与客户端通信。这个客户端通常指的是web浏览器（手机端客户端内部也是浏览器实现的）。 Web 服务器的工作原理可以简单地归纳为： 客户机通过 TCP/IP 协议建立到服务器的 TCP 连接 客户端向服务器发送 HTTP 协议请求包，请求服务器里的资源文档 服务器向客户机发送 HTTP 协议应答包，如果请求的资源包含有动态语言的内容，那么服务器会调用动态语言的解释引擎负责处理“动态内容”，并将处理得到的数据返回给客户端 客户机与服务器断开。由客户端解释 HTML 文档，在客户端屏幕上渲染图形结果 一个简单的 HTTP 事务就是这样实现的，看起来很复杂，原理其实是挺简单的。需要注意的 是客户机与服务器之间的通信是非持久连接的，也就是当服务器发送了应答后就与客户机断开连接，等待下一次请求。 URL与DNS解析：URL(Uniform Resource Locator)是“统一资源定位符”的英文缩写，用于描述一个网络上的资源, 基本格式如下： 12345678schema://host[:port#]/path/.../[?query-string][#anchor]scheme 指定低层使用的协议(例如：http, https, ftp)host HTTP 服务器的 IP 地址或者域名port# HTTP 服务器的默认端口是 80，这种情况下端口号可以省略。如果使用了别的端口，必须指明，例如 http://www.cnblogs.com:8080/path 访问资源的路径query-string 发送给 http 服务器的数据anchor 锚 DNS(Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于 TCP/IP 网络，它从事将主机名或域名转换为实际 IP 地址的 工作。 更详细的 DNS 解析的过程如下，这个过程有助于我们理解 DNS 的工作模式 在浏览器中输入 www.qq.com 域名，操作系统会先检查自己本地的 hosts 文件是否有这个网址映射关系，如果有，就先调用这个 IP 地址映射，完成域名解析。 如果 hosts 里没有这个域名的映射，则查找本地 DNS 解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找 TCP/IP参数中设置的首选 DNS 服务器，在此我们叫它本地 DNS 服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 如果要查询的域名，不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。 如果本地 DNS 服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地 DNS 就把请求发至 “根 DNS服务器”，“根 DNS 服务器”收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个 IP。本地 DNS 服务器收到 IP 信息后，将会联系负责.com域的这台服务器。这台负责.com 域的服务器收到请求后，如果自己无法解析，它就会找一 个管理.com 域的下一级 DNS 服务器址(qq.com)给本地 DNS 服务器。当本地 DNS 服务器收到这个地址后，就会找 qq.com 域服务器，重复上面的动作，进行查询，直至找到www.qq.com 主机。 如果用的是转发模式，此 DNS 服务器就会把请求转发至上一级 DNS 服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根 DNS 或把转请求转至上上级，以此循环。不管是本地 DNS 服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS 服务器，由此 DNS 服务器再返回给客户机。 通过上面的步骤，我们最后获取的是 IP 地址，也就是浏览器最后发起请求的时候是基于 IP来和服务器做信息交互的。 HTTP协议：HTTP 是一种让 Web 服务器与浏览器(客户端)通过 Internet 发送与接收数据的协议,它建立在 TCP 协议之上，一般采用 TCP 的 80 端口。它是一个请求、响应协议–客户端发出一个请 求，服务器响应这个请求。在 HTTP 中，客户端总是通过建立一个连接与发送一个 HTTP 请 求来发起一个事务。服务器不能主动去与客户端联系，也不能给客户端发出一个回调连接。 客户端与服务器端都可以提前中断一个连接。例如，当浏览器下载一个文件时，你可以通过点击“停止”键来中断文件的下载，关闭与服务器的 HTTP 连接。HTTP 协议是无状态的，同一个客户端的这次请求和上次请求是没有对应关系，对 HTTP服务器来说，它并不知道这两个请求是否来自同一个客户端。为了解决这个问题， Web 程 序引入了 Cookie 机制来维护连接的可持续状态。 HTTP 协议是建立在 TCP 协议之上的，因此 TCP 攻击一样会影响 HTTP 的通讯，例如比较常见的一些攻击：SYN Flood 是当前最流行的 DoS（拒绝服务攻击）与 DdoS（分布式拒 绝服务攻击）的方式之一，这是一种利用 TCP 协议缺陷，发送大量伪造的 TCP 连接请求，从而使得被攻击方资源耗尽（CPU 满负荷或内存不足）的攻击方式。 HTTP交互方式：最基本的是GET、POST、PUT、DELETE。一个URL地址用于描述一个网络上的资源，而HTTP中的GET、POST、PUT、DELETE就对应着这个资源的查、改、增、删四个操作。 GET一般用于获取/查询资源信息，POST一般用于更新资源信息。区别在于： GET提交的数据会放在URL之后，以？分割URL和传输数据，参数之间以&amp;相连。POST方法是把提交数据放在HTTP包的Body中。 GET提交的数据大小有限制（因为浏览器对URL长度有限制），而POST提交数据没有限制。 GET方式提交数据，存在安全问题，比如登录页面，通过GET方式的话，用户名和密码都在URL上面，如果页面可以缓存或者其他人可以访问这台机器的，就可以从历史记录中获取账户和密码。 状态码：状态码用来告诉HTTP客户端，HTTP服务器是否产生了预期的Response。HTTP/1.1协议中定义了5类状态码，由三位数字组成，第一个数字定义了响应的类别。 1XX：提示信息-表示请求已经被成功接收，继续处理。 2XX：成功-表示请求已经被成功接收。 3XX：重定向-要完成请求必须进行更进一步处理。 4XX：客户端错误-请求有语法错误或请求无法实现。 5XX：服务器端错误-服务器未能实现合法的请求。 状态码 状态 详情 200 成功 服务器已经处理请求 301 永久重定向 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置 302 临时重定向 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求 303 请求资源路径改变 使用GET方法请求新url 400 请求错误 请求的报文中存在语法错误，比如url含有非法字符 401 未授权 未授权，比如访问SpringSecurity限制了权限的资源 404 未找到 服务器找不到请求的网页 405 请求错误 请求的方式（get、post、delete）方法与后台规定的方式不符合 415 请求错误 后台程序不支持提交的content-type 500 服务器内部错误 服务器遇到错误，无法完成请求","tags":[{"name":"web","slug":"web","permalink":"http://www.ylovex.cn/tags/web/"},{"name":"http","slug":"http","permalink":"http://www.ylovex.cn/tags/http/"}]},{"title":"排序算法总结","date":"2019-05-25T12:32:28.000Z","path":"2019/05/25/排序算法总结/","text":"排序算法：稳定：如果a在b前面 ，并且a==b，排序后a仍在b前面 不稳定：如果a在b前面，并且a==b，排序后a可能在b后面 时间复杂度：指执行当前算法所消耗的时间 空间复杂度：值执行当面算法所占用的内存空间 内排序：所有排序操作都在内存中完成 外排序：数据放在磁盘中，排序通过磁盘和内存的数据传输进行 冒泡排序:1234567891011121314151617181920212223242526272829303132public class bubbleS &#123; public static void bubbleSort1(int[] data)&#123; int len = data.length; for(int i=len-1;i&gt;0;i--)&#123; for(int j=0;j&lt;i;j++)&#123; //比较相邻两数，若前面大则交换 if(data[j]&gt;data[j+1])&#123; int tem = data[j]; data[j]=data[j+1]; data[j+1]=tem; &#125; &#125; &#125; &#125; public static void bubbleSort2(int[] data)&#123; int len = data.length; for(int i=len-1;i&gt;0;i--)&#123; //改进冒泡，如果一次比较都没有交换，则已经排好序，跳出循环 boolean isSort = true; for(int j=0;j&lt;i;j++)&#123; if(data[j]&gt;data[j+1])&#123; int tem = data[j]; data[j]=data[j+1]; data[j+1]=tem; isSort=false; &#125; &#125; if(isSort) break; &#125; &#125;&#125; 选择排序：1234567891011121314public class selectS &#123; public static void selectSort1(int[] data)&#123; for(int i=0;i&lt;data.length;i++)&#123; //记录每次循环中最小数的下标然后和data[i]交换 int minIndex = i; for(int j=i+1;j&lt;data.length;j++)&#123; minIndex = data[j]&lt;data[minIndex] ? j : minIndex; &#125; int tem = data[i]; data[i]=data[minIndex]; data[minIndex]=tem; &#125; &#125;&#125; 插入排序：1234567891011121314public class insertS &#123; public static void insertSort1(int[] data)&#123; int len = data.length; for(int i=1;i&lt;len;i++)&#123;//默认第一个数已排好序，从第二个数开始扫描 int tem = data[i]; int j = i-1;//将data[i]与前一位data[i-1]比较 while (j&gt;=0 &amp;&amp; tem&lt;data[j])&#123;//若小于，将前面的数往后移 data[j+1]=data[j]; j--; &#125; data[j+1]=tem;//找到位置后插入 &#125; &#125;&#125; 希尔排序：123456789101112131415161718public class shellS &#123; public static void shellSort1(int[] data)&#123; int len = data.length; int gap = len/2; while (gap&gt;0)&#123; for(int i=gap;i&lt;len;i++)&#123; int tem = data[i]; int preIndex = i-gap; while (preIndex &gt;= 0 &amp;&amp; data[preIndex]&gt;tem)&#123; data[preIndex+gap]=data[preIndex]; preIndex-=gap; &#125; data[preIndex+gap]=tem; &#125; gap/=2; &#125; &#125;&#125; 归并排序：1234567891011121314151617181920212223242526272829303132public class mergeS &#123; public static void mergeSort1(int[] data)&#123; if(data==null || data.length==0) return; mergeRec(data , 0 , data.length-1); &#125; public static void mergeRec(int[] data , int left , int right)&#123; if(left&gt;=right) return; int mid = left + (right-left)/2; mergeRec(data , left , mid); mergeRec(data , mid+1 , right); merge(data , left , mid , right); &#125; public static void merge(int[] data , int left , int mid , int right)&#123; int[] h = new int[right-left+1]; int p1 = left , p2=mid+1; int k = 0; while (p1&lt;=mid &amp;&amp; p2&lt;=right)&#123; h[k++]=data[p1]&lt;=data[p2] ? data[p1++] : data[p2++]; &#125; while (p1&lt;=mid)&#123; h[k++]=data[p1++]; &#125; while (p2&lt;=right)&#123; h[k++]=data[p2++]; &#125; for(int i=0;i&lt;k;i++)&#123; data[left+i]=h[i]; &#125; &#125;&#125; 堆排序：123456789101112131415161718192021222324252627282930313233343536373839public class heapS &#123; public static void heapSort1(int[] data)&#123; if(data==null || data.length&lt;=1) return; for(int i=0;i&lt;data.length;i++)&#123; siftUp(data , i);//上浮建堆 &#125; int len = data.length-1; swap(data , 0 , len); while (len&gt;0)&#123; siftDown(data , 0 , len); swap(data , 0 , --len); &#125; &#125; public static void siftUp(int[] data , int i)&#123; while (data[i]&gt;data[(i-1)/2])&#123; swap(data , i , (i-1)/2); i=(i-1)/2; &#125; &#125; public static void siftDown(int[] data , int i , int heapSize)&#123; int left = 2*i+1; int right = 2*i+2; int maxIdx = i; if(left&lt;heapSize &amp;&amp; data[left]&gt;data[maxIdx]) maxIdx=left; if(right&lt;heapSize &amp;&amp; data[right]&gt;data[maxIdx]) maxIdx = right; if(maxIdx != i)&#123; swap(data , i , maxIdx); siftDown(data , maxIdx , heapSize); &#125; &#125; public static void swap(int[] data , int s1 , int s2)&#123; int tem = data[s1]; data[s1]=data[s2]; data[s2]=tem; &#125;&#125; 快速排序：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class quickS &#123; public void quickSort_1(int[] data, int start, int end) &#123; if (data == null || start &lt; 0 || end &gt; data.length - 1) &#123; throw new IllegalArgumentException(&quot;Invalid Parameters&quot;); &#125; if (start == end) return; int index = partition(data, start, end); if (index &gt; start) &#123; quickSort_1(data, start, index - 1); &#125; if (index &lt; end) &#123; quickSort_1(data, index + 1, end); &#125; &#125; private int partition(int[] data, int start, int end) &#123; int index = start + (int)(Math.random() * (end - start + 1)); swap(data, index, end); int small = start - 1; for (index = start; index &lt; end; index++) &#123; if (data[index] &lt; data[end]) &#123; small++; if (small != index) &#123; swap(data, index, small); &#125; &#125; &#125; swap(data, small + 1, end); return small + 1; &#125; private void swap(int[] data, int i, int j)&#123; int temp = data[i]; data[i] = data[j]; data[j] = temp; &#125; public void quickSort_2(int[] data, int start, int end) &#123; if (data == null || start &gt;= end) return; int i = start, j = end; int pivotKey = data[start]; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; data[j] &gt;= pivotKey) j--; if (i &lt; j) data[i++] = data[j]; while (i &lt; j &amp;&amp; data[i] &lt;= pivotKey) i++; if (i &lt; j) data[j--] = data[i]; &#125; data[i] = pivotKey; quickSort_2(data, start, i - 1); quickSort_2(data, i + 1, end); &#125;&#125;","tags":[{"name":"排序","slug":"排序","permalink":"http://www.ylovex.cn/tags/排序/"}]},{"title":"单例模式","date":"2019-05-10T12:31:47.000Z","path":"2019/05/10/单例模式/","text":"单例模式：from 《菜鸟教程》 是属于创建型模式，提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，这个类负责创建自己的对象，同时也只有单个对象被创建，这个类提供了一个访问其唯一对象的方法，同时不需要实例化就可以直接访问。 单例类只能有一个实例 单例类必须自己创建自己的唯一实例 单例类必须给所有其他对象提供该实例 单例与静态类 单例可以继承和被继承，方法可以被重写，而静态方法不可以 静态方法中产生的对象会在执行后被释放，进而被GC清理，不会一直存在内存中 静态类会在第一次运行时候初始化，单例模式可以延迟加载 懒汉式，线程不安全Lazy初始化，非多线程 1234567891011public class Singleton &#123; private static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 懒汉式，线程安全Lazy初始化，多线程 12345678910public class Singleton&#123; private static Singleton instance; private Singleton()&#123;&#125; public static synchronized Singleton getInstance()&#123; if(instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 饿汉式非Lazy初始化，多线程，类加载时就初始化 1234567public class Singleton&#123; private static Singleton instance = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()[ return instance; ]&#125; 双检锁1234567891011121314public class Singleton&#123; private volatile static Singleton singleton; private Singleton()&#123;&#125; public static Singleton getSingleton()&#123; if(singleton == null)&#123; synchronized(Singleton.class)&#123; if(singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 登记式123456789public class Singleton&#123; private static class SingletonHolder&#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton()&#123;&#125; public static final Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125;&#125; 枚举123456public enum Singleton&#123; INSTANCE; public void whateverMethod()&#123; &#125;&#125;","tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://www.ylovex.cn/tags/单例模式/"}]},{"title":"Java Map笔记","date":"2019-05-02T13:54:41.000Z","path":"2019/05/02/java-map笔记/","text":"HashMap实现原理 参考https://www.cnblogs.com/chengxiao/p/6059914.html Entry内部结构为： HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，即链地址法。HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对和一个hash值和一个指向下一个Entry的next指针。 如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即 如果定位到的数组包含链表，对于添加操作，其时间复杂度依然为O(1)，操作是创建新节点，把该新节点插入到链表中的头部，该新节点的next指针指向原来的头结点 ，即需要简单改变引用链即可，而对于查找操作来讲，此时就需要遍历链表，然后通过key对象的equals方法逐一比对查找。 所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作 如果key为null，就会插入到table[0]的位置也就是数组头。如果key=null，则hash值直接赋0 存key时，如果链中存在该key，则用传入的value覆盖掉旧的value，同时把旧的value返回：这就是为什么HashMap不能有两个相同的key的原因。 计算hash值之后，如何通过hash值均匀的存到数组里？当然是取模，但取模消耗大，因此HashMap用的&amp;运算符（按位与操作）来实现的：hashCode &amp; (length-1)。 这里就隐含了为什么数组长度length一定要是2的n次方。当length不是2的n次方的时候，length-1的二进制最后一位肯定是0，在&amp;操作时，一个为0，无论另一个为1还是0，最终&amp;操作结果都是0，这就造成了结果的二进制的最后一位都是0，这就导致了所有数据都存储在2的倍数位上，所以说，所以说当length = 2^n时，不同的hash值发生碰撞的概率比较小，这样就会使得数据在table数组中分布较均匀，查询速度也较快。 存储过程： 传入key和value，判断key是否为null，如果为null，则调用putForNullKey，以null作为key存储到哈希表中； 2. 然后计算key的hash值，根据hash值搜索在哈希表table中的索引位置，若当前索引位置不为null，则对该位置的Entry链表进行遍历，如果链中存在该key，则用传入的value覆盖掉旧的value，同时把旧的value返回，结束； 3. 否则调用addEntry，用key-value创建一个新的节点，并把该节点插入到该索引对应的链表的头部 读取过程： 调用hash（key）求得key的hash值，然后调用indexFor（hash）求得hash值对应的table的索引位置，然后遍历索引位置的链表，如果存在key，则把key对应的Entry返回，否则返回null。 JDK1.8前后HashMap区别 在JDK1.8以前版本中，HashMap的实现是数组+链表，它的缺点是即使哈希函数选择的再好，也很难达到元素百分百均匀分布，而且当HashMap中有大量元素都存到同一个桶中时，这个桶会有一个很长的链表，此时遍历的时间复杂度就是O(n)，当然这是最糟糕的情况。 在JDK1.8及以后的版本中引入了红黑树结构，HashMap的实现就变成了数组+链表或数组+红黑树。添加元素时，若桶中链表个数超过8，链表会转换成红黑树；删除元素、扩容时，若桶中结构为红黑树并且树中元素个数较少时会进行修剪或直接还原成链表结构，以提高后续操作性能；遍历、查找时，由于使用红黑树结构，红黑树遍历的时间复杂度为 O(logn)，所以性能得到提升。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; HashMap扩容HashMap扩容可以分为三种情况： 使用默认构造方法初始化HashMap。HashMap在一开始初始化的时候会返回一个空的table，并且thershold为0。因此第一次扩容的容量为默认值DEFAULT_INITIAL_CAPACITY也就是16。同时threshold = DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR = 12。 指定初始容量的构造方法初始化HashMap。初始容量会等于threshold，接着threshold = 当前的容量（threshold） * DEFAULT_LOAD_FACTOR。 HashMap不是第一次扩容。如果HashMap已经扩容过的话，那么每次table的容量以及threshold量为原有的两倍。 HashMap是先插入数据再进行扩容的，但是如果是刚刚初始化容器的时候是先扩容再插入数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 参考https://blog.csdn.net/pange1991/article/details/82347284 HashMap多线程问题HashMap在多线程情况下出现死循环主要是在1.7情况下面，存在多线程时候应该使用ConcurrentHashMap。 12345678910111213void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; 12345678910111213141516171819202122void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; //循环取出原数组中每一个链表，e本身也是一个链表的节点，同时包含下一个节点的连接, //此处e表示第一个节点，next表示链表的下一个节点 if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); //计算在新数组中的存储位置 e.next = newTable[i]; //将原数组链表的第一个元素的next指向新数组，若新数组中已经存在元素， //则这个元素为第一个元素，next属性为原节点地址 newTable[i] = e; //将新数组的头节点指向e，此时e(原数组中的第一个元素)已经成功的转移到了新数据中 e = next; //继续处理原数组中剩下的节点 &#125; &#125; &#125; 参考https://www.jianshu.com/p/1ff9f3dee207 HashMap和HashTable Hashtable 中的方法是同步的，而HashMap中的方法在缺省情况下是非同步的。 Hashtable中，key和value都不允许出现null值。在HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。 并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 HashTable和synchronizedMap和ConcurrentHashMapHashTable、synchronizedMap效率低下 现在基本不用HashTable。HashTable容器使用synchronized来保证线程安全，但是锁的是整个hash表，当一个线程使用 put 方法时，另一个线程不但不可以使用 put 方法，连 get 方法都不可以。 synchronizedMap比HashTable强一分钱，synchronizedMap提供一个不同步的基类和一个同步的包装。允许需要同步的用户可以拥有同步，而不需要同步的用户则不必为同步付出代价，get方法与HashTable一样锁住整个hash表，区别是get()和put()之类的简单操作可以在不需要额外同步的情况下安全地完成。但多个操作组成的操作序列却可能导致数据争用，总之就是不好用。 ConcurrentHashMap效率高，因为用了分段锁（JDK8之前），16个 HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁 那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率 这就是 ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，默认分成16个段，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 上面说到的16个线程指的是写线程，而读操作大部分时候都不需要用到锁。只有在size等操作时才需要锁住整个hash表。 ConcurrentHashMap JDK1.8基本结构：Node&lt;K,V&gt;数组+链表（红黑树）的结构。 而对于锁的粒度，调整为对每个数组元素加锁（Node），即没有分段锁了，而是Node锁，粒度更小。 使用CAS操作来确保Node的一些操作的原子性，这种方式代替了锁。 ConcurrentHashMap在线程安全的基础上提供了更好的写并发能力，但同时降低了读一致性。ConcurrentHashMap的get操作上面并没有加锁。所以在多线程操作的过程中，并不能完全的保证一致性。这里和1.7当中类似，是弱一致性的体现。 代码中使用synchronized而不是ReentrantLock，说明JDK8中synchronized有了足够的优化。 然后是定位节点的hash算法被简化了，这样带来的弊端是Hash冲突会加剧。 因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。这样一来，查询的时间复杂度就会由原先的O(n)变为O(logN)。 ConcurrentHashMap的设计与实现非常精巧，大量的利用了volatile，final，CAS等lock-free技术来减少锁竞争对于性能的影响。 HashEntry中的value以及next都被volatile修饰，这样在多线程读写过程中能够保持它们的可见性。 HashMap读取与写入1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; 12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://www.ylovex.cn/tags/Java/"},{"name":"Map","slug":"Map","permalink":"http://www.ylovex.cn/tags/Map/"}]},{"title":"LMS算法","date":"2019-04-25T12:07:05.000Z","path":"2019/04/25/LMS算法/","text":"自适应滤波就是利用前一时刻获得的滤波器参数来自动调节现时刻的滤波器参数，以适应信号和噪声随时间变化的统计特性，从而实现最优滤波。 主输入端接收带噪信号，参考端为噪声信号，其中参考信号vi是与主输入端中信号s无关但与vo相关的噪声信号，利用量输入信号的相关性和有用信号与噪声的独立性，使参考信号尽可能逼近主输入端中的vo并相减从而抵消掉主输入端中的噪声干扰，最终得到有用信号。 算法代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253function [yn,w,en,itr]=LMSALG(xn,dn,M,mu,itr)% LMS(Least Mean Squre)算法% 输入参数:% xn 输入的信号序列 (列向量) % dn 所期望的响应序列 (列向量) % M 滤波器的阶数 (标量) % mu 收敛因子(步长) (标量) 要求大于0,小于xn的相关矩阵最大特征值的倒数 % itr 迭代次数 (标量) 默认为xn的长度,M &lt; itr &lt;= length(xn) % 输出参数: % w 滤波器的权值矩阵 (矩阵) % 大小为M*itr, % en 误差序列(itr*1) (列向量) % yn 实际输出序列 (列向量)% 确定迭代次数，若输入迭代次数itr，则设置为itr；若没有该参数，则设置为输入信号长度% 参数个数必须为4个或5个if nargin == 4 % 4个时递归迭代的次数为xn的长度 itr = length(xn);elseif nargin == 5 % 5个时需满足 M &lt; itr &lt; length(xn) if itr &gt; length(xn) || itr &lt; M error(&apos;迭代次数过大或过小!&apos;); endelse error(&apos;请检查输入参数的个数!&apos;); end % 初始化参数en = zeros(itr,1); % 误差序列,en(k)表示第k次迭代时预期输出与实际输入的误差w = zeros(itr,M); % 每一行代表一个加权参量,每一列代表-次迭代,初始为0% w权系数取为矩阵主要是为了判断该算法的收敛性xn_r=xn&apos;; %%%%参考行向量dn_r=dn&apos;; %%%%nmr行向量% 迭代计算for kitr = M:itr % 第k次迭代 x = xn(kitr:-1:kitr-M+1); % 滤波器M个抽头的输入 y = w(kitr-1,:)*x; % 滤波器的输出 en(kitr) = dn(kitr) - y; % 第k次迭代的误差 % 滤波器权值计算的迭代式 w(kitr,:) = w(kitr-1,:) + 2*mu*en(kitr)*x&apos;;%%xn(kitr-M+1:kitr)&apos;;end%%%方法一、直接使用filter函数来进行滤波处理CancellationData = filter(w(end,:),1,xn_r); % 直接使用filter函数来进行滤波处理yn = dn_r-CancellationData;yn = yn(M+1:end);% 去掉与滤波系数长度对应的前N个点yn=yn&apos;; %%输出行向量% % 求最优时滤波器的输出序列% yn = zeros(size(xn)); % for kitr = M:length(xn)% x = xn(kitr:-1:kitr-M+1);% yn(kitr) = dn(kitr) - w(end,:)*x; % w(:,end)为最后一次迭代生成的滤波器系数% end% yn = yn(M:end); % 前面M个数据没有经过滤波处理，所以设置成inf，绘图时不显示","tags":[{"name":"lms","slug":"lms","permalink":"http://www.ylovex.cn/tags/lms/"}]},{"title":"Java Set笔记","date":"2019-04-20T13:54:41.000Z","path":"2019/04/20/java-set笔记/","text":"Set种类Set接口的特性，Set接口继承了Collection接口，Set集合中不能包含重复的元素，每个元素必须是唯一的，你只要将元素加入set中，重复的元素会自动移除。 Java中提供了HashSet、TreeSet、LinkedHashSet三种常用的Set实现。 HashSet实现HashSet底层通过HashMap实现。 123456789101112private transient HashMap&lt;E,Object&gt; map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * default initial capacity (16) and load factor (0.75). */ public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; HashSet存储元素是无序的，元素的哈希码进行存储的，HashSet根据每个存储对象的哈希码值（调用hashCode方法获得），用固定的算法算出它的存储索引，把存储对象存放在一个叫做散列表的相应位置中，如果对应的位置没有其它元素，就只需要直接存入；如果该位置已经有元素了，就会将新对象跟该位置的所有对象进行比较（调用equals（）方法），以查看容器中是否已经存在该对象，若不存在，就存放该对象，若已经存在，就直接使用该对象。 HashSet的存储结构是个链表数组，每一个数组元素就是一个链表，类似这种数据结构称为散列表。数组用于存储元素，该存储元素对应的数组下标是调用hashCode方法返回的存储元素的哈希码。当后加入元素的哈希码与已经加入的元素哈希码相同时，HashSet就会创建一个链表，将相同哈希码的元素存入一个链表，并将该链表的头指针存储到哈希码对应的数组元素中。 HashSet和TreeSetHashSet底层数据结构是哈希表，TreeSet底层数据结构是红黑树。 TreeSet保证元素的排序方式： 自然排序(这种排序方式可以理解成元素本身具备比较性)让元素所属的类实现Comparable接口。 比较器排序(这种排序可以理解成集合类具备比较性)让集合构造方法接收Comparator的实现类对象，实现方式可以用匿名类来实现。 LinkedHashSet是HashSet子类，LinkedHashSet集合也是根据元素hashCode值来决定元素存储位置，但它同时使用链表维护元素的次序，这样使的元素看起来是以插入的顺序保存的。也就是说当遍历LinkedHashSet集合里的元素时，HashSet将会按元素的添加顺序来访问集合里的元素。 LinkedHashSet需要维护元素的插入顺序，因此性能略低于HashSet的性能，但是在迭代访问Set里的全部元素时，将有很好的性能，因为它以列表来维护内部顺序。","tags":[{"name":"Java","slug":"Java","permalink":"http://www.ylovex.cn/tags/Java/"},{"name":"Set","slug":"Set","permalink":"http://www.ylovex.cn/tags/Set/"}]},{"title":"Java List笔记","date":"2019-04-14T13:54:41.000Z","path":"2019/04/14/java-list笔记/","text":"ListList是一个接口，继承于Collenction接口，它代表着有序的队列。 ​ ps：java.util.Collection是一个集合接口，它提供了对集合对象进行基本操作的通用接口方法；javautil.Collections是一个包装类，它包含各种有关集合操作的静态多态方法，该类不能实例化，服务于Collection框架。 ArrayList：底层是用数组实现。 LinkedList：底层是通过双向链表实现。 Vector：通过数组实现，线程安全。 ArrayList扩容默认初始容量为10. 12345678/** * Default initial capacity. */ private static final int DEFAULT_CAPACITY = 10; transient Object[] elementData; // non-private to simplify nested class access private int size; 扩容，默认为1.5倍方式 1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; ArrayList和LinkedListArrayList是实现了基于动态数组的数据结构，LinkedList是基于链表结构。 对于随机访问的get和set方法，ArrayList要优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinkedList比较占优势，因为ArrayList要移动数据。 对ArrayList和LinkedList而言，在列表末尾增加一个元素所花的开销都是固定的。对 ArrayList而言，主要是在内部数组中增加一项，指向所添加的元素，偶尔可能会导致对数组重新进行分配；而对LinkedList而言，这个开销是 统一的，分配一个内部Entry对象。 在ArrayList集合中添加或者删除一个元素时，当前的列表所所有的元素都会被移动。而LinkedList集合中添加或者删除一个元素的开销是固定的。 LinkedList集合不支持高效的随机随机访问（RandomAccess），因为可能产生二次项的行为。 ArrayList的空间浪费主要体现在在list列表的结尾预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗相当的空间。 Arrays.asList()方法123456int[] a = &#123;1,2,3,4&#125;; List a_list = Arrays.asList(a); System.out.println(a_list.size());//size=1 Integer[] b = &#123;1,2,3,4&#125;; List b_list = Arrays.asList(b); System.out.println(b_list.size());//size=4 Arrays.asList方法返回的是List，通过Arrays类的一个内部类实现，内部用的数组就是传入的数组，没有拷贝，也不会动态改变大小，所以对数组的修改也会反应到List中，对List调用add/remove方法会抛出异常。 使用ArrayList方法实现为： 1List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(Arrays.asList(a)); ArrayList线程不安全12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; 因为ArrayList本身不是线程安全的，通过Collections.synchronizedList可以将其包装成一个线程安全的List。 Vector和ArrayListvector是线程（Thread）同步（Synchronized）的，所以它也是线程安全的，而Arraylist是线程异步（ASynchronized）的，是不安全的。如果不考虑到线程的安全因素，一般用Arraylist效率比较高。 如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%,而arraylist增长率为目前数组长度的50%.如过在集合中使用数据量比较大的数据，用vector有一定的优势。","tags":[{"name":"Java","slug":"Java","permalink":"http://www.ylovex.cn/tags/Java/"},{"name":"List","slug":"List","permalink":"http://www.ylovex.cn/tags/List/"}]},{"title":"Java 基础知识","date":"2019-04-10T13:43:41.000Z","path":"2019/04/10/java-基础/","text":"面向对象和面向过程 面向过程：是一种是事件为中心的编程思想。就是分析出解决问题所需的步骤，然后用函数把这写步骤实现，并按顺序调用。 面向对象：是以“对象”为中心的编程思想。 面向对象三大特性：封装、继承、多态。因为一切皆对象，所以一切都需要“封装”成类。“继承”让我们设计相似的东西的时候更方便，而“多态”让我们使用类似的东西的时候可以不用去思考它们微弱的不同。我们关心的不是过程，而是接口，而接口来自对象，故名为面向对象。 封装、继承、多态 封装：通过隐藏类的内部实现机制，对外界提供已经定义好的接口进行访问。对外界而言它的内部细节是隐藏的，暴露给外界的只是它的访问方法。 继承：是从已有的类得到继承信息创建新的类的过程，继承可以表示为is-a关系，让我们设计相似的东西的时候更加的方便。 多态：可以分为方法重载和方法重写两种方式，方法重载是在编译时的多态性（也就是前绑定），方法可以根据不同参数类型进行不同的调用，方法名字一致；方法重写是运行时多态（也称为后绑定），实现方法重写：1.方法重写，子类继承父类并重写父类方法；2.用父类型引用来引用子类型对象，实现调用同样的方法会根据子类对象的不同表示出不一样的行为。 反射 Java的反射机制允许我们动态的调用某个对象的方法、构造函数、获取某个对象的属性等； 无需在编码的时候确定调用的对象 实现方式： 先获取这个类的class实例，比如:Class&lt;?&gt; myClass =Class.forName(“myClassName”); 然后通过这个类实例获得一个类对象，比如：Object myClassObject = myClass.newInstance(); 然后调用Class类的对象的getMethod获取method对象; 获取method对象后调用method.invoke方法获取这个类的field、method、construct等，在这一步中，JVM默认如果调用次数小于15次，会调用native方法实现反射，累积调用大于15次之后，会由java代码创建出字节码来实现反射。 集合实现了Collection接口的集合类： Collection&lt;–List&lt;–Vector Collection&lt;–List&lt;–ArrayList Collection&lt;–List&lt;–LinkedList Collection&lt;–Set&lt;–HashSet Collection&lt;–Set&lt;–HashSet&lt;–LinkedHashSet Collection&lt;–Set&lt;–SortedSet&lt;–TreeSet 实现了Map接口，和Collection接口没关系，但都属于集合类的一部分： HashMap HashTable LinkedHashMap TreeMap SynchronizedMap ConcurrentHashMap final和static被final声明的对象即表示“我不想这个对象再被改变”，因此： 被final声明的方法：这个方法不可以被子类重写 被final声明的类：这个类不能被继承 被final声明的变量：引用不能改变，常和static关键字一起使用作为常量final关键字的好处： final关键字提高了性能。JVM和Java应用都会缓存final变量。 final变量可以安全的在多线程环境下进行共享，而不需要额外的同步开销。 使用final关键字，JVM会对方法、变量及类进行优化。 static关键字 static用来修饰成员变量和成员方法，也可以形成静态static代码块。 static对象可以在它的任何对象创建之前访问，无需引用任何对象。 因此主要作用是构造全局变量和全局方法。 数据类型 boolean byte char ：都是一个字节 short int long float double ：int是4个字节，负2的31次方到正2的31次方减1 String Enum Array Object ps：负数使用补码表示 Primitive type: int,long,float… Object: Integer,Long,Float,String… Primitive type: 值类型 用a==b判断相等 Object： 引用类型 用a==b判断是否为同一个Object 用a.equals(b),或者Obeject.equals(a,b)判断是否相等 两个Object如果不是同一个Object，即使值相等用==判断也是false 数组和链表基于空间的考虑： 数组的存储空间是静态，连续分布的，初始化的过大造成空间浪费，过小又将使空间溢出机会增多。而链表的存储空间是动态分布的，只要内存空间尚有空闲，就不会产生溢出；链表中每个节点出了数据域外，还有链域（指向下一个节点），这样空间利用率就会变高。 数组从栈中分配空间，对于程序员方便快速，但是自由度小。链表从堆中分配空间，自由度大但是申请管理比较麻烦。 数组中的数据在内存中按顺序存储的，而链表是随机存储的。 基于时间的考虑： 数组查询快，插入与删除慢，单链表查询慢，插入与删除快。细说的话：数组中任意节点都可以在O（1）内直接存储访问，而链表中的节点，需从头指针顺着链表扫描才能获取到；而链表任意位置进行插入和删除，都只需要修改指针，而数组中插入删除节点，平均要移动一半的节点。 访问控制符 public protected defailt private 同一个类 True True True True 同一个包 True True True False 子父类 True True False False 不同包 True False False False 接口与抽象类抽象类就是比普通类多了一些抽象方法而已，其他部分和普通类完全一样；而接口是特殊的抽象类。作用上看： 接口与抽象类结构有点像，但功能完全不同 接口是强调合约、约束关系，即你要与我合作，必须实现我的功能；抽象类没这个功能 语法上看： 都不能被实例化 接口是特殊的抽象类 接口不能有实现，Java8中可以有添加default关键字的默认实现和静态方法实现。 接口中的成员变量必须是public static final修饰（编译器默认会添加上），因此是常量 一个类可以实现多个接口但只能继承一个抽象类 什么是接口？ 从表现来说：定义了很多函数，但是这些函数都没有实现，这就是接口。从作用来说：起到一个合约规范的作用。我要告诉你和我打交道的东西有什么约束 接口中的方法只能用public和abstract修饰或者不修饰 接口中的属性默认都是public static final，因此是常量 equal与==对于字符串变量： ==：比较两个对象在内存中的首地址 equals：比较字符串中所包含的内容是否相同 对于非字符串变量： ==和equals都是比较对象在堆内存中的首地址。 装箱及拆箱Integer i = 10; //装箱 int n = i ;//拆箱 装箱就是自动将基本数据类型转换为包装器类型。 拆箱就是自动将包装器类型转换为基本数据类型。 hashCode方法及作用Java中的hashCode方法就是根据一定的规则将与对象相关的信息（比如对象的存储地址，对象的 字段等）映射成一个数值，这个数值称作为散列值。 1、在Java集合中有两类，一类是List，一类是Set。他们之间的区别就在于List集合中的元素是有序的，且可以重复，而Set集合中元素是无序不可重复的。对于List好处理，但是对于Set而言我们要如何来保证元素不重复呢？通过迭代来equals()是否相等。数据量小还可以接受，当我们的数据量大的时候效率可想而知2、当集合要添加新的对象时，先调用这个对象的 hashCode方法，得到对应的hashcode值，实际上在HashMap的具体实现中会用一个table保存已经存进去的对象的hashcode 值，如果table中没有该hashcode值，它就可以直接存进去，不用再进行任何比较了；如果存在该hashcode值， 就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址3、所以hashCode在上面扮演的角色为快速寻域（寻找某个对象在集合中区域位置） 在重写equals方法的同时，必须重写hashCode方法。为什么这么说呢？1、让equals方法和hashCode方法始终在逻辑上保持一致性2、即让equals认为相等的两个对象，这两个对象同时调用hashCode方法，返回的值也是一样的 Java8新特性Lambda 表达式 − Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中。 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Date Time API − 加强对日期与时间的处理。 Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。 Java NIO框架对比Mina Mina(Multipurpose Infrastructure for Network Applications) 是 Apache 组织一个较新的项目，它为开发高性能和高可用性的网络应用程序提供了非常便利的框架。当前发行的 Mina 版本2.04支持基于 Java NIO 技术的 TCP/UDP 应用程序开发、串口通讯程序，Mina 所支持的功能也在进一步的扩展中。 Netty Netty是一款异步的事件驱动的网络应用框架和工具，用于快速开发可维护的高性能、高扩展性协议服务器和客户端。也就是说，Netty是一个NIO客户端/服务器框架，支持快速、简单地开发网络应用，如协议服务器和客户端。它极大简化了网络编程，如TCP和UDP套接字服务器。 Grizzly Grizzly是一种应用程序框架，专门解决编写成千上万用户访问服务器时候产生的各种问题。使用JAVA NIO作为基础，并隐藏其编程的复杂性。容易使用的高性能的API。带来非阻塞socketd到协议处理层。利用高性能的缓冲和缓冲管理使用高性能的线程池。 xSocket xSocket是一个轻量级的基于nio的服务器框架用于开发高性能、可扩展、多线程的服务器。该框架封装了线程处理、异步读/写等方面。（只是对Java的NIO做了最简单的封装，以便于开发使用。","tags":[{"name":"Java","slug":"Java","permalink":"http://www.ylovex.cn/tags/Java/"}]},{"title":"my first blog","date":"2019-04-03T13:41:41.000Z","path":"2019/04/03/my-first-blog/","text":"Desire is the starting point of all achievement 渴望是所有成就的原点。 love xy","tags":[{"name":"Life","slug":"Life","permalink":"http://www.ylovex.cn/tags/Life/"}]},{"title":"Hello World","date":"2019-04-01T12:07:05.000Z","path":"2019/04/01/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]