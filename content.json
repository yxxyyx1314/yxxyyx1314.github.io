[{"title":"jvm虚拟机执行子系统","date":"2019-07-09T12:26:37.000Z","path":"2019/07/09/jvm虚拟机执行子系统/","text":"虚拟机执行子系统类文件结构任何一个Class文件都对应着唯一一个类或者接口的定义信息，但反过来说，类或接口并不一定都得定义在文件里（譬如类或者接口也可以通过类加载器直接生成）。 Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地 排列在Class文件之中，中间没有添加任何分隔符，这使得整个Class文件中存储的内容几乎 全部是程序运行的必要数据，没有空隙存在。当遇到需要占用8位字节以上空间的数据项时，则会按照高位在前的方式分割成若干个8位字节进行存储。 Class文件格式采用一种类似于C语言结构体的伪结构来存 储数据，这种伪结构中只有两种数据类型：无符号数和表： 无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1个字节、2个字节、4个 字节和8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8 编码构成字符串值。 表是由多个无符号数或者其他表作为数据项构成的复合数据类型，所有表都习惯性以“_info”结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表。 Class类文件结构详解： 魔数：每个Class文件的头4个字节称为魔数，唯一的作用是确定这个文件是否为一个能被虚拟机接受的Class文件。值为：0xCAFEBABE。 版本号：紧接着魔数的4个字节存储的是Class文件的版本号，第5和第6个字节是次版本号，第7和第8个字节是主版本号。java版本号从45开始。 常量池：紧接着版本号之后的是常量池入口，常量池可以理解为Class文件之中的资源仓库，常量池入口需要放置一项u2类型的数据，代表常量池容量计数器，该容量计数从1开始而不是0；常量池主要存在两大类常量：字面量和符号引用，字面量比较接近于java语言层面的常量概念，如文本字符串、声明为final的常量值等。符号引用则属于编译原理方面的概念，包含：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符。 访问标志：常量池结束后，紧接着的两个字符代表访问标志，这个标志用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口、是否定义为public类型、是否定义为abstract类型、如果是类的话，是否被声明为final等 类索引、父类索引、接口索引：类索引和父类索引都是一个u2类型的数据，而接口索引集合是一组u2类型的数据集合 字符表集合：用于描述接口或者类中声明的变量，字段包括类级变量以及实例级变量，但不包括在方法内部声明的局部变量。 方法表集合：结构如同字段表一样，依次包括了访问标志、名称索引、描述符索引、属性表集合几项 属性表集合：常用属性如下 Code属性；使用位置：方法表；含义：Java代码编译成的字节码指令 ConstantValue属性；字段表；final关键字定义的常量值 Deprecated属性；类、方法表、字段表；被声明为deprecated的方法和字段 Exceptions属性、方法表、方法抛出的异常 EnclosingMethod属性、方法表、仅当一个类为局部类或者匿名类时才能拥有这个属性，这个属性用于标识这个类所在的外围方法 虚拟机类加载机制虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是JVM的类加载机制。 类加载的时机类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载 （Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化 （Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备、解析3个 部分统称为连接（Linking） 其中，加载、验证、准备、初始化和卸载这5个阶段是确认的， 解析阶段不一定：在某些情况在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也称为动态绑定或晚期绑定） 虚拟机严格规定了有且只有5种情况必须立即对类进行“初始化”（而加载、验证、准备自然需要在此之前开始）： 遇到new、getstatic、putstatic或invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化， 则需要先触发其初始化 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化 当虚拟机启动时，用户需要指定一个要执行的主类（包含main（）方法的那个 类），虚拟机会先初始化这个主类 当使用JDK 1.7的动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄 所对应的类没有进行过初始化，则需要先触发其初始化。 对于这5种会触发类进行初始化的场景，虚拟机规范中使用了一个很强烈的限定语：“有 且只有”，这5种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都 不会触发初始化，称为被动引用： 对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化 通过数组定义来引用类，不会触发此类的初始化 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 接口也用初始化过程，当一个类在初始化时，要求其父类全部都已经初始 化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使 用到父接口的时候（如引用接口中定义的常量）才会初始化。 类加载过程加载 通过一个类的全限定名来获取定义此类的二进制字节流。JVM把这个阶段的动作放在了虚拟机外部的“类加载器”中实现。未指明从哪里获取，因此有各种花样，比如从JAR包、WAR包，或者网络，或者运行时计算生成比如动态代理、由其他文件生成、从数据库读取等等。 将这个字节流所代表的的静态存储结构转化为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。即对象类型数据（非对象实例数据）存在方法区。 验证验证的目的是确保Class文件的字节流中包含的信号符合当前虚拟机的要求，不会危害虚拟机自身的安全。 分为四个阶段： 文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理 元数据验证：是对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求 字节码验证：主要是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的 符号引用验证：发生在虚拟机将符号引用转化为直接引用的时候，这个转化动作将在连接的第三阶段–解析阶段中发生。符号引用验证可以看做是对类自身以外的信息进行匹配性校验。 对于虚拟机的类加载机制来说，验证阶段是一个非常重要的、但不是一定必要（因为对 程序运行期没有影响）的阶段。如果所运行的全部代码（包括自己编写的及第三方包中的代 码）都已经被反复使用和验证过，那么在实施阶段就可以考虑使用-Xverify：none参数来关 闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。 这个阶段中有两个容易产生混淆的概念需要强调一下，首先，这时候进行内存分配的仅包括类变量（被static修饰的变量），而不包括实例变量，实例变量将会在对象实例化时随着对象一起分配在Java堆中。其次，这里所说的初始值“通常情况”下是数据类型的零值。 比如public static int value=123：在准备阶段过后value=0，只有在初始化阶段后，value才等于123； 但是如何类字段的字段属性表中存在ConstantValue属性，那么在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，比如 public static final int value=123，编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为123. 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。 直接引用（Direct References）：直接引用可以是直接指向目标的指针、相对偏移量或是 一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引 用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在 虚拟机规范之中并未规定解析阶段发生的具体时间，只要求了在执行anewarray、 checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invokespecial、 invokestatic、invokevirtual、ldc、ldc_w、multianewarray、new、putfield和putstatic这16个用于 操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析 对同一个符号引用进行多次解析请求是很常见的事情，除invokedynamic指令以外，虚拟 机实现可以对第一次解析的结果进行缓存（在运行时常量池中记录直接引用，并把常量标识 为已解析状态）从而避免解析动作重复进行。 对于invokedynamic指令，上面规则则不成立。当碰到某个前面已经由invokedynamic指令 触发过解析的符号引用时，并不意味着这个解析结果对于其他invokedynamic指令也同样生 效。因为invokedynamic指令的目的本来就是用于动态语言支持（目前仅使用Java语言不会生 成这条字节码指令），它所对应的引用称为“动态调用点限定符”（Dynamic Call Site Specifier），这里“动态”的含义就是必须等到程序实际运行到这条指令的时候，解析动作才能进行。相对的，其余可触发解析的指令都是“静态”的，可以在刚刚完成加载阶段，还没有 开始执行代码时就进行解析。 解析动作主要针对类或者接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行 初始化是类加载过程的最后一步，类加载过程中，除了在加载阶段用户应用程序可以通过自定义类加载器参与之外，其余动作完全由虚拟机主导和控制，到了初始化阶段，才开始真正执行类中定义的Java程序代码。 在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通 过程序制定的主观计划去初始化类变量和其他资源，或者可以从另外一个角度来表达：初始 化阶段是执行类构造器＜clinit＞（）方法的过程。 类加载器虚拟机把类加载阶段中的通过一个类的全限定名来获取定义此类的二进制字节流这个动作放在了虚拟机外部的“类加载器”中实现。 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机中的唯一性 比较两个类是否“相等”，只有在这个两个类是由同一个类加载器加载的前提下才有意义。 双亲委派模型绝大部分Java程序都会使用到3种系统提供的类加载器： 启动类加载器：这个类将器负责将存放在＜ JAVA_HOME＞\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机 识别的（仅按照文件名识别，如rt.jar，名字不符合的类库即使放在lib目录中也不会被加载） 类库加载到虚拟机内存中 扩展类加载器：它负责加载＜JAVA_HOME＞\\lib\\ext目录中的，或者被java.ext.dirs系 统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。 应用程序类加载器：它负责加载用户类路径（ClassPath）上所指定的类 库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一 般情况下这个就是程序中默认的类加载器。 上图就是类加载器的双亲委派模型，双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当 有自己的父类加载器。这里类加载器之间的父子关系一般不会以继承（Inheritance）的关系 来实现，而是都使用组合（Composition）关系来复用父加载器的代码 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 12345678910111213141516171819202122protected synchronized Class＜?＞loadClass（String name,boolean resolve）throws ClassNotFoundException &#123; //首先，检查请求的类是否已经被加载过了 Class c=findLoadedClass（name）； if（c==null）&#123; try&#123; if（parent！=null）&#123; c=parent.loadClass（name,false）；&#125;else&#123;c=findBootstrapClassOrNull（name）；&#125; &#125;catch（ClassNotFoundException e）&#123; //如果父类加载器抛出ClassNotFoundException //说明父类加载器无法完成加载请求&#125; if（c==null）&#123; //在父类加载器无法加载的时候 //再调用本身的findClass方法来进行类加载c=findClass（name）；&#125; &#125; if（resolve）&#123; resolveClass（c）； &#125; return c；&#125; 好处：Java类随着它的类加载器一起具备了一种带有优先级的层次关系。 为什么需要双亲委派模型： 例如类java.lang.Object，它存在在rt.jar中，无论哪一个类加载器要加载这个类，最终都是委派给处于模型最顶端的Bootstrap ClassLoader进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。相反，如果没有双亲委派模型而是由各个类加载器自行加载的话，如果用户编写了一个java.lang.Object的同名类并放在ClassPath中，那系统中将会出现多个不同的Object类，程序将混乱。 如果不采用双亲委派模型，那么由各个类加载器自己去加载的话，那么系统中会存在多种不同的Object类。 虚拟机字节码执行引擎执行引擎是Java虚拟机最核心的组成部分之一。 运行时栈帧结构栈帧（Stack Frame）是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区中的虚拟机栈（Virtual Machine Stack）的栈元素。 栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息。每一个方法从调用开始至执行完成的过程，都对应着一个栈帧在虚拟机栈里面从入栈到出栈的过程。 每一个栈帧都包括了局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。在编译程序代码的时候，栈帧中需要多大的局部变量表，多深的操作数栈都已经完全确定了，并且写入到方法表的Code属性之中，因此一个栈帧需要分配多少内存，不会受 到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。 一个线程中的方法调用链可能会很长，很多方法都同时处于执行状态。对于执行引擎来 说，在活动线程中，只有位于栈顶的栈帧才是有效的，称为当前栈帧（Current Stack Frame），与这个栈帧相关联的方法称为当前方法（Current Method）。执行引擎运行的所有 字节码指令都只针对当前栈帧进行操作。 局部变量表是一组变量值存储空间，用于存放方法参数和方法 内部定义的局部变量。在Java程序编译为Class文件时，就在方法的Code属性的max_locals数 据项中确定了该方法所需要分配的局部变量表的最大容量 以变量槽（Slot）为最小单位，到每个Slot都应该能存放一 个boolean、byte、char、short、int、float、reference或returnAddress类型的数据。 操作数栈也常称为操作栈，它是一个后入先出（Last In First Out,LIFO）栈。同局部变量表一样，操作数栈的最大深度也在编译的时候写入到Code属性的 max_stacks数据项中。操作数栈的每一个元素可以是任意的Java数据类型，包括long和 double。32位数据类型所占的栈容量为1，64位数据类型所占的栈容量为2。在方法执行的任 何时候，操作数栈的深度都不会超过在max_stacks数据项中设定的最大值 动态连接每个栈帧都包含一个指向运行时常量池[1]中该栈帧所属方法的引用，持有这个引用是为 了支持方法调用过程中的动态连接（Dynamic Linking）。Class 文件的常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符 号引用作为参数。这些符号引用一部分会在类加载阶段或者第一次使用的时候就转化为直接引用，这种转化称为静态解析。另外一部分将在每一次运行期间转化为直接引用，这部分称为动态连接 方法返回地址当一个方法开始执行后，只有两种方法可以退出： 执行引擎遇到任意一个方法返回的字节码指令 遇到异常，并且该异常没有在方法体内得到处理 方法调用方法调用阶段唯一的任务就是确认被调用方法的版本（即调用哪一个方法），一切方法调用在Class文件里面存储的都只是符号引用，而不是方法在实践运行时内存布局中的入口地址。 解析所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载的解析阶段会将其中一部分符号引用转化为直接引用 这类解析成立前提：方法在程序真正运行之前就有一个可确定的调用版本，并且这个方法的调用版本在运行期不可变。 符合“编译期可知，运行期不可变”：主要包括静态方法和私有方法。 Java虚拟机里面提供了5条方法调用字节指令： invokestatic：调用静态方法 invokespecial：调用实例构造器方法，私有方法和父类方法 invokevirtual;调用所有的虚方法 invokeinterface:调用接口方法，会在运行时再确认一个实现此接口的对象 invokedynamic:先在运行时动态解析出调用点限定符所引用的方法，然后再执行该方 法，在此之前的4条调用指令，分派逻辑是固化在Java虚拟机内部的，而invokedynamic指令 的分派逻辑是由用户所设定的引导方法决定 只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段中确定唯一的 调用版本，符合这个条件的有静态方法、私有方法、实例构造器、父类方法4类，它们在类 加载的时候就会把符号引用解析为该方法的直接引用。这些方法可以称为非虚方法，与之相 反，其他方法称为虚方法（除去final方法） 分派静态分派：所有依赖静态类型来定位方法执行版本的分派动作称为静态分派。典型应用是方法重载。 动态分派：在运行期根据实际类型确定方法执行的颁布的分派过程，重要体现是方法重写 Java代码编译过程 代码编译是由Javac编译器来完成，流程如上图所示。Javac的任务就是将Java源代码编译成Java字节码，也就是JVM能够识别的二进制代码，从表面看是将.java文件转化为.class文件。而实际上是将Java源代码转化成一连串二进制数字，这些二进制数字是有格式的，只有JVM能够真确的识别他们到底代表什么意思。 具体流程： 词法分析：读取源代码，一个字节一个字节的读进来，找出这些词法中我们定义的语言关键词如：if、else、while等，识别哪些if是合法的哪些是不合法的。这个步骤就是词法分析过程 语法分析：就是对词法分析中得到的token流进行语法分析，这一步就是检查这些关键词组合在一起是不是符合Java语言规范。如if的后面是不是紧跟着一个布尔型判断表达式。 语义分析：语法分析完成之后也就不存在语法问题了，语义分析的主要工作就是把一些难懂的，复杂的语法转化成更简单的语法。比如将foreach转化为for循环。 字节码生成：将会根据经过注释的抽象语法树生成字节码，也就是将一个数据结构转化为另外一个数据结构，结果就是生成符合java虚拟机规范的字节码。","tags":[{"name":"java","slug":"java","permalink":"http://ylovex.cn/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://ylovex.cn/tags/jvm/"}]},{"title":"nowcoder-病毒传播","date":"2019-07-06T23:37:20.000Z","path":"2019/07/07/nowcoder-病毒传播/","text":"题目来源：https://www.nowcoder.com/practice/3b6060942397444cb0fe5846e230f6d9?tpId=90&amp;tqId=30850&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：给出一个图G(V,E)，图上有n个点，m条边，所有的边都是无向边。 最开始，也就是第0天的时候，这n个点中有一个点v感染了病毒，之后的每一天，凡是感染病毒的点都会向它的邻居点传播病毒。经过了t天之后，得到了感染病毒的点集S。要求找出第0天感染病毒的点v。如果v有很多不同的答案，把它们都找出来。 思路：bfs算法，显然感染源一定是感染的点，先用ArrayLIst生成图，以每个感染的点为起点在t时间内进行广度遍历，将结果与给定的感染集合进行比较，如果一样则该点可以是感染源。 参考代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class Now_74 &#123; static boolean[] infected; static ArrayList&lt;Integer&gt;[] graph; static int n, m, k, t; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); n = sc.nextInt(); m = sc.nextInt(); infected = new boolean[n+1]; graph = new ArrayList[n+1]; for(int i=1;i&lt;=n;i++)&#123; graph[i]=new ArrayList&lt;&gt;(); &#125; for(int i=0 ; i&lt;m;i++)&#123; int u = sc.nextInt(); int v = sc.nextInt(); graph[u].add(v); graph[v].add(u); &#125; k = sc.nextInt(); t = sc.nextInt(); for(int i = 0;i&lt;k;i++)&#123; infected[sc.nextInt()]=true; &#125; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for(int i=1;i&lt;=n;i++)&#123; if(infected[i] &amp;&amp; bfs(i))&#123; res.add(i); &#125; &#125; if(res.size()==0)&#123; System.out.println(-1); &#125; else &#123; for(int i=0;i&lt;res.size();i++)&#123; if(i==res.size()-1)&#123; System.out.print(res.get(i)); &#125; else &#123; System.out.print(res.get(i)+\" \"); &#125; &#125; &#125; &#125; //以x为起点传播t天的结果和实际结果比较是否相同 private static boolean bfs(int x) &#123; //每个点被传染需要的时间, 为0表明没有被传染 int[] temp = new int[n+1]; LinkedList&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); temp[x]=1; queue.offer(x); while (! queue.isEmpty())&#123; int cur = queue.poll(); if(temp[cur]&gt;t) break; for(Integer e : graph[cur])&#123; if(temp[e]==0)&#123; temp[e]=temp[cur]+1; queue.offer(e); &#125; &#125; &#125; for(int i=1;i&lt;=n;i++)&#123; if(!infected[i] &amp;&amp; temp[i]!=0) return false; if(infected[i] &amp;&amp; temp[i]==0) return false; &#125; return true; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://ylovex.cn/tags/code/"},{"name":"bfs","slug":"bfs","permalink":"http://ylovex.cn/tags/bfs/"}]},{"title":"Redis设计与实现笔记三","date":"2019-07-04T22:55:12.000Z","path":"2019/07/05/Redis设计与实现笔记三/","text":"字典：又称符号表、关联数组、映射，是一种保存键值对的抽象数据结构。 Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，一个哈希表节点就保存了字典中的一个键值对。 哈希表：由dict.h/dictht结构定义： 1234567891011typedef struct dictht&#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于size-1 unsigned long sizemask; //该哈希表已有节点数量 unsigned long user;&#125; table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存一个键值对。size属性记录了哈希表的大小，也即是table数组的大小，而used属性则记录了哈希表目前已有节点的数量，sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放在table数组的哪个索引上面。 哈希表节点：使用dictEntry结构，每个dictEntry结构都保存一个键值对。 123456789101112typedef struct dictEntry&#123; //键 void *key; //值 union&#123; void *val; uint64_t u64; unt64_t s64; &#125;v; //指向下个哈希表节点，形成链表 strcut dictEntry *next;&#125;dictEntry; key属性保存键，v属性保存值，可以是指针、uint64_t、uint64_t。 next属性指向另一个哈希表节点指针，解决哈希冲突。 字典：由dict.h/dict结构表示： 1234567891011typedef struct dict&#123; //类型特定函数 sictType *type; //私有数据 void *privtata; //哈希表 dictht ht[2]; //rehash索引 //当rehash不在进行时，值为-1 int trehashidx;/*rehashing not in progress if rehashidx==-1 */&#125;dict; type属性和privdata属性是针对不同的类型的键值对，为创建多态字典而设置的： type属性是一个指向dictType结构的指针，每个dictType结构保存了一簇用于操作特定类型键值对的函数，Redis会为用途不同的字典设置不同的类型特定函数。 privdata属性则保存了需要传给那些类型特定函数的可选参数。 1234567891011121314typedef struct dictType&#123; //计算哈希值的函数 unsigned int (*hashFunction)(const void *key); //复制键的函数 void *(*keyDup)(void *privdata,const void *key); //复制值的函数 void *(*valDup)(void *privdata,const void *obj); //对比键的函数 int (*keyCompare)(void *privdata,const void *key1.const void *key2); //销毁键的函数 void (*keyDestructor)(void *prevdata,void *key); //销毁值的函数 void (*valDestructor)(void *prevdata,void *obj);&#125;dictType； ht属性是一个包含两项的数组，数组的每一项都是一个dictht哈希表，一般，字典只使用ht[0]，ht[1]用于对ht[0]rehash。 哈希算法：Redis计算哈希值和索引值方法： 12345//使用字典设置的哈希函数，计算键key的哈希值hash = dict-&gt;type-&gt;hashFunction(key);//使用哈希值的sizemask属性和哈希值，计算索引//根据情况不同，ht[x]可以是hx[0]或者ht[1]index = hash &amp; dict-&gt;ht[x].sizemask; 解决键冲突：当有两个或者以上数量的键被分配到哈希表数组的同一个索引上面的时候，产生了冲突。 使用链地址法来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上的多个节点可以用这个单向链表连接起来，从而解决键冲突。 新节点总是添加到链表的表头位置（复杂度为O(1)） rehash:扩展和收缩哈希表通过rehash（重新散列）完成 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量（也即是ht[0].used属性值） 如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2^n值 如果执行的收缩，那么ht[1]的大小是第一个大于等于ht[0].used的2^n值 将保存在ht[0]中的所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放在ht[1]哈希表指定位置 当ht[0]包含所有键值对都迁移到ht[1]后，释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新建一个空白哈希表，为下一次rehash做准备。 哈希表的扩展与收缩：哈希表的负载因子=哈希表已保存节点数量/哈希表大小 渐进式rehash为了避免rehash对服务器性能造成影响，服务器不是一次性将ht[0]里面的所有键值对全部rehash到ht[1],二十分多次、渐进式地将ht[0]里面的键值对慢慢rehash。 在渐进式rehash进行期间，字典的删除、查找、更新等操作会在两个哈希表进行 渐进式rehash期间，新添加到字典的键值对一律会保存到ht[1]中","tags":[{"name":"Redis","slug":"Redis","permalink":"http://ylovex.cn/tags/Redis/"}]},{"title":"Redis设计与实现笔记二","date":"2019-07-03T04:52:07.000Z","path":"2019/07/03/Redis设计与实现笔记二/","text":"链表：链表和链表节点的实现：链表节点使用一个adlist.h/listNode结构表示： 12345678typedef struct listNode&#123; //前置节点 struct listNode *prev; //后置节点 struct listNode *next; //节点的值 void *value;&#125;listNode; 多个listNode可以通过prev和next指针组成双端链表。 使用adlist.h/list来持有链表。 1234567891011121314typedef struct list&#123; //表头节点 listNode *head; //表尾节点 listNode *tail; //链表所包含的节点数量 unsigned long len; //节点值复制函数 void *(*dup)(void *ptr); //节点值释放函数 void *(*free)(void *ptr); //节点值对比函数 int (*match)(void *pre , void *key);&#125;list; 上图是一个由list结构和三个listNode结构组成的链表。 Redis链表实现特性: 双端：链表节点带有prev和next指针，获取某个节点的前置和后置复杂度都是O(1) 无环：表头节点的prev和表尾的next都指向NULL，对链表访问都以NULL为终点 带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点都是O(1) 带链表长度计数器：获取链表中节点数量的复杂度为O(1) 多态：链表节点使用void* 指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://ylovex.cn/tags/Redis/"}]},{"title":"nowcoder-骰子游戏","date":"2019-07-01T23:37:01.000Z","path":"2019/07/02/nowcoder-骰子游戏/","text":"题目来源：https://www.nowcoder.com/practice/0e83797c34e54cca91179fe9ad681bc4?tpId=90&amp;tqId=30849&amp;tPage=4&amp;rp=4&amp;ru=%2Fta%2F2018test&amp;qru=%2Fta%2F2018test%2Fquestion-ranking 题目描述：小易参加了一个骰子游戏,这个游戏需要同时投掷n个骰子,每个骰子都是一个印有数字1~6的均匀正方体。小易同时投掷出这n个骰子,如果这n个骰子向上面的数字之和大于等于x,小易就会获得游戏奖励。小易想让你帮他算算他获得奖励的概率有多大。 思路：12345动态规划，用dp[i][j]表示i个骰子产生数字和j的结果数，初始值dp[1][j]=1(j=1~6),dp[i] [i]=1,dp[i][6*i]=1,由于第i个骰子的点数可以为1~6，要使i个骰子的数字和为j的话，则前i-1个骰子的数字和可以为j-1~j-6，所以得到公式dp[i][j] +=dp[i-1][j-k] (k=1~6)。 参考代码：1234567891011121314151617181920212223242526272829public class Now_73 &#123; public static void main(String[] args) &#123; Scanner sc=new Scanner(System.in); int n=sc.nextInt(); int x=sc.nextInt(); if(n&gt;=x) System.out.print(1); else if(6*n&lt;x) System.out.print(0); else &#123; long[][] dp=new long[n+1][6*n+1]; for(int i=1;i&lt;=6;i++) dp[1][i]=1; for(int i=2;i&lt;=n;i++) &#123; for(int j=i;j&lt;=6*n;j++) &#123; for(int k=1;k&lt;j&amp;&amp;k&lt;=6;k++) &#123; dp[i][j]+=dp[i-1][j-k]; &#125; &#125; &#125; long total=(long)Math.pow(6,n); long sum=0; for(int i=1;i&lt;x;i++) sum+=dp[n][i]; long num=gcd(total-sum,total); System.out.print((total-sum)/num+\"/\"+total/num); &#125; &#125; private static long gcd(long a,long b) &#123; return (a%b==0)?b:gcd(b,a%b);//求最大公约数 &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://ylovex.cn/tags/code/"},{"name":"dp","slug":"dp","permalink":"http://ylovex.cn/tags/dp/"}]},{"title":"Redis设计与实现笔记一","date":"2019-07-01T13:33:42.000Z","path":"2019/07/01/Redis设计与实现笔记一/","text":"简单动态字符串：Redis并没有直接使用C语音传统的字符串（以空字符串结尾的字符数组），而是构建了一种名为简单动态字符串（simple dynamic string ， SDS）的抽象类型。 每个sds.h/sdshdr结构表示一个SDS值： 1234567891011struct sdshdr&#123; //记录buf数组中已使用字节的数量 //等于SDS所保存字符串的长度 int len; //记录buf数组中未使用字节的数量 int free; //字节数组，用于保存字符串 char buf[];&#125;; 下图展示了一个SDS示例： 其中： free属性的值为0，表示这个SDS没有分配任何未使用的空间 len属性的值为5，表示这个SDS保存一个5字节长的字符串 buf属性是一个char类型的数组，最后以空字符‘\\0’。 SDS遵循C字符串以空字符结尾的惯例，保存的空字符的1字节不计算在SDS的len属性中，并且为空字符分配额外的1字节空间，以及添加空字符到字符末尾等操作都是SDS自动完成，对使用者完成透明，遵循空字符结尾可以重用一部分C字符串函数库里面的函数。 SDS优点：常数复杂度获取字符串的长度：通过使用SDS而不是C字符串，Redis将获取字符串长度所需要的复杂度从O(n)降低到了O(1)。 杜绝缓冲区溢出：当SDS API需要对SDS进行修改时候，API会先检查SDS空间是否满足修改所需的要求，如果不满足的话，API会自动将SDS空间扩展至执行修改所需的大小，然后才执行实际的修改操作。 减少修改字符串时候带来的内存重分配次数：对于一个包含N个字符的C字符串，这个C字符串的底层实现总是一个N+1个字符长的数组（额外的一个字符空间用于保存空字符），因为C字符串的长度和底层数组的长度之间存在这种关联，所以每次增长或者缩短一个C字符串，程序都总要对保存这个C字符串的数组进行一个内存重分配操作： 如果程序执行的是增长字符串操作，比如拼接（append），那么在执行这个操作之前，程序需要先通过内存重分配来扩展底层数组的空间大小—如果忘了这一步就会产生缓冲区溢出。 如果程序执行的就是缩短字符串操作，比如截断（trim），那么在执行这个操作之后，程序需要通过内存重分配来释放字符串不再使用的那部分空间—如果忘了这步就会产生内存泄漏。 为了避免C字符串这种缺陷，SDS通过未使用空间解除了字符串长度和底层数组长度的关联，在SDS中，buf数组的长度不一定是字符数量加一，数组里面可以包含未使用的字节，而这个未使用的字节由SDS的free属性记录。 通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略。 空间预分配：空间预分配用于优化SDS字符串增长操作：当SDS的API对一个SDS进行修改，并且需要对SDS进行空间扩展的时候，程序不仅会为SDS分配修改所必须的空间的时候，还会为SDS分配额外的未使用空间。 其中，额外分配的未使用空间数量由以下公式决定： 如果对SDS进行修改之后，SDS的的长度将小于1MB，那么程序分配和len属性同样大小的未使用空间。 如何对SDS进行修改后，SDS的长度将大于等于1MB，那么程序会分配1MB的未使用空间。 通过空间预分配策略，Redis可以减少连续执行字符串增长操作所需要的内存重分配次数。 惰性空间释放：惰性空间释放用于优化SDS字符串缩短操作：当SDS的API需要缩短的SDS保存的字符串时候，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节数量记录起来，并等到将来使用。 二进制安全：C字符中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使C字符只能保存文本数据，不能保存像图像、音频、视频、压缩文件这样的二进制数据。 SDS的API都是二进制安全的，所有SDS API都会处理二进制的方式来处理SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者假设，数据在写入是什么样，被读取就是什么样。 兼容部分C字符串函数：通过遵循C字符串以空字符结尾的惯例，SDS可以在有需要时重用&lt;string.h&gt;函数库，从而避免了不必要的代码重复。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://ylovex.cn/tags/Redis/"}]},{"title":"jvm自动内存管理机制","date":"2019-06-28T00:11:47.000Z","path":"2019/06/28/jvm自动内存管理机制/","text":"JVM组成：JVM 由类加载器子系统、运行时数据区、执行引擎以及本地方法接口组成。 运行时数据区域：Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。 程序计数器：是当前线程所执行的字节码的行号指示器。字节码解释器工作时候通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复都依赖该计数器。 线程私有，此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况区域。 Java虚拟机栈：存储局部变量表、操作数栈、动态链接、方法出口等信息。 线程私有。 局部变量表存放编译期可知的各种基本数据类型、对象引用和returnAddress类型（指向一条字节码指令地址）。 其中64位长度的long和double类型数据占用2个局部变量空间（slot），其余数据类型只占1个字节。 本地方法栈：虚拟机栈为虚拟机执行Java方法（字节码）服务，本地方法栈为虚拟机使用Native方法服务。 Java堆：存放对象实例，是垃圾收集器管理的主要区域。 线程共享。 方法区：存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 线程共享。 运行时常量池：是方法区的一部分。具有动态性，不仅预置入Class文件中常量池的内容可以进入方法区运行时常量池，运行期间也可以将新的常量放入池中。 对象的创建： 虚拟机遇到一条new指令时，会先去常量池检测能否找到new对应的类的符号引用，并检测这个类是否加载、初始化。 如果加载检查通过，则分配内存。分配内存有两种方式：⑴指针碰撞，针对连续内存区域；⑵空闲列表，针对不连续内存区域 内存分配完之后，会对内存初始化零值，保证实例字段能在java代码不赋初值也能使用。 接下来对对象信息进行设置，把类的元数据信息、对象的哈希吗、对象的GC分代年龄等信息存放在对象头之中 最后执行用户的Init方法 对象的内存布局： 分为三部分，对象头、实例数据、对齐填充 对象头：⑴对象自身运行时数据，如哈希吗、GC分代年龄、锁状态标志、线程持有的锁等。⑵类型指针，虚拟机通过这个来确定这个对象是哪个类的实例。⑶如果对象是一个Java数组，那么对象头中还必须有一块用于记录数组长度的数据。 实例数据：对象真正存储的有效信息，也是在程序代码中定义的各种类型的字段内容。 对齐填充：JVM要求对象的起始地址必须是8字节的整数倍，因此当对象实例数据没有对齐时，这部分来补全。 对象的访问定位：使用句柄访问：Java堆中会划分一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 直接指针访问：那么Java堆对象的布局中就必须考虑如何放置访问类型数据的 相关信息，而reference中存储的直接就是对象地址 Java垃圾回收区域： Java垃圾回收只针对堆和方法区的内存。 程序计数器、虚拟机栈、本地方法栈随线程而生，随线程而灭，因此不用管。 如何确认垃圾：引用计数算法：给对象中添加一个引用计数器，每当有 一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器为0 的对象就是不可能再被使用的。 可达性分析算法：这个算法的基本思 路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），当一个对象到GC Roots没有任何引用链相连 （用图论的话来说，就是从GC Roots到这个对象不可达）时，则证明此对象是不可用的。如图所示，对象object 5、object 6、object 7虽然互相有关联，但是它们到GC Roots是不可达 的，所以它们将会被判定为是可回收的对象。 可作为GC Roots对象有： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。 垃圾回收算法：标记-清除算法：首先标记出所有需要回收的对象，在标记完成后统一回收所有 被标记的对象。 不足有两个：一个是效率问题，标记和清除两个过程的效率都不高；另一个是 空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法：它将可用内存按容 量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着 的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样使得每次都是 对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指 针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原来的一半。 标记-整理算法：标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存 活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集：一般是把Java堆 分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代 中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付 出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间 对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。 JVM GC：枚举根节点要GC就得枚举根节点，如果逐一去检查引用，效率很低。因此JVM使用一组称为OopMap的数据结构，直接知道哪些地方存放着对象引用。 安全点可能导致引用关系、或者说OopMap内容变化的指令非常多，不可能为每一条指令都生成对应的OopMap，因此有了安全点，在安全点才记录OopMap，在安全点才能进行GC，例如方法调用、循环跳转、异常跳转等，具有这些功能的指令才会产生安全点 如何让GC发生时线程都跑到安全点采用主动式中断思想，GC时，不直接对线程操作，而是设置一个中断标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起，轮询标志的地方和安全点是重合的 安全区域如果程序不执行时，比如sleep了，岂不是就进不了安全点？因此有了安全区域，安全区域指在一段代码中，引用关系不会发生变化，在这个区域内GC都是安全的。线程进入安全区域后，会标志自己进入了。JVM要GC时就不会管这些线程。线程要离开安全区域时，必须检查GC是否完成，如果GC完成了线程就继续执行，否则一直等待直到GC完成。 垃圾收集器： Serial收集器：单线程，GC时候需要暂停其他所有的工作线程，直到它收集结束。 JVM运行在Client模式下的默认新生代收集器：简单而高效。 ParNew收集器：Serial收集器的多线程版本。 许多运行在Server模式下虚拟机的首选新生代收集器。 在单CPU环境次啊ParNew不会有比Serial收集器效果更好，Serial和ParNew都是与CMS配合工作。 Parallel Scavenge收集器：新生代收集器，使用复制算法。 关注吞吐量，吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）。 Serial Old收集器：是Seraial收集器的老年代版本，单线程，采用“标记-整理”算法。 Parallel Old收集器：是Parallel Scavenge收集器的老年代版本，“标记-整理”。 CMS收集器：是一种以获取最短回收停顿时间为目标的收集器。 基于“标记-清除”。 初始标记，并发标记，重新标记，并发清除。其中，初始标记、重新标记这两个步骤仍然需要“Stop The World”。初始标记仅仅只是 标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC RootsTracing 的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变 动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远 比并发标记的时间短。 由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起 工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。 缺点：对CPU资源非常敏感、无法处理浮动垃圾、基于“标记-清除”，产生大量空间碎片。 G1收集器：是一款面向服务端应用的垃圾收集器，、并行与并发、分代收集、空间整合、可预测停顿 将整个Java堆划分多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的。 内存分配与回收策略： 对象优先在Eden分配。 老年代GC（Full GC/Major GC）一般比新生代GC（Minor GC）慢10倍以上。 大对象直接进入老年代，大对象指需要大量连续内存空间的Java对象，比如很长的字符串和数组。可通过参数设置。 长期存活的对象将进入老年代。默认15岁。 动态对象年龄判定。如果Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 空间分配担保。当出现大量对象Minor GC后仍然存活的情况，需要老年代进行分配担保，让Survivor无法容纳的对象直接进入老年代。","tags":[{"name":"java","slug":"java","permalink":"http://ylovex.cn/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"http://ylovex.cn/tags/jvm/"}]},{"title":"nowcoder-数位重排","date":"2019-06-18T12:32:06.000Z","path":"2019/06/18/nowcoder-数位重排/","text":"题目来源：https://www.nowcoder.com/practice/f970201e9f7e4040ab25a40918e27d15?tpId=90&amp;tqId=30847&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：牛牛有一个正整数x,牛牛需要把数字x中的数位进行重排得到一个新数(不同于x的数),牛牛想知道这个新数是否可能是原x的倍数。请你来帮他解决这个问题。 思路：题目要求将x中的数位重排得到的新数是否可能是原x的倍数；只需判断x的2到9的倍数中是否存在由x重排后得到的数。 参考代码：123456789101112131415161718192021222324252627282930313233343536public class Now_71&#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); int n = sc.nextInt(); boolean[] booleans = new boolean[n]; for(int i=0;i&lt;n;i++)&#123; booleans[i] = isCheck(sc.nextInt()); &#125; for(int i=0;i&lt;n;i++)&#123; if(booleans[i])&#123; System.out.println(&quot;Possible&quot;); &#125; else &#123; System.out.println(&quot;Impossible&quot;); &#125; &#125; &#125; private static boolean isCheck(int num) &#123; for(int i=2;i&lt;=9;i++)&#123; String s1 = String.valueOf(num*i); String s2 = String.valueOf(num); char[] c1 = s1.toCharArray(); char[] c2 = s2.toCharArray(); if(c1.length != c2.length) continue; Arrays.sort(c1); Arrays.sort(c2); String s3 = String.valueOf(c1); String s4 = String.valueOf(c2); if(s3.equals(s4))&#123; return true; &#125; &#125; return false; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://ylovex.cn/tags/code/"}]},{"title":"数据库基础","date":"2019-06-15T01:30:43.000Z","path":"2019/06/15/数据库基础/","text":"数据库类别关系型数据库关系型数据库模型是把复杂的数据结构归结为简单的二元关系（即二维表格形式）。在关系型数据库中，对数据的操作几乎全部建立在一个或多个关系表格上，通过对这些关联的表格分类、合并、连接或选取等运算来实现数据库的管理。包括：Mysql、Oracle、DB2、Sqlserver 非关系型数据库NoSQL是非关系型数据库的广义定义，如下小结：NOSQL不是否定关系数据库，而是作为关系数据库的一个重要补充。NOSQL为了高性能、高并发而生，忽略影响高性能、高并发的功能。NOSQL典型产品memcached（纯内存），redis（持久化缓存），mongodb（面向文档） 键值存储数据库（key-value） 键值数据库就类似传统语言中使用的哈希表。可以通过key来添加、查询或者删除数据库，因为使用key主键访问，所以会获得很高的性能及扩展性。键值数据库主要使用一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说的优势在于简单、易部署、高并发。典型产品：Memcached、Redis、MemcacheDB: 列存储（Column-oriented）数据库:列存储数据库将数据存储在列族中，一个列族存储经常被一起查询的相关数据，比如人类，我们经常会查询某个人的姓名和年龄，而不是薪资。这种情况下姓名和年龄会被放到一个列族中，薪资会被放到另一个列族中。这种数据库通常用来应对分布式存储海量数据。典型产品：Cassandra、HBase 面向文档（Document-Oriented）数据库:文档型数据库的灵感是来自于Lotus Notes办公软件，而且它同第一种键值数据库类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可以 看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。面向文档数据库会将数据以文档形式存储。每个文档都是自包含的数据单元，是一系列数据项的集合。每个数据项都有一个名词与对应值，值既可以是简单的数据类型，如字符串、数字和日期等；也可以是复杂的类型，如有序列表和关联对象。数据存储的最小单位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用XML、JSON或JSONB等多种形式存储。典型产品：MongoDB、CouchDB 图形数据库图形数据库允许我们将数据以图的方式存储。实体会被作为顶点，而实体之间的关系则会被作为边。比如我们有三个实体，Steve Jobs、Apple和Next，则会有两个“Founded by”的边将Apple和Next连接到Steve Jobs。典型产品：Neo4J、InforGrid 关系型和非关系型数据库区别关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织。优点： 易于维护：都是使用表结构，格式一致； 使用方便：SQL语言通用，可用于复杂查询； 复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。 缺点： 读写性能比较差，尤其是海量数据的高效率读写； 固定的表结构，灵活度稍欠； 不能满足高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。 非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方式的集合，可以是文档或者键值对等。 优点： 格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。 速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘； 高扩展性； 成本低：nosql数据库部署简单，基本都是开源软件。 缺点： 不提供sql支持，学习和使用成本较高； 无事务处理； 数据结构相对复杂，复杂查询方面稍欠。 Innodb和MyIASM：区别： MyIASM是非事务安全的，而InnoDB是事务安全的 MyIASM锁的粒度是表级的，而InnoDB支持行级锁 MyIASM不支持外键，InnoDB支持外键 MyIASM支持全文类型（FullText）索引，而InnoDB不支持全文类型索引 MyIASM保存了表的行数，InnDB没有保存表的行数 MyIASM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyIASM 应用场景： InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量insert和update操作，应该选择InnoDB MyIASM管理非事务表，提供高速存储和检索以及全文搜索能力，如果再应用中执行大量select操作，应该选择MyIASM 对于一般的Web应用来说，应该选择MyIASM，效率更高，特定场景再用InnoDB 数据库三大范式：第一范式（1NF）即表中的列的具有原子性，不可再分解，即列的信息，不能分解, 只要数据库是关系型数据库(MySQL/oracle/db2 /SQL server)，就自动的满足1NF。数据库表的每一列都是不可分割的原子数据项，而不能是集合，数组，记录等非原子数据项。如果实体中的某个属性有多个值时，必须拆分为不同的属性。通俗理解即一个字段只存储一项信息。 第二范式（2NF）第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被唯一地区分。为实现区分通常需要我们设计一个主键来实现。 第三范式（3NF）满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中定义的非主键字段 事务满足ACID条件：原子性、一致性、隔离性、持久性 原子性：一个事务中的所有操作，要么全部完成，要么全部不完成 一致性：在事务开始之前和结束后，数据库的完整性没有被破坏 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。 持久性：事务结束之后，事务的结果是持久性的，即使断电结果也能保存下来 事务处理主要方法： 用BEGIN、ROLLBACK、COMMIT实现，BEGIN开始一个事务、ROLLBACK事务回滚、COMMIT事务确认 直接用SET来改变MySQL的自动提交模式，SET AUTHCOMMIT=0禁止自动提交、SET AUTHCOMMIT=1开启自动提交 隔离级别Read Uncommitted读未提交就是其他事务做到一半还未提交的数值可以被读出来 脏读：事务可以读取未提交的数据 Read Committed读已提交就是读取其他事务提交后的数值，比如B事务修改了某数据后还没有提交的话，A事务看到的值仍然是修改之前的数值。 可避免脏读的发生 Repeatable Read可重复读就是在开始读取数据（A事务开启）时候，即使其他事务修改了数据，但A事务读到的数据不管读几次都是不变的 可避免脏读、不可重复读的发生：不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了 幻读：可重复读可能产生幻读，A事务开始准备插入一条记录id=6，B事务同时开始并成功插入一条记录id=6，此时A执行插入id=6操作，结果插入失败，因为id=6记录已经存在，这就是幻读。Innodb通过多版本并发控制(MVCC)解决了幻读问题。 Serializable读加共享锁，写加排他锁 以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式（类似于Java多线程中的锁）使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read（可重复读）。 事务回滚机制事务是用户定义的一个数据库操作序列，这些操作要么全做要么全不做，是一个不可分割的工作单位，事务回滚是指将该事务已经完成的对数据库的更新操作撤销。 要同时修改数据库中两个不同表时，如果它们不是一个事务的话，当第一个表修改完，可能第二个表修改过程中出现了异常而没能修改，此时就只有第二个表依旧是未修改之前的状态，而第一个表已经被修改完毕。而当你把它们设定为一个事务的时候，当第一个表修改完，第二表修改出现异常而没能修改，第一个表和第二个表都要回到未修改的状态，这就是所谓的事务回滚 锁数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。 加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。 锁分类： 按操作划分：DML锁，DDL锁 按锁的粒度划分：表级锁、行级锁、页级锁 按锁级别划分：共享锁、排他锁 按加锁方式划分：自动锁、显示锁 按使用方式划分：乐观锁、悲观锁 悲观锁：顾名思义，就是很悲观，每次去拿（取）数据的时候都认为别人会修改，所以每次在拿（取）数据的时候都会上锁，这样别人想拿这个数据就会block（阻塞）直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 悲观锁优缺点：悲观并发控制(悲观锁)采用”先取锁再分”的保守策略，为数据处理提供了安全的保证。但在效率方面，加锁机制会产生额外的开销，增加产生死锁的机会。 乐观锁：乐观锁的机制就是CAS，版本保护就是CAS中的期望值 CAS顾名思义，就是很乐观，每次去拿（取）数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，并发量不是很高的时候可以用，并发量高时，比如抢票，数据就存在Redis这类内存中了，就不存mysql了，mysql太慢了。 乐观锁优缺点：乐观锁认为事务直接竞争的概率是很小的，在提交的时候才锁定，所以不会产生死锁。但是如果两个事务同时写入数据库的某一行，这时，就会发现乐观锁的弊端。 行级锁：行级锁分为共享锁和排它锁。行级锁是Mysql中锁定粒度最细的锁。InnoDB引擎支持行级锁和表级锁，只有在通过索引条件检索数据的时候，才使用行级锁，否就使用表级锁。行级锁开销大，加锁慢，锁定粒度最小，发生锁冲突概率最低，并发度最高 表级锁：表级锁分为表共享锁和表独占锁。表级锁开销小，加锁快，锁定粒度大、发生锁冲突最高，并发度最低 页级锁：页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁。开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 排它锁(exclusive locck)：排它锁又叫写锁，如果事务T对A加上排它锁，则其它事务都不能对A加任何类型的锁。获准排它锁的事务既能读数据，又能写数据。 共享锁(share lock)：共享锁又叫读锁，如果事务T对A加上共享锁，则其它事务只能对A再加共享锁，不能加其它锁。获准共享锁的事务只能读数据，不能写数据。 InnoDB：支持行级锁和表级锁，默认是行级锁 MyISAM &amp;Memory：这两个存储引擎都是采用表级锁 锁优化： 读写分离 分段加锁 减少锁持有的时间 多个线程尽量以相同的顺序去获取资源 Innodb多版本并发控制（MVCC）可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制所有不同，但大都实现了非阻塞的读操作，写操作也只锁定必要的行。 InnoDB的MVCC，是通过在每行纪录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存了行的过期时间，（存储的并不是实际的时间值，而是系统版本号）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行纪录的版本号进行比较。 MYSQL索引类型MySQL目前主要有以下几种索引类型：普通索引、唯一索引、主键索引、组合索引、全文索引。 普通索引：仅加速查询 唯一索引：加速查询 + 列值唯一（可以有null） 主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 全文索引：对文本的内容进行分词，进行搜索 普通索引-是最基本的索引，它没有任何限制。它有以下几种创建方式： 123456789101112131415直接创建索引CREATE INDEX index_name ON table(column(length))修改表结构的方式添加索引ALTER TABLE table_name ADD INDEX index_name ON (column(length))创建表的时候同时创建索引CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`), INDEX index_name (title(length)))删除索引 DROP INDEX index_name ON table 唯一索引-与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式： 123456789101112创建唯一索引 CREATE UNIQUE INDEX indexName ON table(column(length))修改表结构 ALTER TABLE table_name ADD UNIQUE indexName ON (column(length))创建表的时候直接指定CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , UNIQUE indexName (title(length))); 主键索引-是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引： 12345CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) NOT NULL , PRIMARY KEY (`id`)); 组合索引-指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合。 1ALTER TABLE `table` ADD INDEX name_city_age (name,city,age); 全文索引-主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。 12345678910111213创建表的适合添加全文索引CREATE TABLE `table` ( `id` int(11) NOT NULL AUTO_INCREMENT , `title` char(255) CHARACTER NOT NULL , `content` text CHARACTER NULL , `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`), FULLTEXT (content));修改表结构添加全文索引ALTER TABLE article ADD FULLTEXT index_content(content)直接创建索引CREATE FULLTEXT INDEX index_content ON article(content) 索引的作用和优缺点索引就一种特殊的查询表，数据库的搜索引擎可以利用它加速对数据的检索。它很类似与现实生活中书的目录，不需要查询整本书内容就可以找到想要的数据。索引可以是唯一的，创建索引允许指定单个列或者是多个列。缺点是它减慢了数据录入（插入、删除、更新表）的速度，同时也增加了数据库的尺寸大小。 优点： 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 可以大大加快数据的检索速度。 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 缺点： 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 索引需要占物理空间，除了数据表占物理空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存索引文件。 如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。 不建议使用索引情况： 数据唯一性差的字段不要使用索引：比如性别，只有两种可能数据。意味着索引的二叉树级别少，多是平级。这样的二叉树查找无异于全表扫描。 频繁更新的字段不要使用索引：比如logincount登录次数，频繁变化导致索引也频繁变化，增大数据库工作量，降低效率。 字段不在where语句出现时不要添加索引：只有在where语句出现，mysql才会去使用索引 数据量少的表不要使用索引：使用了改善也不大 另外，如果mysql估计使用全表扫描要比使用索引快，则不会使用索引。 索引、主键索引、唯一索引、组合索引索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。 普通索引(由关键字KEY或INDEX定义的索引)的唯一任务是加快对数据的访问速度。 普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。 主键，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，不允许有空值，使用关键字 PRIMARY KEY 来创建。 索引可以覆盖多个数据列，如像INDEX(columnA, columnB)索引，这就是组合索引。 索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度，因为在执行这些写操作时，还要操作索引文件。 主键、外键、唯一索引定义： 主键–唯一标识一条记录，不能有重复的，不允许为空 外键–表的外键是另一表的主键, 外键可以有重复的, 可以是空值 唯一索引–该字段没有重复值，但可以有一个空值 作用： 主键–用来保证数据完整性 外键–用来和其他表建立联系用的 唯一索引–是提高查询排序的速度 个数： 主键–主键只能有一个 外键–一个表可以有多个外键 唯一索引–一个表可以有多个唯一索引 MySQL索引原理MySQL支持诸多存储引擎，而各种存储引擎对索引的支持也各不相同，因此MySQL数据库支持多种索引类型，如BTree索引，B+Tree索引，哈希索引，全文索引等等 哈希索引只有memory（内存）存储引擎支持哈希索引，哈希索引用索引列的值计算该值的hashCode，然后在hashCode相应的位置存执该值所在行数据的物理位置，因为使用散列算法，因此访问速度非常快，但是一个值只能对应一个hashCode，而且是散列的分布方式，因此哈希索引不支持范围查找和排序的功能。 全文索引FULLTEXT（全文）索引，仅可用于MyISAM和InnoDB，针对较大的数据，生成全文索引非常的消耗时间和空间。对于文本的大对象，或者较大的CHAR类型的数据，如果使用普通索引，那么匹配文本前几个字符还是可行的，但是想要匹配文本中间的几个单词，那么就要使用LIKE %word%来匹配，这样需要很长的时间来处理，响应时间会大大增加，这种情况，就可使用时FULLTEXT索引了，在生成FULLTEXT索引时，会为文本生成一份单词的清单，在索引时及根据这个单词的清单来索引。FULLTEXT可以在创建表的时候创建，也可以在需要的时候用ALTER或者CREATE INDEX来添加： 123456789//创建表的时候添加FULLTEXT索引CTREATE TABLE my_table(id INT(10) PRIMARY KEY,name VARCHAR(10) NOT NULL,my_text text CHARACTER SET utf8 COLLATE utf8_general_ci NULL,FULLTEXT(my_text));//创建表以后，在需要的时候添加FULLTEXT索引ALTER my_table ADD FULLTEXT ft_index(my_text);CREATE INDEX ft_index ON my_table(my_text); 对于较大的数据集，把数据添加到一个没有FULLTEXT索引的表，然后添加FULLTEXT索引的速度比把数据添加到一个已经有FULLTEXT索引的表快。 MySQL自带的全文索引只能用于MyISAM存储引擎，如果是其它数据引擎，那么全文索引不会生效。 在MySQL中，全文索引支队英文有用，目前对中文还不支持。 在MySQL中，如果检索的字符串太短则无法检索得到预期的结果，检索的字符串长度至少为4字节，此外，如果检索的字符包括停止词，那么停止词会被忽略。 BTree索引和B+Tree索引BTree索引BTree是平衡搜索多叉树，设树的度为d（d&gt;1），高度为h，那么BTree要满足以一下条件： 每个叶子结点的高度一样，等于h； 每个非叶子结点由n-1个key和n个指针point组成，其中d&lt;=n&lt;=2d,key和point相互间隔，结点两端一定是key； 叶子结点指针都为null； 非叶子结点的key都是[key,data]二元组，其中key表示作为索引的键，data为键值所在行的数据； 在BTree的机构下，就可以使用二分查找的查找方式，查找复杂度为h*log(n)，一般来说树的高度是很小的，一般为3左右，因此BTree是一个非常高效的查找结构。 B+Tree索引B+Tree是BTree的一个变种，设d为树的度数，h为树的高度，B+Tree和BTree的不同主要在于： B+Tree中的非叶子结点不存储数据，只存储键值； B+Tree的叶子结点没有指针，所有键值都会出现在叶子结点上，且key存储的键值对应的数据的物理地址； 一般来说B+Tree比BTree更适合实现外存的索引结构，因为存储引擎的设计专家巧妙的利用了外存（磁盘）的存储结构，即磁盘的一个扇区是整数倍的page（页），页是存储中的一个单位，通常默认为4K，因此索引结构的节点被设计为一个页的大小，然后利用外存的“预读取”原则，每次读取的时候，把整个节点的数据读取到内存中，然后在内存中查找，已知内存的读取速度是外存读取I/O速度的几百倍，那么提升查找速度的关键就在于尽可能少的磁盘I/O，那么可以知道，每个节点中的key个数越多，那么树的高度越小，需要I/O的次数越少，因此一般来说B+Tree比BTree更快，因为B+Tree的非叶节点中不存储data域，就可以存储更多的key。带顺序索引的B+TREE。很多存储引擎在B+Tree的基础上进行了优化，添加了指向相邻叶节点的指针，形成了带有顺序访问指针的B+Tree，这样做是为了提高区间查找的效率，只要找到第一个值那么就可以顺序的查找后面的值。 SQL常见语句数据库 12345678# 查看所有的数据库SHOW DATABASES ;# 创建一个数据库CREATE DATABASE name;# 删除一个数据库DROP DATABASE name;# 使用这个数据库USE name; 表 12345678910111213141516171819202122232425262728# 查看所有的表SHOW TABLES ;# 创建一个表CREATE TABLE n(id INT, name VARCHAR(10));CREATE TABLE m(id INT, name VARCHAR(10), PRIMARY KEY (id), FOREIGN KEY (id) REFERENCES n(id), UNIQUE (name));CREATE TABLE m(id INT, name VARCHAR(10));# 直接将查询结果导入或复制到新创建的表CREATE TABLE n SELECT * FROM m;# 新创建的表与一个存在的表的数据结构类似CREATE TABLE m LIKE n;# 创建一个临时表# 临时表将在你连接MySQL期间存在。当断开连接时，MySQL将自动删除表并释放所用的空间。也可手动删除。CREATE TEMPORARY TABLE l(id INT, name VARCHAR(10));# 直接将查询结果导入或复制到新创建的临时表CREATE TEMPORARY TABLE tt SELECT * FROM n;# 删除一个存在表DROP TABLE IF EXISTS m;# 更改存在表的名称ALTER TABLE n RENAME m;RENAME TABLE n TO m;# 查看表的结构(以下五条语句效果相同）DESC n; # 因为简单，所以建议使用（DESC表示descend降序，ASC表示ascend升序）DESCRIBE n; #（discribe）SHOW COLUMNS IN n;SHOW COLUMNS FROM n;EXPLAIN n;# 查看表的创建语句SHOW CREATE TABLE n; 表的结构 12345678# 添加字段ALTER TABLE n ADD age VARCHAR(2) ;# 删除字段ALTER TABLE n DROP age;# 更改字段属性和属性ALTER TABLE n CHANGE age a INT;# 只更改字段属性ALTER TABLE n MODIFY age VARCHAR(7) ; 表的数据 1234567891011# 增加数据INSERT INTO n VALUES (1, &apos;tom&apos;, &apos;23&apos;), (2, &apos;john&apos;, &apos;22&apos;);INSERT INTO n SELECT * FROM n; # 把数据复制一遍重新插入# 删除数据DELETE FROM n WHERE id = 2;# 更改数据UPDATE n SET name = &apos;tom&apos; WHERE id = 2;# 数据查找SELECT * FROM n WHERE name LIKE &apos;%h%&apos;;# 数据排序(反序)SELECT * FROM n ORDER BY name, id DESC ; 键 12345678910111213141516171819202122232425# 添加主键ALTER TABLE n ADD PRIMARY KEY (id);ALTER TABLE n ADD CONSTRAINT pk_n PRIMARY KEY (id); # 主键只有一个，所以定义键名似乎也没有什么用# 删除主键ALTER TABLE n DROP PRIMARY KEY ;# 添加外键ALTER TABLE m ADD FOREIGN KEY (id) REFERENCES n(id); # 自动生成键名m_ibfk_1ALTER TABLE m ADD CONSTRAINT fk_id FOREIGN KEY (id) REFERENCES n(id); # 使用定义的键名fk_id# 删除外键ALTER TABLE m DROP FOREIGN KEY `fk_id`;# 修改外键ALTER TABLE m DROP FOREIGN KEY `fk_id`, ADD CONSTRAINT fk_id2 FOREIGN KEY (id) REFERENCES n(id); # 删除之后从新建# 添加唯一键ALTER TABLE n ADD UNIQUE (name);ALTER TABLE n ADD UNIQUE u_name (name);ALTER TABLE n ADD UNIQUE INDEX u_name (name);ALTER TABLE n ADD CONSTRAINT u_name UNIQUE (name);CREATE UNIQUE INDEX u_name ON n(name);# 添加索引ALTER TABLE n ADD INDEX (age);ALTER TABLE n ADD INDEX i_age (age);CREATE INDEX i_age ON n(age);# 删除索引或唯一键DROP INDEX u_name ON n;DROP INDEX i_age ON n; 视图 12345678910111213# 创建视图CREATE VIEW v AS SELECT id, name FROM n;CREATE VIEW v(id, name) AS SELECT id, name FROM n;# 查看视图(与表操作类似)SELECT * FROM v;DESC v;# 查看创建视图语句SHOW CREATE VIEW v;# 更改视图CREATE OR REPLACE VIEW v AS SELECT name, age FROM n;ALTER VIEW v AS SELECT name FROM n ;# 删除视图DROP VIEW IF EXISTS v; 链接 12345678910111213# 内联接SELECT * FROM m INNER JOIN n ON m.id = n.id;# 左外联接SELECT * FROM m LEFT JOIN n ON m.id = n.id;# 右外联接SELECT * FROM m RIGHT JOIN n ON m.id = n.id;# 交叉联接SELECT * FROM m CROSS JOIN n; # 标准写法SELECT * FROM m, n;# 类似全连接full join的联接用法SELECT id,name FROM mUNIONSELECT id,name FROM n; 函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# 聚合函数SELECT count(id) AS total FROM n; # 总数SELECT sum(age) AS all_age FROM n; # 总和SELECT avg(age) AS all_age FROM n; # 平均值SELECT max(age) AS all_age FROM n; # 最大值SELECT min(age) AS all_age FROM n; # 最小值# 数学函数SELECT abs(-5); # 绝对值SELECT bin(15), oct(15), hex(15); # 二进制，八进制，十六进制SELECT pi(); # 圆周率3.141593SELECT ceil(5.5); # 大于x的最小整数值6SELECT floor(5.5); # 小于x的最大整数值5SELECT greatest(3,1,4,1,5,9,2,6); # 返回集合中最大的值9SELECT least(3,1,4,1,5,9,2,6); # 返回集合中最小的值1SELECT mod(5,3); # 余数2SELECT rand(); # 返回０到１内的随机值，每次不一样SELECT rand(5); # 提供一个参数(种子)使RAND()随机数生成器生成一个指定的值。SELECT round(1415.1415); # 四舍五入1415SELECT round(1415.1415, 3); # 四舍五入三位数1415.142SELECT round(1415.1415, -1); # 四舍五入整数位数1420SELECT truncate(1415.1415, 3); # 截短为3位小数1415.141SELECT truncate(1415.1415, -1); # 截短为-1位小数1410SELECT sign(-5); # 符号的值负数-1SELECT sign(5); # 符号的值正数1SELECT sqrt(9); # 平方根3SELECT sqrt(9); # 平方根3# 字符串函数SELECT concat(&apos;a&apos;, &apos;p&apos;, &apos;p&apos;, &apos;le&apos;); # 连接字符串-appleSELECT concat_ws(&apos;,&apos;, &apos;a&apos;, &apos;p&apos;, &apos;p&apos;, &apos;le&apos;); # 连接用&apos;,&apos;分割字符串-a,p,p,leSELECT insert(&apos;chinese&apos;, 3, 2, &apos;IN&apos;); # 将字符串&apos;chinese&apos;从3位置开始的2个字符替换为&apos;IN&apos;-chINeseSELECT left(&apos;chinese&apos;, 4); # 返回字符串&apos;chinese&apos;左边的4个字符-chinSELECT right(&apos;chinese&apos;, 3); # 返回字符串&apos;chinese&apos;右边的3个字符-eseSELECT substring(&apos;chinese&apos;, 3); # 返回字符串&apos;chinese&apos;第三个字符之后的子字符串-ineseSELECT substring(&apos;chinese&apos;, -3); # 返回字符串&apos;chinese&apos;倒数第三个字符之后的子字符串-eseSELECT substring(&apos;chinese&apos;, 3, 2); # 返回字符串&apos;chinese&apos;第三个字符之后的两个字符-inSELECT trim(&apos; chinese &apos;); # 切割字符串&apos; chinese &apos;两边的空字符-&apos;chinese&apos;SELECT ltrim(&apos; chinese &apos;); # 切割字符串&apos; chinese &apos;两边的空字符-&apos;chinese &apos;SELECT rtrim(&apos; chinese &apos;); # 切割字符串&apos; chinese &apos;两边的空字符-&apos; chinese&apos;SELECT repeat(&apos;boy&apos;, 3); # 重复字符&apos;boy&apos;三次-&apos;boyboyboy&apos;SELECT reverse(&apos;chinese&apos;); # 反向排序-&apos;esenihc&apos;SELECT length(&apos;chinese&apos;); # 返回字符串的长度-7SELECT upper(&apos;chINese&apos;), lower(&apos;chINese&apos;); # 大写小写 CHINESE chineseSELECT ucase(&apos;chINese&apos;), lcase(&apos;chINese&apos;); # 大写小写 CHINESE chineseSELECT position(&apos;i&apos; IN &apos;chinese&apos;); # 返回&apos;i&apos;在&apos;chinese&apos;的第一个位置-3SELECT position(&apos;e&apos; IN &apos;chinese&apos;); # 返回&apos;i&apos;在&apos;chinese&apos;的第一个位置-5SELECT strcmp(&apos;abc&apos;, &apos;abd&apos;); # 比较字符串，第一个参数小于第二个返回负数- -1SELECT strcmp(&apos;abc&apos;, &apos;abb&apos;); # 比较字符串，第一个参数大于第二个返回正数- 1# 时间函数SELECT current_date, current_time, now(); # 2018-01-13 12:33:43 2018-01-13 12:33:43SELECT hour(current_time), minute(current_time), second(current_time); # 12 31 34SELECT year(current_date), month(current_date), week(current_date); # 2018 1 1SELECT quarter(current_date); # 1SELECT monthname(current_date), dayname(current_date); # January SaturdaySELECT dayofweek(current_date), dayofmonth(current_date), dayofyear(current_date); # 7 13 13# 控制流函数SELECT if(3&gt;2, &apos;t&apos;, &apos;f&apos;), if(3&lt;2, &apos;t&apos;, &apos;f&apos;); # t fSELECT ifnull(NULL, &apos;t&apos;), ifnull(2, &apos;t&apos;); # t 2SELECT isnull(1), isnull(1/0); # 0 1 是null返回1，不是null返回0SELECT nullif(&apos;a&apos;, &apos;a&apos;), nullif(&apos;a&apos;, &apos;b&apos;); # null a 参数相同或成立返回null，不同或不成立则返回第一个参数SELECT CASE 2 WHEN 1 THEN &apos;first&apos; WHEN 2 THEN &apos;second&apos; WHEN 3 THEN &apos;third&apos; ELSE &apos;other&apos; END ; # second# 系统信息函数SELECT database(); # 当前数据库名-testSELECT connection_id(); # 当前用户id-306SELECT user(); # 当前用户-root@localhostSELECT version(); # 当前mysql版本SELECT found_rows(); # 返回上次查询的检索行数 用户 1234567891011121314151617# 增加用户CREATE USER &apos;test&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;test&apos;;INSERT INTO mysql.user(Host, User, Password) VALUES (&apos;localhost&apos;, &apos;test&apos;, Password(&apos;test&apos;)); # 在用户表中插入用户信息，直接操作User表不推荐# 删除用户DROP USER &apos;test&apos;@&apos;localhost&apos;;DELETE FROM mysql.user WHERE User=&apos;test&apos; AND Host=&apos;localhost&apos;;FLUSH PRIVILEGES ;# 更改用户密码SET PASSWORD FOR &apos;test&apos;@&apos;localhost&apos; = PASSWORD(&apos;test&apos;);UPDATE mysql.user SET Password=Password(&apos;t&apos;) WHERE User=&apos;test&apos; AND Host=&apos;localhost&apos;;FLUSH PRIVILEGES ;# 用户授权GRANT ALL PRIVILEGES ON *.* TO test@localhost IDENTIFIED BY &apos;test&apos;;# 授予用&apos;test&apos;密码登陆成功的test@localhost用户操作所有数据库的所有表的所有的权限FLUSH PRIVILEGES ; # 刷新系统权限表,使授予权限生效# 撤销用户授权REVOKE DELETE ON *.* FROM &apos;test&apos;@&apos;localhost&apos;; # 取消该用户的删除权限 存储过程 1234567891011121314151617181920212223242526272829303132333435# 创建存储过程DELIMITER // # 无参数CREATE PROCEDURE getDates() BEGIN SELECT * FROM test ; END //CREATE PROCEDURE getDates_2(IN id INT) # in参数 BEGIN SELECT * FROM test WHERE a = id; END //CREATE PROCEDURE getDates_3(OUT sum INT) # out参数 BEGIN SET sum = (SELECT count(*) FROM test); END //CREATE PROCEDURE getDates_4(INOUT i INT) # inout参数 BEGIN SET i = i + 1; END //DELIMITER ;# 删除存储过程DROP PROCEDURE IF EXISTS getDates;# 修改存储过程的特性ALTER PROCEDURE getDates MODIFIES SQL DATA ;# 修改存储过程语句（删除再重建）略# 查看存储过程SHOW PROCEDURE STATUS LIKE &apos;getDates&apos;; # 状态SHOW CREATE PROCEDURE getDates_3; # 语句# 调用存储过程CALL getDates();CALL getDates_2(1);CALL getDates_3(@s);SELECT @s;SET @i = 1;CALL getDates_4(@i);SELECT @i; # @i = 2 SQL语句关键字SQL语言包括数据定义(DDL)、数据操纵(DML),数据控制(DCL)和数据查询（DQL）四个部分。 数据定义：Create Table,Alter Table,Drop Table, Craete/Drop Index 数据操纵：select ,insert,update,delete 数据控制：revoke 数据查询：select DROP、TRUNCATE、DELETE DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行回滚操作。 TRUNCATE TABLE一次性地从表中删除所有的数据，不能通过ROLLBACK回滚。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。 DROP是DDL，会隐式提交，所以不能回滚，不会触发触发器。 表和索引所占空间。当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小，DELETE操作不会减少表或索引所占用的空间。DROP语句将表所占用的空间全释放掉。 应用范围：TRUNCATE只能对TABLE使用；DELETE可以是TABLE和VIEW；DROP可以删除表和数据库。 TRUNCATE和DELETE只删除数据，DROP则删除整个表（结构和数据）。TRUNCATE与不带WHERE的DELETE：只删除数据，而不删除表的结构（定义）；DROP语句将删除表的结构，被依赖的约束（constrain)，触发器（trigger)，索引（index）也会被删除；而依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。 对于外键（FOREIGN KEY）约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带where 子句的 DELETE 语句。TRUNCATE TABLE不能用于参与了索引视图的表。 MySQL连接方式内链接：（相交部分)关键字：inner join on 语句：select * from a_table a inner join b_table b on a.a_id = b.b_id; 左链接：（左边部分）关键字：left join on / left outer join on 语句：select * from a_table a left join b_table b on a.a_id = b.b_id; 右链接：（右边部分）关键字：right join on/right outer join on 语句：select * from a_table a right outer join b_table b on a.a_id = b.b_id; 全链接：目前MySQL不支持MySQL查询过程 客户端先发送一条查询给服务器； 服务器先检查查询缓存，如果命中了缓存，则立刻返回给存储在缓存中的结果，否则进入下一个阶段； 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划； MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询； 将结果返回客户端。 数据库高并发解决方法总结一个项目刚开始的时候是为了实现基本功能，随着版本和功能的迭代，大数据和高并发成了软件设计必须考虑的问题！本质很简单，一个是慢，一个是等。两者是相互关联的，因为慢，所以要等，因为等，所以慢，解决了慢，也就解决了等，解决了等，也就解决了慢。关键是如何解决慢和等，核心一个是短，一个是少，一个是分流，最后一种是集群/横向扩张/读写分离/建立主从。 短是指路径要短：典型的mvc结构是请求-&gt;controller-&gt;model-&gt;dao-&gt;view，然后把页面返回给用户。要想短的话， 页面静态化-用户可以直接获取页面，不用走那么多流程，比较适用于页面不频繁更新。 使用缓存-第一次获取数据从数据库准提取，然后保存在缓存中，以后就可以直接从缓存提取数据。不过需要有机制维持缓存和数据库的一致性。 使用储存过程-那些处理一次请求需要多次访问数据库的操作，可以把操作整合到储存过程，这样只要一次数据库访问就可以了。 批量读取-高并发情况下，可以把多个请求的查询合并到一次进行，以减少数据库的访问次数 延迟修改-高并发情况下，可以把多次修改请求，先保存在缓存中，然后定时将缓存中的数据保存到数据库中，风险是可能会断电丢失缓存中的数据， 使用索引-索引可以看作是特殊的缓存，尽量使用索引就要求where字句中精确的给出索引列的值。 少是指查询的数据要少 分表-把本来同一张表的内容，可以按照地区，类别等分成多张表，很简单的一个思路，但是要尽量避免分出来的多表关联查询。 分离活跃数据-例如登录用户业务，注册用户很多，但是活跃的登录用户很少，可以把活跃用户专门保存一张表，查询是先查询活跃表，没有的话再查总表，这也类似与缓存啦。 分块-数据库层面的优化，对程序是透明的，查询大数据只用找到相应块就行。 分流三种: 集群-将并发请求分配到不同的服务器上，可以是业务服务器，也可以是数据库服务器。 分布式-分布式是把单次请求的多项业务逻辑分配到多个服务器上，这样可以同步处理很多逻辑，一般使用与特别复杂的业务请求。 CDN -在域名解析层面的分流，例如将华南地区的用户请求分配到华南的服务器，华中地区的用户请求分配到华中的服务器。 高并发数据库系统 数据库的优化，包括合理的事务隔离级别、SQL语句优化、索引的优化 使用缓存，尽量减少据库 IO 分布式数据库、分布式缓存 服务器的负载均衡 SQL优化选择正确的存储引擎以 MySQL为例，包括有两个存储引擎 MyISAM 和 InnoDB，每个引擎都有利有弊。 MyISAM 适合于一些需要大量查询的应用，但其对于有大量写操作并不是很好。甚至你只是需要update一个字段，整个表都会被锁起来，而别的进程，就算是读进程都无法操作直到读操作完成。另外，MyISAM 对于 SELECT COUNT(*) 这类的计算是超快无比的。 InnoDB 的趋势会是一个非常复杂的存储引擎，对于一些小的应用，它会比 MyISAM 还慢。但是它支持“行锁” ，于是在写操作比较多的时候，会更优秀。并且，他还支持更多的高级应用，比如：事务。 优化字段的数据类型记住一个原则，越小的列会越快。如果一个表只会有几列罢了（比如说字典表，配置表），那么，我们就没有理由使用 INT 来做主键，使用 MEDIUMINT, SMALLINT 或是更小的 TINYINT 会更经济一些。如果你不需要记录时间，使用 DATE 要比 DATETIME 好得多。当然，你也需要留够足够的扩展空间。 为常用的搜索字段添加索引索引并不一定就是给主键或是唯一的字段。如果在你的表中，有某个字段你总要会经常用来做搜索，那么最好是为其建立索引，除非你要搜索的字段是大的文本字段，那应该建立全文索引。 避免使用Select *从数据库里读出越多的数据，那么查询就会变得越慢。并且，如果你的数据库服务器和WEB服务器是两台独立的服务器的话，这还会增加网络传输的负载。即使你要查询数据表的所有字段，也尽量不要用*通配符，善用内置提供的字段排除定义也许能给带来更多的便利。 使用 ENUM 而不是 VARCHARENUM 类型是非常快和紧凑的。在实际上，其保存的是 TINYINT，但其外表上显示为字符串。这样一来，用这个字段来做一些选项列表变得相当的完美。例如，性别、民族、部门和状态之类的这些字段的取值是有限而且固定的，那么，你应该使用 ENUM 而不是 VARCHAR。 尽可能的使用 NOT NULL除非你有一个很特别的原因去使用 NULL 值，你应该总是让你的字段保持 NOT NULL。 NULL其实需要额外的空间，并且，在你进行比较的时候，你的程序会更复杂。 当然，这里并不是说你就不能使用NULL了，现实情况是很复杂的，依然会有些情况下，你需要使用NULL值。+ 固定长度的表会更快如果表中的所有字段都是“固定长度”的，整个表会被认为是 “static” 或 “fixed-length”。 例如，表中没有如下类型的字段： VARCHAR，TEXT，BLOB。只要你包括了其中一个这些字段，那么这个表就不是“固定长度静态表”了，这样，MySQL 引擎会用另一种方法来处理。 固定长度的表会提高性能，因为MySQL搜寻得会更快一些，因为这些固定的长度是很容易计算下一个数据的偏移量的，所以读取的自然也会很快。而如果字段不是定长的，那么，每一次要找下一条的话，需要程序找到主键。 并且，固定长度的表也更容易被缓存和重建。不过，唯一的副作用是，固定长度的字段会浪费一些空间，因为定长的字段无论你用不用，他都是要分配那么多的空间。 SQL语句优化方法 where子句中：where表之间的连接必须写在其他Where条件之前，那些可以过滤掉最大数量记录的条件必须写在where子句的末尾.HAVING最后。 用EXISTS替代IN、用NOT EXISTS替代NOT IN。 避免在索引列上使用计算 避免在索引列上使用IS NULL和IS NOT NULL 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描 实践中优化MySQL从效果上第一条影响最大，后面越来越小。 SQL语句及索引的优化 数据库表结构的优化 系统配置的优化 硬件的优化 优化数据库方法 选取最适用的字段属性，尽可能减少定义字段宽度，尽量把字段设置NOTNULL，例如’省份’、’性别’最好适用ENUM 使用连接(JOIN)来代替子查询 适用联合(UNION)来代替手动创建的临时表 事务处理 锁定表、优化事务处理 适用外键，优化锁定表 建立索引 优化查询语句 NULL含义NULL这个值表示UNKNOWN(未知)，它不表示“”(空字符串)。对NULL这个值的任何比较都会生产一个NULL值。您不能把任何值与一个 NULL值进行比较，并在逻辑上希望获得一个答案。 使用IS NULL来进行NULL判断 char和varcharchar是一种固定长度的类型，varchar则是一种可变长度的类型，它们的区别是： char(M)类型的数据列里，每个值都占用M个字节，如果某个长度小于M，MySQL就会在它的右边用空格字符补足。（在检索操作中那些填补出来的空格字符将被去掉）在varchar(M)类型的数据列里，每个值只占用刚好够用的字节再加上一个用来记录其长度的字节（即总长度为L+1字节）． varchar的适用场景: 字符串列得最大长度比平均长度大很多。 字符串很少被更新，容易产生存储碎片 使用多字节字符集存储字符串 char的适用场景: 存储具有近似得长度（md5值,身份证，手机号）,长度比较短小得字符串（因为varchar需要额外空间记录字符串长度），更适合经常更新得字符串，更新时不会出现页分裂得情况，避免出现存储碎片，获得更好的io性能。 SQL约束not null：非空约束，强制列不接受空值。例：创建表时，name varchar(6) not null unique：唯一性约束约束唯一标识数据库表中的每条记录 unique和primary key都为数据提供了唯一性约束 primary key 拥有自动定义的unique约束 注意：每个表中只能有一个primary key约束，但是可以有多个Unique约束 语法： 123451.name int unique2.unique(column_name)3.CONSTRAINT uc_PersonID UNIQUE (Id_P, LastName)：添加多个约束 4.alter table table_name add unique(column_name)：增加表中的约束 5.ALTER TABLE table_name DROP CONSTRAINT 主键名：删除约束 Primary Key约束约束唯一标识数据库表中的每条记录 主键必须包含唯一的值，主键列不能为空 每个表都应该有个主键，但只能有一个主键 语法： 123456① StudentID int not null primary key 创建学生编号为主键② primary key(StudentID) 创建学生编号为主键③ primary key(StudentID, Email) 创建学生ID和Email为联合主键④ alter table table_name add primary key(column_name) 为已存在的列创建主键⑤ alter table table_name drop primary key 删除主键约束⑥ alter table table_name drop constraint 主键约束名 删除主键约束 foreign key约束一个表中的foreign key指向另一个表的primary key foreign key约束用于预防破坏表之间连接的动作 foreign key约束也能防止非法数据插入外键列，因为它必须是指向的表中的主键值 语法： 1234foreign key (column_name) references 主表名（主键列名）创建column_name为主表名的外键 column_name int foreign key references 主表名（主键列名）创建column_name为主表名的外键 alter table table_name add foreign key (列名) references 主表名（主键列名）为已存在的列创建外键 alter table table_name drop foreign key 外键约束名 删除外键约束 check 约束check约束用于限制列中的值的范围 如果对个单个列做check约束，那么该列只可以输入特定数值 如果一个表定义check约束，那么此约束会在特定的列对值进行限制 语法： 123StudentID int not null check (StudentID&gt;0) 限制StudentID输入的值要大于0sex varchar(2) not null check(sex=&apos;男&apos; or sex=&apos;女&apos;) 限制sex的性别只能是男或者女 alter table table_name add check(列名&gt;0) 向已有的列加入check约束 default约束：用于向列中插入默认值，若没有规定其他值，那么会将默认值添加到所有的新记录中 语法：name varchar(10) default ‘张三’ name默认插入张三的名字 完整性约束数据完整性(Data Integrity)是指数据的精确(Accuracy)和可靠性(Reliability)。 分为以下四类： 实体完整性：规定表的每一行在表中是惟一的实体。 域完整性：是指表中的列必须满足某种特定的数据类型约束，其中约束又包括取值范围、精度等规定。 参照完整性：是指两个表的主关键字和外关键字的数据应一致，保证了表之间的数据的一致性，防止了数据丢失或无意义的数据在数据库中扩散。 用户定义的完整性：不同的关系数据库系统根据其应用环境的不同，往往还需要一些特殊的约束条件。用户定义的完整性即是针对某个特定关系数据库的约束条件，它反映某一具体应用必须满足的语义要求。 与表有关的约束：包括列约束(NOT NULL（非空约束）)和表约束(PRIMARY KEY、foreign key、check、UNIQUE) 。 基本表和视图基本表是本身独立存在的表，在 SQL 中一个关系就对应一个表。 视图是从一个或几个基本表导出的表。视图本身不独立存储在数据库中，是一个虚表。 视图的优点 视图能够简化用户的操作 视图使用户能以多种角度看待同一数据； 视图为数据库提供了一定程度的逻辑独立性； 视图能够对机密数据提供安全保护。 MySQL运维优化 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。 选择合适的表字段数据类型和存储引擎，适当的添加索引。 mysql库主从读写分离。 找规律分表，减少单表中的数据量提高查询速度。 添加缓存机制，比如memcached，apc等。 不经常改动的页面，生成静态页面。 书写高效率的SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE. 大流量网站，解决各页面访问量统计问题 确认服务器是否能支撑当前访问量。 优化数据库访问。 禁止外部访问链接（盗链）, 比如图片盗链。 控制文件下载。 使用不同主机分流。 使用浏览统计软件，了解访问量，有针对性的进行优化 数据库连接池不用连接池的话，就要根据每个请求或者每个用户来建立连接。这样的缺点是显而易见的。 这样需要建立很多连接，建立连接是要花很多时间的。 有的用户建立了连接，却没有使用，造成了资源浪费。 因此需要用连接池，如下先建好5个连接（Tomcat默认的连接是10到100个，可修改），每次请求来了直接用，用完了还回去，如果请求太多，来不及处理，超时会报错（线程池请求太多会排队，不会超时报错） JDBC和ODBCJDBC使用起来更方便，ODBC因为是C编写，性能更快一些。 JDBC：（Java Data Base Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，它是Java十三个规范之一。可以为多种关系数据库提供统一访问，它由一组用Java语言编写的类和接口组成。 JDBC的最大特点是它独立于详细的关系数据库。 ODBC：是微软公司开放服务结构(WOSA，Windows Open Services Architecture)中有关数据库的一个组成部分。一个基于ODBC的应用程序对数据库的操作不依赖数据库类型，能以统一的方式处理全部的数据库。 MySQL主从同步原理 一句话解释：Slaver读取Master的binlog并顺序执行 概述： MySQL的主从复制是一个异步的复制过程（虽然一般情况下感觉是实时的），在Master与Slave之间实现整个主从复制的过程是由三个线程参与完成的。其中有两个线程（SQL线程和IO线程）在Slave端，另一个线程（I/O线程）在Master端。 要实现MySQL的主从复制，首先必须打开Master端的binlog记录功能，否则就无法实现。因为整个复制过程实际上就是Slave从Master端获取binlog日志，然后再在Slave上以相同顺序执行获取的binlog日志中的记录的各种SQL操作 详细过程 在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制。 此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容 Master服务器接收到来自Slave服务器的IO线程的请求后，其上负责复制的IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在Master服务器端记录的IO线程。返回的信息中除了binlog中的下一个指定更新位置。 当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（Mysql-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容 Slave服务器端的SQL线程会实时检测本地Relay Log 中新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点 知识点 3个线程，主库IO，从库IO和SQL及作用 master.info（从库）作用 relay-log 作用 异步复制 binlog作用（如果需要级联需要开启Binlog） 小结 主从复制是异步的逻辑的SQL语句级的复制 复制时，主库有一个I/O线程，从库有两个线程，I/O和SQL线程 实现主从复制的必要条件是主库要开启记录binlog功能 作为复制的所有Mysql节点的server-id都不能相同 binlog文件只记录对数据库有更改的SQL语句（来自主库内容的变更），不记录任何查询（select，show）语句 工作中常用主从模式 数据库事务断电本地事务数据库断电的这种情况，它是怎么保证数据一致性的呢？ 我们使用SQL Server来举例，我们知道我们在使用 SQL Server 数据库是由两个文件组成的，一个数据库文件和一个日志文件，通常情况下，日志文件都要比数据库文件大很多。数据库进行任何写入操作的时候都是要先写日志的，同样的道理，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时候，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。 两段锁协议数据库的两段锁协议是指所有事务必须分两个阶段对数据项进行加锁和解锁1.扩展阶段在对任何数据项的读、写之前，要申请并获得该数据项的封锁。 2.收缩阶段每个事务中，所有的封锁请求必须先于解锁请求。例如：事务T遵循两段锁协议，其封锁协议为：BEGIN TRANSACTION;LOCK（A）；READ A; A := A + 100; WRITE A; LOCK(B); UNLOCK(A); READ(B), UNLOCK(B),;COMMIT; 可以证明：若并发执行的所有事务均遵守两段锁协议，则对这些并行事务的任何并行调度策略都是可串行化 需要说明的是，并发执行的所有事务若均遵守两段锁协议，只是这些事务的并行调度策略能可串行化的充分条件，不是必要条件。 两段锁协议与防止死锁的一次封锁法的区别：一次封锁法要求事务必须一次对所有要使用到的数据项进行加锁，否则不能继续运行。 显然，一次封锁法符合两段锁协议，但是两段锁协议并不要求一次就要对所有需要用到的数据项进行加锁，因此遵守两段锁协议的事务有可能死锁 参考链接&lt;https://blog.csdn.net/aaronthon/article/details/81714528&gt; &lt;https://blog.csdn.net/c361604199/article/details/79479398&gt; &lt;https://blog.csdn.net/plg17/article/details/78758593&gt; &lt;https://www.cnblogs.com/luyucheng/p/6289714.html&gt; &lt;https://blog.csdn.net/tongdanping/article/details/79878302&gt; &lt;https://blog.csdn.net/yifansj/article/details/79233726&gt; &lt;https://www.cnblogs.com/zxz1987/p/6538462.html&gt; &lt;https://coding.imooc.com/lesson/132.html#mid=6561&gt; &lt;https://coding.imooc.com/lesson/132.html#mid=6562&gt; &lt;https://blog.csdn.net/qq_23923485/article/details/73456784&gt;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://ylovex.cn/tags/MySQL/"}]},{"title":"nowcoder-最小众倍数","date":"2019-06-11T04:52:39.000Z","path":"2019/06/11/nowcoder-最小众倍数/","text":"题目来源：https://www.nowcoder.com/practice/3e9d7d22b7dd4daab695b795d243315b?tpId=90&amp;tqId=30844&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：定5个正整数, 它们的最小的众倍数是指的能够被其中至少三个数整除的最小正整数。给定5个不同的正整数, 请计算输出它们的最小众倍数。 思路：先遍历n从1开始，再遍历nums[i]，使用map记录n*nums[i]出现的次数，当该数的次数出现三次的时候即为最小众倍数。 参考代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Now_68 &#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); int[] nums = new int[5]; for(int i=0;i&lt;5;i++)&#123; nums[i]=sc.nextInt(); &#125; Arrays.sort(nums); int res = getRes(nums); System.out.println(res); &#125; private static int getRes(int[] nums) &#123; Map&lt;Integer , Integer&gt; map = new HashMap&lt;&gt;(); for(int n=1;n&lt;Integer.MAX_VALUE; n++)&#123; for(int i=0;i&lt;5;i++)&#123; if(map.containsKey(n*nums[i]))&#123; map.put(n*nums[i] , map.get(n*nums[i])+1); if(map.get(n*nums[i])==3)&#123; return n*nums[i]; &#125; &#125; else &#123; map.put(n*nums[i] , 1); &#125; &#125; &#125; return -1; &#125; public static int getRes2(int[] nums)&#123; for(int n=1;n&lt;Integer.MAX_VALUE;n++)&#123; int count=0; for(int i=0;i&lt;5;i++)&#123; if(n%nums[i]==0)&#123; count++; &#125; if(count&gt;2)&#123; return n; &#125; &#125; &#125; return -1; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://ylovex.cn/tags/code/"},{"name":"遍历","slug":"遍历","permalink":"http://ylovex.cn/tags/遍历/"}]},{"title":"nowcoder-括号匹配问题","date":"2019-06-06T23:44:08.000Z","path":"2019/06/07/nowcoder-括号匹配问题/","text":"题目来源：https://www.nowcoder.com/practice/380380e6c6b444888ae145593ccbbbca?tpId=90&amp;tqId=30840&amp;tPage=4&amp;rp=4&amp;ru=/ta/2018test&amp;qru=/ta/2018test/question-ranking 题目描述：合法的括号匹配序列被定义为: 空串””是合法的括号序列 如果”X”和”Y”是合法的序列,那么”XY”也是一个合法的括号序列 如果”X”是一个合法的序列,那么”(X)”也是一个合法的括号序列 每个合法的括号序列都可以由上面的规则生成例如””, “()”, “()()()”, “(()())”, “(((())))”都是合法的。 东东现在有一个合法的括号序列s,一次移除 操作分为两步: 移除序列s中第一个左括号 移除序列s中任意一个右括号.保证操作之后s还是一个合法的括号序列东东现在想知道使用上述的移除操作有多少种方案可以把序列s变为空如果两个方案中有一次移除操作移除的是不同的右括号就认为是不同的方案。例如: s = “()()()()()”,输出1, 因为每次都只能选择被移除的左括号所相邻的右括号.s = “(((())))”,输出24, 第一次有4种情况, 第二次有3种情况, … ,依次类推, 4 * 3 * 2 * 1 = 24 思路：反向遍历，用count记录”)“数量，用res记录结果，每次遍历到”)“则count加一，遍历到”(“则结果乘以count，表示该”(“可以匹配的”)”选择为count数，之后count减一继续遍历，遍历完序列后的res即为方案数量。 参考代码：12345678910111213141516171819public class Now_64 &#123; public static void main(String[] args) throws IOException&#123; BufferedReader bf = new BufferedReader(new InputStreamReader(System.in)); String input = bf.readLine(); int len=input.length(); int res=1; int count=0; for(int i=len-1;i&gt;=0;i--)&#123; if(input.charAt(i)==')')&#123; count++; &#125; else &#123; res*=count; count--; &#125; &#125; System.out.println(res); &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://ylovex.cn/tags/code/"},{"name":"Stack","slug":"Stack","permalink":"http://ylovex.cn/tags/Stack/"}]},{"title":"nowcoder-神奇数","date":"2019-06-02T23:40:06.000Z","path":"2019/06/03/nowcoder-神奇数/","text":"题目来源：https://www.nowcoder.com/practice/56d818ae68134c12b26e81f41ecafb9e?tpId=90&amp;tqId=30841&amp;tPage=4&amp;rp=4&amp;ru=%2Fta%2F2018test&amp;qru=%2Fta%2F2018test%2Fquestion-ranking 题目描述：/** 东东在一本古籍上看到有一种神奇数,如果能够将一个数的数字分成两组, 其中一组数字的和等于另一组数字的和,我们就将这个数称为神奇数。 例如242就是一个神奇数,我们能够将这个数的数字分成两组, 分别是{2,2}以及{4},而且这两组数的和都是4.东东现在需要统计给定区间中有多少个神奇数, 即给定区间[l, r],统计这个区间中有多少个神奇数,请你来帮助他。*/ 思路：设数字X，先求出X的每位数字存在List中，再求出X每位数字和，若为奇数则舍弃，若为偶数则判断是否是神奇数，通过动态规划，dp[i] [j]表示链表前i个数字能否求和得到j，则有dp[i] [j]=dp[i-1] [j] || dp[i-1] [j-list.get(i)];通过逆序循环将dp数组简化为一维数组。 参考代码：123456789101112131415161718192021222324252627282930313233343536public class Now_65 &#123; public static void main(String[] args)throws IOException&#123; BufferedReader bf = new BufferedReader(new InputStreamReader(System.in)); String[] strings = bf.readLine().split(&quot; &quot;); int left = Integer.parseInt(strings[0]); int right = Integer.parseInt(strings[1]); int res = 0; for(int num = left ; num&lt;=right ; num++)&#123; if(isMagic(num))&#123; res++; &#125; &#125; System.out.println(res); &#125; private static boolean isMagic(int num) &#123; List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); int sum = 0; while (num&gt;0)&#123; list.add(num%10); sum+=num%10; num/=10; &#125; if(sum%2 != 0) return false; int mid = sum/2; int len = list.size(); boolean[] dp = new boolean[mid+1]; dp[0]=true; for(int i=0;i&lt;len;i++)&#123; for(int j=mid;j&gt;=list.get(i);j--)&#123; dp[j]=dp[j-list.get(i)] || dp[j]; &#125; &#125; return dp[mid]; &#125;&#125;","tags":[{"name":"code","slug":"code","permalink":"http://ylovex.cn/tags/code/"},{"name":"动态规划","slug":"动态规划","permalink":"http://ylovex.cn/tags/动态规划/"}]},{"title":"web工作方式","date":"2019-05-28T13:30:45.000Z","path":"2019/05/28/web工作方式/","text":"Web工作方式：from:《Go Web 编程》 打开浏览器，输入网址后按下回车，然后显示出浏览内容，这个看似简单的用户行为背后，隐藏的流程一般是：浏览器本身是一个客户端，当你输入 URL 的 时候，首先浏览器会去请求 DNS 服务器，通过 DNS 获取相应的域名对应的 IP，然后通过IP 地址找到 IP 对应的服务器后，要求建立 TCP 连接，等浏览器发送完 HTTP Request（请求）包后，服务器接收到请求包之后才开始处理请求包，服务器调用自身服务，返回HTTP Response（响应）包；客户端收到来自服务器的响应后开始渲染这个 Response 包里的主体（body），等收到全部的内容随后断开与该服务器之间的 TCP 连接。 一个Web服务器也被称为HTTP服务器，它通过HTTP协议与客户端通信。这个客户端通常指的是web浏览器（手机端客户端内部也是浏览器实现的）。 Web 服务器的工作原理可以简单地归纳为： 客户机通过 TCP/IP 协议建立到服务器的 TCP 连接 客户端向服务器发送 HTTP 协议请求包，请求服务器里的资源文档 服务器向客户机发送 HTTP 协议应答包，如果请求的资源包含有动态语言的内容，那么服务器会调用动态语言的解释引擎负责处理“动态内容”，并将处理得到的数据返回给客户端 客户机与服务器断开。由客户端解释 HTML 文档，在客户端屏幕上渲染图形结果 一个简单的 HTTP 事务就是这样实现的，看起来很复杂，原理其实是挺简单的。需要注意的 是客户机与服务器之间的通信是非持久连接的，也就是当服务器发送了应答后就与客户机断开连接，等待下一次请求。 URL与DNS解析：URL(Uniform Resource Locator)是“统一资源定位符”的英文缩写，用于描述一个网络上的资源, 基本格式如下： 12345678schema://host[:port#]/path/.../[?query-string][#anchor]scheme 指定低层使用的协议(例如：http, https, ftp)host HTTP 服务器的 IP 地址或者域名port# HTTP 服务器的默认端口是 80，这种情况下端口号可以省略。如果使用了别的端口，必须指明，例如 http://www.cnblogs.com:8080/path 访问资源的路径query-string 发送给 http 服务器的数据anchor 锚 DNS(Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于 TCP/IP 网络，它从事将主机名或域名转换为实际 IP 地址的 工作。 更详细的 DNS 解析的过程如下，这个过程有助于我们理解 DNS 的工作模式 在浏览器中输入 www.qq.com 域名，操作系统会先检查自己本地的 hosts 文件是否有这个网址映射关系，如果有，就先调用这个 IP 地址映射，完成域名解析。 如果 hosts 里没有这个域名的映射，则查找本地 DNS 解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 如果 hosts 与本地 DNS 解析器缓存都没有相应的网址映射关系，首先会找 TCP/IP参数中设置的首选 DNS 服务器，在此我们叫它本地 DNS 服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 如果要查询的域名，不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析，此解析不具有权威性。 如果本地 DNS 服务器本地区域文件与缓存解析都失效，则根据本地 DNS 服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地 DNS 就把请求发至 “根 DNS服务器”，“根 DNS 服务器”收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个 IP。本地 DNS 服务器收到 IP 信息后，将会联系负责.com域的这台服务器。这台负责.com 域的服务器收到请求后，如果自己无法解析，它就会找一 个管理.com 域的下一级 DNS 服务器址(qq.com)给本地 DNS 服务器。当本地 DNS 服务器收到这个地址后，就会找 qq.com 域服务器，重复上面的动作，进行查询，直至找到www.qq.com 主机。 如果用的是转发模式，此 DNS 服务器就会把请求转发至上一级 DNS 服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根 DNS 或把转请求转至上上级，以此循环。不管是本地 DNS 服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS 服务器，由此 DNS 服务器再返回给客户机。 通过上面的步骤，我们最后获取的是 IP 地址，也就是浏览器最后发起请求的时候是基于 IP来和服务器做信息交互的。 HTTP协议：HTTP 是一种让 Web 服务器与浏览器(客户端)通过 Internet 发送与接收数据的协议,它建立在 TCP 协议之上，一般采用 TCP 的 80 端口。它是一个请求、响应协议–客户端发出一个请 求，服务器响应这个请求。在 HTTP 中，客户端总是通过建立一个连接与发送一个 HTTP 请 求来发起一个事务。服务器不能主动去与客户端联系，也不能给客户端发出一个回调连接。 客户端与服务器端都可以提前中断一个连接。例如，当浏览器下载一个文件时，你可以通过点击“停止”键来中断文件的下载，关闭与服务器的 HTTP 连接。HTTP 协议是无状态的，同一个客户端的这次请求和上次请求是没有对应关系，对 HTTP服务器来说，它并不知道这两个请求是否来自同一个客户端。为了解决这个问题， Web 程 序引入了 Cookie 机制来维护连接的可持续状态。 HTTP 协议是建立在 TCP 协议之上的，因此 TCP 攻击一样会影响 HTTP 的通讯，例如比较常见的一些攻击：SYN Flood 是当前最流行的 DoS（拒绝服务攻击）与 DdoS（分布式拒 绝服务攻击）的方式之一，这是一种利用 TCP 协议缺陷，发送大量伪造的 TCP 连接请求，从而使得被攻击方资源耗尽（CPU 满负荷或内存不足）的攻击方式。 HTTP交互方式：最基本的是GET、POST、PUT、DELETE。一个URL地址用于描述一个网络上的资源，而HTTP中的GET、POST、PUT、DELETE就对应着这个资源的查、改、增、删四个操作。 GET一般用于获取/查询资源信息，POST一般用于更新资源信息。区别在于： GET提交的数据会放在URL之后，以？分割URL和传输数据，参数之间以&amp;相连。POST方法是把提交数据放在HTTP包的Body中。 GET提交的数据大小有限制（因为浏览器对URL长度有限制），而POST提交数据没有限制。 GET方式提交数据，存在安全问题，比如登录页面，通过GET方式的话，用户名和密码都在URL上面，如果页面可以缓存或者其他人可以访问这台机器的，就可以从历史记录中获取账户和密码。 状态码：状态码用来告诉HTTP客户端，HTTP服务器是否产生了预期的Response。HTTP/1.1协议中定义了5类状态码，由三位数字组成，第一个数字定义了响应的类别。 1XX：提示信息-表示请求已经被成功接收，继续处理。 2XX：成功-表示请求已经被成功接收。 3XX：重定向-要完成请求必须进行更进一步处理。 4XX：客户端错误-请求有语法错误或请求无法实现。 5XX：服务器端错误-服务器未能实现合法的请求。 状态码 状态 详情 200 成功 服务器已经处理请求 301 永久重定向 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置 302 临时重定向 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求 303 请求资源路径改变 使用GET方法请求新url 400 请求错误 请求的报文中存在语法错误，比如url含有非法字符 401 未授权 未授权，比如访问SpringSecurity限制了权限的资源 404 未找到 服务器找不到请求的网页 405 请求错误 请求的方式（get、post、delete）方法与后台规定的方式不符合 415 请求错误 后台程序不支持提交的content-type 500 服务器内部错误 服务器遇到错误，无法完成请求","tags":[{"name":"web","slug":"web","permalink":"http://ylovex.cn/tags/web/"},{"name":"http","slug":"http","permalink":"http://ylovex.cn/tags/http/"}]},{"title":"排序算法总结","date":"2019-05-25T12:32:28.000Z","path":"2019/05/25/排序算法总结/","text":"排序算法：稳定：如果a在b前面 ，并且a==b，排序后a仍在b前面 不稳定：如果a在b前面，并且a==b，排序后a可能在b后面 时间复杂度：指执行当前算法所消耗的时间 空间复杂度：值执行当面算法所占用的内存空间 内排序：所有排序操作都在内存中完成 外排序：数据放在磁盘中，排序通过磁盘和内存的数据传输进行 冒泡排序:1234567891011121314151617181920212223242526272829303132public class bubbleS &#123; public static void bubbleSort1(int[] data)&#123; int len = data.length; for(int i=len-1;i&gt;0;i--)&#123; for(int j=0;j&lt;i;j++)&#123; //比较相邻两数，若前面大则交换 if(data[j]&gt;data[j+1])&#123; int tem = data[j]; data[j]=data[j+1]; data[j+1]=tem; &#125; &#125; &#125; &#125; public static void bubbleSort2(int[] data)&#123; int len = data.length; for(int i=len-1;i&gt;0;i--)&#123; //改进冒泡，如果一次比较都没有交换，则已经排好序，跳出循环 boolean isSort = true; for(int j=0;j&lt;i;j++)&#123; if(data[j]&gt;data[j+1])&#123; int tem = data[j]; data[j]=data[j+1]; data[j+1]=tem; isSort=false; &#125; &#125; if(isSort) break; &#125; &#125;&#125; 选择排序：1234567891011121314public class selectS &#123; public static void selectSort1(int[] data)&#123; for(int i=0;i&lt;data.length;i++)&#123; //记录每次循环中最小数的下标然后和data[i]交换 int minIndex = i; for(int j=i+1;j&lt;data.length;j++)&#123; minIndex = data[j]&lt;data[minIndex] ? j : minIndex; &#125; int tem = data[i]; data[i]=data[minIndex]; data[minIndex]=tem; &#125; &#125;&#125; 插入排序：1234567891011121314public class insertS &#123; public static void insertSort1(int[] data)&#123; int len = data.length; for(int i=1;i&lt;len;i++)&#123;//默认第一个数已排好序，从第二个数开始扫描 int tem = data[i]; int j = i-1;//将data[i]与前一位data[i-1]比较 while (j&gt;=0 &amp;&amp; tem&lt;data[j])&#123;//若小于，将前面的数往后移 data[j+1]=data[j]; j--; &#125; data[j+1]=tem;//找到位置后插入 &#125; &#125;&#125; 希尔排序：123456789101112131415161718public class shellS &#123; public static void shellSort1(int[] data)&#123; int len = data.length; int gap = len/2; while (gap&gt;0)&#123; for(int i=gap;i&lt;len;i++)&#123; int tem = data[i]; int preIndex = i-gap; while (preIndex &gt;= 0 &amp;&amp; data[preIndex]&gt;tem)&#123; data[preIndex+gap]=data[preIndex]; preIndex-=gap; &#125; data[preIndex+gap]=tem; &#125; gap/=2; &#125; &#125;&#125; 归并排序：1234567891011121314151617181920212223242526272829303132public class mergeS &#123; public static void mergeSort1(int[] data)&#123; if(data==null || data.length==0) return; mergeRec(data , 0 , data.length-1); &#125; public static void mergeRec(int[] data , int left , int right)&#123; if(left&gt;=right) return; int mid = left + (right-left)/2; mergeRec(data , left , mid); mergeRec(data , mid+1 , right); merge(data , left , mid , right); &#125; public static void merge(int[] data , int left , int mid , int right)&#123; int[] h = new int[right-left+1]; int p1 = left , p2=mid+1; int k = 0; while (p1&lt;=mid &amp;&amp; p2&lt;=right)&#123; h[k++]=data[p1]&lt;=data[p2] ? data[p1++] : data[p2++]; &#125; while (p1&lt;=mid)&#123; h[k++]=data[p1++]; &#125; while (p2&lt;=right)&#123; h[k++]=data[p2++]; &#125; for(int i=0;i&lt;k;i++)&#123; data[left+i]=h[i]; &#125; &#125;&#125; 堆排序：123456789101112131415161718192021222324252627282930313233343536373839public class heapS &#123; public static void heapSort1(int[] data)&#123; if(data==null || data.length&lt;=1) return; for(int i=0;i&lt;data.length;i++)&#123; siftUp(data , i);//上浮建堆 &#125; int len = data.length-1; swap(data , 0 , len); while (len&gt;0)&#123; siftDown(data , 0 , len); swap(data , 0 , --len); &#125; &#125; public static void siftUp(int[] data , int i)&#123; while (data[i]&gt;data[(i-1)/2])&#123; swap(data , i , (i-1)/2); i=(i-1)/2; &#125; &#125; public static void siftDown(int[] data , int i , int heapSize)&#123; int left = 2*i+1; int right = 2*i+2; int maxIdx = i; if(left&lt;heapSize &amp;&amp; data[left]&gt;data[maxIdx]) maxIdx=left; if(right&lt;heapSize &amp;&amp; data[right]&gt;data[maxIdx]) maxIdx = right; if(maxIdx != i)&#123; swap(data , i , maxIdx); siftDown(data , maxIdx , heapSize); &#125; &#125; public static void swap(int[] data , int s1 , int s2)&#123; int tem = data[s1]; data[s1]=data[s2]; data[s2]=tem; &#125;&#125; 快速排序：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class quickS &#123; public void quickSort_1(int[] data, int start, int end) &#123; if (data == null || start &lt; 0 || end &gt; data.length - 1) &#123; throw new IllegalArgumentException(&quot;Invalid Parameters&quot;); &#125; if (start == end) return; int index = partition(data, start, end); if (index &gt; start) &#123; quickSort_1(data, start, index - 1); &#125; if (index &lt; end) &#123; quickSort_1(data, index + 1, end); &#125; &#125; private int partition(int[] data, int start, int end) &#123; int index = start + (int)(Math.random() * (end - start + 1)); swap(data, index, end); int small = start - 1; for (index = start; index &lt; end; index++) &#123; if (data[index] &lt; data[end]) &#123; small++; if (small != index) &#123; swap(data, index, small); &#125; &#125; &#125; swap(data, small + 1, end); return small + 1; &#125; private void swap(int[] data, int i, int j)&#123; int temp = data[i]; data[i] = data[j]; data[j] = temp; &#125; public void quickSort_2(int[] data, int start, int end) &#123; if (data == null || start &gt;= end) return; int i = start, j = end; int pivotKey = data[start]; while (i &lt; j) &#123; while (i &lt; j &amp;&amp; data[j] &gt;= pivotKey) j--; if (i &lt; j) data[i++] = data[j]; while (i &lt; j &amp;&amp; data[i] &lt;= pivotKey) i++; if (i &lt; j) data[j--] = data[i]; &#125; data[i] = pivotKey; quickSort_2(data, start, i - 1); quickSort_2(data, i + 1, end); &#125;&#125;","tags":[{"name":"排序","slug":"排序","permalink":"http://ylovex.cn/tags/排序/"}]},{"title":"单例模式","date":"2019-05-10T12:31:47.000Z","path":"2019/05/10/单例模式/","text":"单例模式：from 《菜鸟教程》 是属于创建型模式，提供了一种创建对象的最佳方式。 这种模式涉及到一个单一的类，这个类负责创建自己的对象，同时也只有单个对象被创建，这个类提供了一个访问其唯一对象的方法，同时不需要实例化就可以直接访问。 单例类只能有一个实例 单例类必须自己创建自己的唯一实例 单例类必须给所有其他对象提供该实例 单例与静态类 单例可以继承和被继承，方法可以被重写，而静态方法不可以 静态方法中产生的对象会在执行后被释放，进而被GC清理，不会一直存在内存中 静态类会在第一次运行时候初始化，单例模式可以延迟加载 懒汉式，线程不安全Lazy初始化，非多线程 1234567891011public class Singleton &#123; private static Singleton instance; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; if(instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 懒汉式，线程安全Lazy初始化，多线程 12345678910public class Singleton&#123; private static Singleton instance; private Singleton()&#123;&#125; public static synchronized Singleton getInstance()&#123; if(instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 饿汉式非Lazy初始化，多线程，类加载时就初始化 1234567public class Singleton&#123; private static Singleton instance = new Singleton(); private Singleton()&#123;&#125; public static Singleton getInstance()[ return instance; ]&#125; 双检锁1234567891011121314public class Singleton&#123; private volatile static Singleton singleton; private Singleton()&#123;&#125; public static Singleton getSingleton()&#123; if(singleton == null)&#123; synchronized(Singleton.class)&#123; if(singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 登记式123456789public class Singleton&#123; private static class SingletonHolder&#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton()&#123;&#125; public static final Singleton getInstance()&#123; return SingletonHolder.INSTANCE; &#125;&#125; 枚举123456public enum Singleton&#123; INSTANCE; public void whateverMethod()&#123; &#125;&#125;","tags":[{"name":"单例模式","slug":"单例模式","permalink":"http://ylovex.cn/tags/单例模式/"}]},{"title":"Java Map笔记","date":"2019-05-02T13:54:41.000Z","path":"2019/05/02/java-map笔记/","text":"HashMap实现原理 参考https://www.cnblogs.com/chengxiao/p/6059914.html Entry内部结构为： HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，即链地址法。HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对和一个hash值和一个指向下一个Entry的next指针。 如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即 如果定位到的数组包含链表，对于添加操作，其时间复杂度依然为O(1)，操作是创建新节点，把该新节点插入到链表中的头部，该新节点的next指针指向原来的头结点 ，即需要简单改变引用链即可，而对于查找操作来讲，此时就需要遍历链表，然后通过key对象的equals方法逐一比对查找。 所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作 如果key为null，就会插入到table[0]的位置也就是数组头。如果key=null，则hash值直接赋0 存key时，如果链中存在该key，则用传入的value覆盖掉旧的value，同时把旧的value返回：这就是为什么HashMap不能有两个相同的key的原因。 计算hash值之后，如何通过hash值均匀的存到数组里？当然是取模，但取模消耗大，因此HashMap用的&amp;运算符（按位与操作）来实现的：hashCode &amp; (length-1)。 这里就隐含了为什么数组长度length一定要是2的n次方。当length不是2的n次方的时候，length-1的二进制最后一位肯定是0，在&amp;操作时，一个为0，无论另一个为1还是0，最终&amp;操作结果都是0，这就造成了结果的二进制的最后一位都是0，这就导致了所有数据都存储在2的倍数位上，所以说，所以说当length = 2^n时，不同的hash值发生碰撞的概率比较小，这样就会使得数据在table数组中分布较均匀，查询速度也较快。 存储过程： 传入key和value，判断key是否为null，如果为null，则调用putForNullKey，以null作为key存储到哈希表中； 2. 然后计算key的hash值，根据hash值搜索在哈希表table中的索引位置，若当前索引位置不为null，则对该位置的Entry链表进行遍历，如果链中存在该key，则用传入的value覆盖掉旧的value，同时把旧的value返回，结束； 3. 否则调用addEntry，用key-value创建一个新的节点，并把该节点插入到该索引对应的链表的头部 读取过程： 调用hash（key）求得key的hash值，然后调用indexFor（hash）求得hash值对应的table的索引位置，然后遍历索引位置的链表，如果存在key，则把key对应的Entry返回，否则返回null。 JDK1.8前后HashMap区别 在JDK1.8以前版本中，HashMap的实现是数组+链表，它的缺点是即使哈希函数选择的再好，也很难达到元素百分百均匀分布，而且当HashMap中有大量元素都存到同一个桶中时，这个桶会有一个很长的链表，此时遍历的时间复杂度就是O(n)，当然这是最糟糕的情况。 在JDK1.8及以后的版本中引入了红黑树结构，HashMap的实现就变成了数组+链表或数组+红黑树。添加元素时，若桶中链表个数超过8，链表会转换成红黑树；删除元素、扩容时，若桶中结构为红黑树并且树中元素个数较少时会进行修剪或直接还原成链表结构，以提高后续操作性能；遍历、查找时，由于使用红黑树结构，红黑树遍历的时间复杂度为 O(logn)，所以性能得到提升。 123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; HashMap扩容HashMap扩容可以分为三种情况： 使用默认构造方法初始化HashMap。HashMap在一开始初始化的时候会返回一个空的table，并且thershold为0。因此第一次扩容的容量为默认值DEFAULT_INITIAL_CAPACITY也就是16。同时threshold = DEFAULT_INITIAL_CAPACITY * DEFAULT_LOAD_FACTOR = 12。 指定初始容量的构造方法初始化HashMap。初始容量会等于threshold，接着threshold = 当前的容量（threshold） * DEFAULT_LOAD_FACTOR。 HashMap不是第一次扩容。如果HashMap已经扩容过的话，那么每次table的容量以及threshold量为原有的两倍。 HashMap是先插入数据再进行扩容的，但是如果是刚刚初始化容器的时候是先扩容再插入数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 参考https://blog.csdn.net/pange1991/article/details/82347284 HashMap多线程问题HashMap在多线程情况下出现死循环主要是在1.7情况下面，存在多线程时候应该使用ConcurrentHashMap。 12345678910111213void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; 12345678910111213141516171819202122void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; //循环取出原数组中每一个链表，e本身也是一个链表的节点，同时包含下一个节点的连接, //此处e表示第一个节点，next表示链表的下一个节点 if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); //计算在新数组中的存储位置 e.next = newTable[i]; //将原数组链表的第一个元素的next指向新数组，若新数组中已经存在元素， //则这个元素为第一个元素，next属性为原节点地址 newTable[i] = e; //将新数组的头节点指向e，此时e(原数组中的第一个元素)已经成功的转移到了新数据中 e = next; //继续处理原数组中剩下的节点 &#125; &#125; &#125; 参考https://www.jianshu.com/p/1ff9f3dee207 HashMap和HashTable Hashtable 中的方法是同步的，而HashMap中的方法在缺省情况下是非同步的。 Hashtable中，key和value都不允许出现null值。在HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。 并发性不如ConcurrentHashMap，因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。 HashTable和synchronizedMap和ConcurrentHashMapHashTable、synchronizedMap效率低下 现在基本不用HashTable。HashTable容器使用synchronized来保证线程安全，但是锁的是整个hash表，当一个线程使用 put 方法时，另一个线程不但不可以使用 put 方法，连 get 方法都不可以。 synchronizedMap比HashTable强一分钱，synchronizedMap提供一个不同步的基类和一个同步的包装。允许需要同步的用户可以拥有同步，而不需要同步的用户则不必为同步付出代价，get方法与HashTable一样锁住整个hash表，区别是get()和put()之类的简单操作可以在不需要额外同步的情况下安全地完成。但多个操作组成的操作序列却可能导致数据争用，总之就是不好用。 ConcurrentHashMap效率高，因为用了分段锁（JDK8之前），16个 HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁 那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率 这就是 ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，默认分成16个段，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 上面说到的16个线程指的是写线程，而读操作大部分时候都不需要用到锁。只有在size等操作时才需要锁住整个hash表。 ConcurrentHashMap JDK1.8基本结构：Node&lt;K,V&gt;数组+链表（红黑树）的结构。 而对于锁的粒度，调整为对每个数组元素加锁（Node），即没有分段锁了，而是Node锁，粒度更小。 使用CAS操作来确保Node的一些操作的原子性，这种方式代替了锁。 ConcurrentHashMap在线程安全的基础上提供了更好的写并发能力，但同时降低了读一致性。ConcurrentHashMap的get操作上面并没有加锁。所以在多线程操作的过程中，并不能完全的保证一致性。这里和1.7当中类似，是弱一致性的体现。 代码中使用synchronized而不是ReentrantLock，说明JDK8中synchronized有了足够的优化。 然后是定位节点的hash算法被简化了，这样带来的弊端是Hash冲突会加剧。 因此在链表节点数量大于8时，会将链表转化为红黑树进行存储。这样一来，查询的时间复杂度就会由原先的O(n)变为O(logN)。 ConcurrentHashMap的设计与实现非常精巧，大量的利用了volatile，final，CAS等lock-free技术来减少锁竞争对于性能的影响。 HashEntry中的value以及next都被volatile修饰，这样在多线程读写过程中能够保持它们的可见性。 HashMap读取与写入1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; 12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125;","tags":[{"name":"Java","slug":"Java","permalink":"http://ylovex.cn/tags/Java/"},{"name":"Map","slug":"Map","permalink":"http://ylovex.cn/tags/Map/"}]},{"title":"LMS算法","date":"2019-04-25T12:07:05.000Z","path":"2019/04/25/LMS算法/","text":"自适应滤波就是利用前一时刻获得的滤波器参数来自动调节现时刻的滤波器参数，以适应信号和噪声随时间变化的统计特性，从而实现最优滤波。 主输入端接收带噪信号，参考端为噪声信号，其中参考信号vi是与主输入端中信号s无关但与vo相关的噪声信号，利用量输入信号的相关性和有用信号与噪声的独立性，使参考信号尽可能逼近主输入端中的vo并相减从而抵消掉主输入端中的噪声干扰，最终得到有用信号。 算法代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253function [yn,w,en,itr]=LMSALG(xn,dn,M,mu,itr)% LMS(Least Mean Squre)算法% 输入参数:% xn 输入的信号序列 (列向量) % dn 所期望的响应序列 (列向量) % M 滤波器的阶数 (标量) % mu 收敛因子(步长) (标量) 要求大于0,小于xn的相关矩阵最大特征值的倒数 % itr 迭代次数 (标量) 默认为xn的长度,M &lt; itr &lt;= length(xn) % 输出参数: % w 滤波器的权值矩阵 (矩阵) % 大小为M*itr, % en 误差序列(itr*1) (列向量) % yn 实际输出序列 (列向量)% 确定迭代次数，若输入迭代次数itr，则设置为itr；若没有该参数，则设置为输入信号长度% 参数个数必须为4个或5个if nargin == 4 % 4个时递归迭代的次数为xn的长度 itr = length(xn);elseif nargin == 5 % 5个时需满足 M &lt; itr &lt; length(xn) if itr &gt; length(xn) || itr &lt; M error(&apos;迭代次数过大或过小!&apos;); endelse error(&apos;请检查输入参数的个数!&apos;); end % 初始化参数en = zeros(itr,1); % 误差序列,en(k)表示第k次迭代时预期输出与实际输入的误差w = zeros(itr,M); % 每一行代表一个加权参量,每一列代表-次迭代,初始为0% w权系数取为矩阵主要是为了判断该算法的收敛性xn_r=xn&apos;; %%%%参考行向量dn_r=dn&apos;; %%%%nmr行向量% 迭代计算for kitr = M:itr % 第k次迭代 x = xn(kitr:-1:kitr-M+1); % 滤波器M个抽头的输入 y = w(kitr-1,:)*x; % 滤波器的输出 en(kitr) = dn(kitr) - y; % 第k次迭代的误差 % 滤波器权值计算的迭代式 w(kitr,:) = w(kitr-1,:) + 2*mu*en(kitr)*x&apos;;%%xn(kitr-M+1:kitr)&apos;;end%%%方法一、直接使用filter函数来进行滤波处理CancellationData = filter(w(end,:),1,xn_r); % 直接使用filter函数来进行滤波处理yn = dn_r-CancellationData;yn = yn(M+1:end);% 去掉与滤波系数长度对应的前N个点yn=yn&apos;; %%输出行向量% % 求最优时滤波器的输出序列% yn = zeros(size(xn)); % for kitr = M:length(xn)% x = xn(kitr:-1:kitr-M+1);% yn(kitr) = dn(kitr) - w(end,:)*x; % w(:,end)为最后一次迭代生成的滤波器系数% end% yn = yn(M:end); % 前面M个数据没有经过滤波处理，所以设置成inf，绘图时不显示","tags":[{"name":"lms","slug":"lms","permalink":"http://ylovex.cn/tags/lms/"}]},{"title":"Java Set笔记","date":"2019-04-20T13:54:41.000Z","path":"2019/04/20/java-set笔记/","text":"Set种类Set接口的特性，Set接口继承了Collection接口，Set集合中不能包含重复的元素，每个元素必须是唯一的，你只要将元素加入set中，重复的元素会自动移除。 Java中提供了HashSet、TreeSet、LinkedHashSet三种常用的Set实现。 HashSet实现HashSet底层通过HashMap实现。 123456789101112private transient HashMap&lt;E,Object&gt; map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * default initial capacity (16) and load factor (0.75). */ public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; HashSet存储元素是无序的，元素的哈希码进行存储的，HashSet根据每个存储对象的哈希码值（调用hashCode方法获得），用固定的算法算出它的存储索引，把存储对象存放在一个叫做散列表的相应位置中，如果对应的位置没有其它元素，就只需要直接存入；如果该位置已经有元素了，就会将新对象跟该位置的所有对象进行比较（调用equals（）方法），以查看容器中是否已经存在该对象，若不存在，就存放该对象，若已经存在，就直接使用该对象。 HashSet的存储结构是个链表数组，每一个数组元素就是一个链表，类似这种数据结构称为散列表。数组用于存储元素，该存储元素对应的数组下标是调用hashCode方法返回的存储元素的哈希码。当后加入元素的哈希码与已经加入的元素哈希码相同时，HashSet就会创建一个链表，将相同哈希码的元素存入一个链表，并将该链表的头指针存储到哈希码对应的数组元素中。 HashSet和TreeSetHashSet底层数据结构是哈希表，TreeSet底层数据结构是红黑树。 TreeSet保证元素的排序方式： 自然排序(这种排序方式可以理解成元素本身具备比较性)让元素所属的类实现Comparable接口。 比较器排序(这种排序可以理解成集合类具备比较性)让集合构造方法接收Comparator的实现类对象，实现方式可以用匿名类来实现。 LinkedHashSet是HashSet子类，LinkedHashSet集合也是根据元素hashCode值来决定元素存储位置，但它同时使用链表维护元素的次序，这样使的元素看起来是以插入的顺序保存的。也就是说当遍历LinkedHashSet集合里的元素时，HashSet将会按元素的添加顺序来访问集合里的元素。 LinkedHashSet需要维护元素的插入顺序，因此性能略低于HashSet的性能，但是在迭代访问Set里的全部元素时，将有很好的性能，因为它以列表来维护内部顺序。","tags":[{"name":"Java","slug":"Java","permalink":"http://ylovex.cn/tags/Java/"},{"name":"Set","slug":"Set","permalink":"http://ylovex.cn/tags/Set/"}]},{"title":"Java List笔记","date":"2019-04-14T13:54:41.000Z","path":"2019/04/14/java-list笔记/","text":"ListList是一个接口，继承于Collenction接口，它代表着有序的队列。 ​ ps：java.util.Collection是一个集合接口，它提供了对集合对象进行基本操作的通用接口方法；javautil.Collections是一个包装类，它包含各种有关集合操作的静态多态方法，该类不能实例化，服务于Collection框架。 ArrayList：底层是用数组实现。 LinkedList：底层是通过双向链表实现。 Vector：通过数组实现，线程安全。 ArrayList扩容默认初始容量为10. 12345678/** * Default initial capacity. */ private static final int DEFAULT_CAPACITY = 10; transient Object[] elementData; // non-private to simplify nested class access private int size; 扩容，默认为1.5倍方式 1234567891011private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; ArrayList和LinkedListArrayList是实现了基于动态数组的数据结构，LinkedList是基于链表结构。 对于随机访问的get和set方法，ArrayList要优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinkedList比较占优势，因为ArrayList要移动数据。 对ArrayList和LinkedList而言，在列表末尾增加一个元素所花的开销都是固定的。对 ArrayList而言，主要是在内部数组中增加一项，指向所添加的元素，偶尔可能会导致对数组重新进行分配；而对LinkedList而言，这个开销是 统一的，分配一个内部Entry对象。 在ArrayList集合中添加或者删除一个元素时，当前的列表所所有的元素都会被移动。而LinkedList集合中添加或者删除一个元素的开销是固定的。 LinkedList集合不支持高效的随机随机访问（RandomAccess），因为可能产生二次项的行为。 ArrayList的空间浪费主要体现在在list列表的结尾预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗相当的空间。 Arrays.asList()方法123456int[] a = &#123;1,2,3,4&#125;; List a_list = Arrays.asList(a); System.out.println(a_list.size());//size=1 Integer[] b = &#123;1,2,3,4&#125;; List b_list = Arrays.asList(b); System.out.println(b_list.size());//size=4 Arrays.asList方法返回的是List，通过Arrays类的一个内部类实现，内部用的数组就是传入的数组，没有拷贝，也不会动态改变大小，所以对数组的修改也会反应到List中，对List调用add/remove方法会抛出异常。 使用ArrayList方法实现为： 1List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(Arrays.asList(a)); ArrayList线程不安全12345public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; &#125; 因为ArrayList本身不是线程安全的，通过Collections.synchronizedList可以将其包装成一个线程安全的List。 Vector和ArrayListvector是线程（Thread）同步（Synchronized）的，所以它也是线程安全的，而Arraylist是线程异步（ASynchronized）的，是不安全的。如果不考虑到线程的安全因素，一般用Arraylist效率比较高。 如果集合中的元素的数目大于目前集合数组的长度时，vector增长率为目前数组长度的100%,而arraylist增长率为目前数组长度的50%.如过在集合中使用数据量比较大的数据，用vector有一定的优势。","tags":[{"name":"Java","slug":"Java","permalink":"http://ylovex.cn/tags/Java/"},{"name":"List","slug":"List","permalink":"http://ylovex.cn/tags/List/"}]},{"title":"Java 基础知识","date":"2019-04-10T13:43:41.000Z","path":"2019/04/10/java-基础/","text":"面向对象和面向过程 面向过程：是一种是事件为中心的编程思想。就是分析出解决问题所需的步骤，然后用函数把这写步骤实现，并按顺序调用。 面向对象：是以“对象”为中心的编程思想。 面向对象三大特性：封装、继承、多态。因为一切皆对象，所以一切都需要“封装”成类。“继承”让我们设计相似的东西的时候更方便，而“多态”让我们使用类似的东西的时候可以不用去思考它们微弱的不同。我们关心的不是过程，而是接口，而接口来自对象，故名为面向对象。 封装、继承、多态 封装：通过隐藏类的内部实现机制，对外界提供已经定义好的接口进行访问。对外界而言它的内部细节是隐藏的，暴露给外界的只是它的访问方法。 继承：是从已有的类得到继承信息创建新的类的过程，继承可以表示为is-a关系，让我们设计相似的东西的时候更加的方便。 多态：可以分为方法重载和方法重写两种方式，方法重载是在编译时的多态性（也就是前绑定），方法可以根据不同参数类型进行不同的调用，方法名字一致；方法重写是运行时多态（也称为后绑定），实现方法重写：1.方法重写，子类继承父类并重写父类方法；2.用父类型引用来引用子类型对象，实现调用同样的方法会根据子类对象的不同表示出不一样的行为。 反射 Java的反射机制允许我们动态的调用某个对象的方法、构造函数、获取某个对象的属性等； 无需在编码的时候确定调用的对象 实现方式： 先获取这个类的class实例，比如:Class&lt;?&gt; myClass =Class.forName(“myClassName”); 然后通过这个类实例获得一个类对象，比如：Object myClassObject = myClass.newInstance(); 然后调用Class类的对象的getMethod获取method对象; 获取method对象后调用method.invoke方法获取这个类的field、method、construct等，在这一步中，JVM默认如果调用次数小于15次，会调用native方法实现反射，累积调用大于15次之后，会由java代码创建出字节码来实现反射。 集合实现了Collection接口的集合类： Collection&lt;–List&lt;–Vector Collection&lt;–List&lt;–ArrayList Collection&lt;–List&lt;–LinkedList Collection&lt;–Set&lt;–HashSet Collection&lt;–Set&lt;–HashSet&lt;–LinkedHashSet Collection&lt;–Set&lt;–SortedSet&lt;–TreeSet 实现了Map接口，和Collection接口没关系，但都属于集合类的一部分： HashMap HashTable LinkedHashMap TreeMap SynchronizedMap ConcurrentHashMap final和static被final声明的对象即表示“我不想这个对象再被改变”，因此： 被final声明的方法：这个方法不可以被子类重写 被final声明的类：这个类不能被继承 被final声明的变量：引用不能改变，常和static关键字一起使用作为常量final关键字的好处： final关键字提高了性能。JVM和Java应用都会缓存final变量。 final变量可以安全的在多线程环境下进行共享，而不需要额外的同步开销。 使用final关键字，JVM会对方法、变量及类进行优化。 static关键字 static用来修饰成员变量和成员方法，也可以形成静态static代码块。 static对象可以在它的任何对象创建之前访问，无需引用任何对象。 因此主要作用是构造全局变量和全局方法。 数据类型 boolean byte char ：都是一个字节 short int long float double ：int是4个字节，负2的31次方到正2的31次方减1 String Enum Array Object ps：负数使用补码表示 Primitive type: int,long,float… Object: Integer,Long,Float,String… Primitive type: 值类型 用a==b判断相等 Object： 引用类型 用a==b判断是否为同一个Object 用a.equals(b),或者Obeject.equals(a,b)判断是否相等 两个Object如果不是同一个Object，即使值相等用==判断也是false 数组和链表基于空间的考虑： 数组的存储空间是静态，连续分布的，初始化的过大造成空间浪费，过小又将使空间溢出机会增多。而链表的存储空间是动态分布的，只要内存空间尚有空闲，就不会产生溢出；链表中每个节点出了数据域外，还有链域（指向下一个节点），这样空间利用率就会变高。 数组从栈中分配空间，对于程序员方便快速，但是自由度小。链表从堆中分配空间，自由度大但是申请管理比较麻烦。 数组中的数据在内存中按顺序存储的，而链表是随机存储的。 基于时间的考虑： 数组查询快，插入与删除慢，单链表查询慢，插入与删除快。细说的话：数组中任意节点都可以在O（1）内直接存储访问，而链表中的节点，需从头指针顺着链表扫描才能获取到；而链表任意位置进行插入和删除，都只需要修改指针，而数组中插入删除节点，平均要移动一半的节点。 访问控制符 public protected defailt private 同一个类 True True True True 同一个包 True True True False 子父类 True True False False 不同包 True False False False 接口与抽象类抽象类就是比普通类多了一些抽象方法而已，其他部分和普通类完全一样；而接口是特殊的抽象类。作用上看： 接口与抽象类结构有点像，但功能完全不同 接口是强调合约、约束关系，即你要与我合作，必须实现我的功能；抽象类没这个功能 语法上看： 都不能被实例化 接口是特殊的抽象类 接口不能有实现，Java8中可以有添加default关键字的默认实现和静态方法实现。 接口中的成员变量必须是public static final修饰（编译器默认会添加上），因此是常量 一个类可以实现多个接口但只能继承一个抽象类 什么是接口？ 从表现来说：定义了很多函数，但是这些函数都没有实现，这就是接口。从作用来说：起到一个合约规范的作用。我要告诉你和我打交道的东西有什么约束 接口中的方法只能用public和abstract修饰或者不修饰 接口中的属性默认都是public static final，因此是常量 equal与==对于字符串变量： ==：比较两个对象在内存中的首地址 equals：比较字符串中所包含的内容是否相同 对于非字符串变量： ==和equals都是比较对象在堆内存中的首地址。 装箱及拆箱Integer i = 10; //装箱 int n = i ;//拆箱 装箱就是自动将基本数据类型转换为包装器类型。 拆箱就是自动将包装器类型转换为基本数据类型。 hashCode方法及作用Java中的hashCode方法就是根据一定的规则将与对象相关的信息（比如对象的存储地址，对象的 字段等）映射成一个数值，这个数值称作为散列值。 1、在Java集合中有两类，一类是List，一类是Set。他们之间的区别就在于List集合中的元素是有序的，且可以重复，而Set集合中元素是无序不可重复的。对于List好处理，但是对于Set而言我们要如何来保证元素不重复呢？通过迭代来equals()是否相等。数据量小还可以接受，当我们的数据量大的时候效率可想而知2、当集合要添加新的对象时，先调用这个对象的 hashCode方法，得到对应的hashcode值，实际上在HashMap的具体实现中会用一个table保存已经存进去的对象的hashcode 值，如果table中没有该hashcode值，它就可以直接存进去，不用再进行任何比较了；如果存在该hashcode值， 就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址3、所以hashCode在上面扮演的角色为快速寻域（寻找某个对象在集合中区域位置） 在重写equals方法的同时，必须重写hashCode方法。为什么这么说呢？1、让equals方法和hashCode方法始终在逻辑上保持一致性2、即让equals认为相等的两个对象，这两个对象同时调用hashCode方法，返回的值也是一样的 Java8新特性Lambda 表达式 − Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中。 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Date Time API − 加强对日期与时间的处理。 Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用。 Java NIO框架对比Mina Mina(Multipurpose Infrastructure for Network Applications) 是 Apache 组织一个较新的项目，它为开发高性能和高可用性的网络应用程序提供了非常便利的框架。当前发行的 Mina 版本2.04支持基于 Java NIO 技术的 TCP/UDP 应用程序开发、串口通讯程序，Mina 所支持的功能也在进一步的扩展中。 Netty Netty是一款异步的事件驱动的网络应用框架和工具，用于快速开发可维护的高性能、高扩展性协议服务器和客户端。也就是说，Netty是一个NIO客户端/服务器框架，支持快速、简单地开发网络应用，如协议服务器和客户端。它极大简化了网络编程，如TCP和UDP套接字服务器。 Grizzly Grizzly是一种应用程序框架，专门解决编写成千上万用户访问服务器时候产生的各种问题。使用JAVA NIO作为基础，并隐藏其编程的复杂性。容易使用的高性能的API。带来非阻塞socketd到协议处理层。利用高性能的缓冲和缓冲管理使用高性能的线程池。 xSocket xSocket是一个轻量级的基于nio的服务器框架用于开发高性能、可扩展、多线程的服务器。该框架封装了线程处理、异步读/写等方面。（只是对Java的NIO做了最简单的封装，以便于开发使用。","tags":[{"name":"Java","slug":"Java","permalink":"http://ylovex.cn/tags/Java/"}]},{"title":"my first blog","date":"2019-04-03T13:41:41.000Z","path":"2019/04/03/my-first-blog/","text":"Desire is the starting point of all achievement 渴望是所有成就的原点。 love xy","tags":[{"name":"Life","slug":"Life","permalink":"http://ylovex.cn/tags/Life/"}]},{"title":"Hello World","date":"2019-04-01T12:07:05.000Z","path":"2019/04/01/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[]}]